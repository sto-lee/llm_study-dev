{
  "video_url": "https://www.youtube.com/watch?v=aGwYtUzMQUk",
  "video_id": "aGwYtUzMQUk",
  "title": "What is AI Ethics?",
  "upload_date": "20210930",
  "channel": "IBM Technology",
  "duration": "6:10",
  "caption": "I want to start off with talking to you about \nthree things that keep me up at night, right? \n  Three things: the first, and it may be, you \nknow, very common for you too, is climate change.   Climate change absolutely keeps me up at night. The second thing that keeps me up at night   is that people may have no idea that an artificial intelligence is making a decision that directly   impacts their lives - what percentage interest \nrate you get on your loan, whether you get that   job that you applied for, whether your kid gets \ninto that college that they really want to go to.  Today AI is making decisions \nthat directly impact you. The third thing that keeps me up at night \nis: even when people know that an AI   is making a decision about them, they may assume \nthat because it's not a fallible human with bias,   that somehow the AI is going to make a decision that's morally or ethically squeaky clean,   and that could not be farther from the truth. \n  So, if you think about organizations \nand what happens over 80% of the time   proof of concepts associated with artificial \nintelligence actually gets stalled in testing   and more often than not it is because people do not trust the results from that AI model. So, we're going to talk a lot about trust,   and when thinking about trust (I’m going to \nswitch colors here) there's actually five pillars. OK, when you're thinking about what does it \ntake to earn trust in an artificial intelligence   that's being made by your organization or being procured by your organization: five pillars. \n  The first thing to be thinking about \nis fairness. How can you ensure   that the AI model is fair towards everybody in particular historically underrepresented groups. \n  OK, the second is explainable is your AI model explainable such that you'd be able to tell   somebody, an end user, what data sets were being \nused in order to curate that model, what methods,   what expertise was the data lineage in provenance \nassociated with, how that model was trained. \n  The third: robustness. Can you assure end users \nthat nobody can hack such an AI model such that   a person could disadvantage \nwillfully other people and or   make the results of that model benefit \none particular person over another?\n  The fourth is transparency. Are you telling \npeople, right off the bat, that the AI model   is indeed being used to make \nthat decision and are you giving   people access to a fact sheet or metadata so \nthat they can learn more about that model? \n\t\n  And the fifth one is: are you \nassuring people's data privacy?  So, those are the five pillars. OK, now \nIBM has come up with three principles   when thinking about AI in an organization. The first being that the purpose of artificial   intelligence is really meant to be to augment \nhuman intelligence not to replace it.\n  The second is that data and the insights from \nthose data belong to the creator alone\n\t\n  OK, and the third is that AI systems, and I would \nopine the entire AI life cycle, really should be   transparent and explainable, right? \n \nSo, so, those are the five pillars.   Now, the next thing I want you to remember as \nyou're thinking about this space of earning   trust and artificial intelligence is that this is \nnot a technological challenge. It can't be solved   with just throwing tools and tech over some kind \nof fence. This is a socio-technological challenge.   \"Social\" meaning people, people, people. \nSocio-technological challenges because   it's a socio-technological challenge it \nmust be addressed holistically, okay? \n  \"Holistically\" meaning there's three major things \nthat you should think about. I mentioned people,   people the culture of your organization, right? \nThinking about the diversity of your teams,   you know, your data science team. Who is curating \nthat data to train that model? How many women are   on that team? How many minorities are on that \nteam, right? Think about diversity. I don't   know if you've ever heard of the the \"wisdom of \ncrowds\". That's actually a proven mathematical   theory: the more diverse your group of people, \nthe less chance for error, and that is absolutely   true in the realm of artificial intelligence. \n \nThe second thing is process or governance, right?  What is it that use your organization \nwhat are you going to promise your   both your employees as well as the market with \nrespect to what standards you're going to stand by   for your AI model in terms of things like fairness \nand explainability accountability, etc., right?\n  And the third area is tooling, right? What are \nthe tools, AI engineering methods, frameworks   that you can use in order to ensure these \nthings, ensure those five pillars, and we're   gonna do a deep dive into that as well, but the \nnext show that I’m going to be running with you   we're actually going to be talking about this \none. About people and culture. So, stay tuned. \n  If you like this video and series, please \ncomment below stay tuned for more videos   that are part of this series and to \nget updates please like and subscribe."
}