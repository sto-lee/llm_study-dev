{
  "video_url": "https://www.youtube.com/watch?v=BmajUTU3gGU",
  "video_id": "BmajUTU3gGU",
  "title": "AI Pilots to Progress: The lowdown on what makes AI projects successful",
  "upload_date": "20241119",
  "channel": "IBM Technology",
  "duration": "36:51",
  "caption": "My advice would be go with the big or the biggest model that you can find,\nand see if it solves a problem. Then using techniques like distilling\nor fine tuning and there are many others quantization\nsee if you can make the model smaller. 80% of all AI pilots fail. And that's\naccording to the Harvard Business Review. I did my homework, y'all. Four out of five, just dead on arrival. And yet, everywhere we look, it's\nAI everything. So what is actually going on\nbehind the scenes? How do pilots go from something\npromising to a pilot graveyard? And if it is working, when and\nwhere do you double down on the winners? I am beyond thrilled to ask\nthese questions and many more to my guests today. We'll chat first with Anupam Singh,\nwho is the VP of AI and Growth at Roblox. Anupam, thanks so much for coming on. I'm a huge fan of the game\nand the company. Hello, how are you doing? I'm really, really well. Now, Anupam, though\nI'm curious, please tell us a bit about your journey that you took in order\nto get to your current role. I am, two time\nfounder of two big data companies. The second one\nwent on to be acquired by Cloudera. So if you've ever heard about Hadoop,\nif you have ever played with open source, big data platforms,\nthere's a lot you can blame me for. In what works, what does not work. Well, can you tell me also about some of your experience\nwith building AI pilots? Then before Roblox and now at Roblox,\nI know that you mentioned a little bit of it there,\nbut I want to dig deeper. Oh, yeah. So AI, you know, used to be called machine\nlearning before everybody started calling it AI. So we've been doing machine\nlearning for a long, long while. Take Roblox, for instance. We have had a text filter for our safety\nfor years and years where,\nif you and I were texting each other and let's say\nyou decided to use a colorful word, our text filter would in line\nlive hashtag it. Meaning it's bleeping, but for text. And that always used machine learning. It is invoked around\n4 billion times a day. Imagine every one of your text\ngoing through this text filter being filtered out. And that was our biggest machine\nlearning service. Before all of AI\nbecame the rage in the industry. Out of those pilots,\nthen how many of them failed? It's interesting if you narrow down\nthe problem the way I described it. So we are not trying to boil the ocean. We're not trying to do AGI. You simplify, the problem statement rather than trying to boil everything. And so some of the failed things\nthat we have seen is when we try, try to do too much in one go\nbecause we get excited about the technology. You know, you must have heard something\ncalled time to first token. This is all the rage in AI. It's the first, it’s the time that\nit takes to get the first token. I have started calling something time\nto first demo. In AI, building a demo is easy, but never confuse the demo\nwith actual production. Never confuse the demo\nwith actual production. Can you break that down for me\na little more? So let's say you have a video building software\nor you are trying to build photos. One of my AI friends calls it party\ntrick models. Party trick models is you open your phone\nand you say, I want dolphins riding bicycles on Ocean\nBeach in San Francisco. Comes out and it's beautiful. But firstly, it's not useful to anything. It's a proposal. Nothing. Now, if you want to build a real video\nor a 3D world which has Ocean Beach,\nwhich has the fog of San Francisco, which has dolphins,\nit's a much bigger task. So the demo sometimes confuses people. I have other companies where people\nhave gone to the board and demoed something, and the board assumes\nthat it is the full product. We try to avoid that. We try to avoid, irrational exuberance\naround AI demos. Well, then how widespread is this issue\nof irrational exuberance? Honestly, because so many models are now available, so many\nlarge models are so easily available. I think it's become more common now\nbecause you can ask... the model can almost fool\nyou into thinking that you just solved a very complex business use case,\nbut it really hasn't. I'm curious about where does this usually start though,\nwithin the company or within the organization? Does it start in the C-suite or more\nso on the developer level? At some level, it's\nat the developer level, because earlier if you did AI before the large models,\nyou would have to start with the data. You'd have to figure out which neural\nnetwork technique you're going to use, and then you have to figure out\nabout the output. But now, because large models\nare available off the shelf and and many companies are making them\naccessible, your first step is much easier but now all of it portends\nwell for the future. But just because it is easy\nto do the first step, people confuse it with the with the end,\nwith the conclusion of the project. Does that make it almost too easy\nto step into piloting? In some ways, yes. It is very easy to articulate\na business problem. Have a demo ready and in your mind\nyou're now not thinking about cost. You're not thinking about data quality,\nand you're not thinking about user experience. If you take these three away,\nthe project becomes easy. But if your AI model\nis about to curse at you, or it is going to give you factually\nwrong answers, how do you assure that\nthat's not happening? And those are the last 10% of an AI\nproject might be harder than the first 90%. So what else are people missing\nas they start the piloting process? I think, the first one, I would say,\nbecause Roblox is at such a high scale,\nwe have to think about cost. We like to give out our features to\nall of our users and all of our creators. So from day one,\nwe have to think about, publicly. We talk about\n4 billion hours of engagement. So it's 4 billion hours of people\ntalking to each other, people playing with each other,\npeople building content. And we need to think at that scale. So often people will forget the number of tokens\nthat are actually going to be used. And then when you multiply it\nby cost of running it on the cloud, you're suddenly,\nyour beautiful AI project could cost your company $100 million straight up. And the bills are running up the way\ncloud bills do. They start very innocuously, and then suddenly it's a huge cash\noutlay for your company. Okay, you've identified a couple\nof huge problems here, right then Anupam. So I need your help now\nin helping us identify some hacks on how to build something\nthat has staying power. So number one, let's talk about cost,\nokay. On cost, consider whether you really need\nthat large a model. There's a little bit of an ego battle. It's like,\noh, you know, John is using a 100 billion parameter model, but Arvind is using a 10\nbillion parameter model. Oh, obviously\n100 billion is better than 10 billion. Not true. Because if your business problem\nis constrained enough, if your user experience question\nis constrained enough, you can actually work\nvery well with 10 billion parameter model. What happens next? A 10 billion parameter model sometimes is 100 times cheaper than, let's say,\n100 billion parameter model. So it's very important\nto constrain the problem and then, use that constraint to reduce the footprint of your machine\nlearning model. I've see now you've got me in two\ndifferent mindsets though, because if I'm going to start small, how\ncan I start to think about scalability? When I say start small, I don't mean that you should always start\nwith the smallest model possible. You can start with the biggest model,\nyou know, whether it's open source, whether it's your own. Take the biggest model,\nsee if it solves your user's question. Let me give you an example. We started on something called Code\nAssistant. Millions of creators come to our platform\nand they write code. Of course, having a code\nassistant is great, but we started with a very big model. We actually put it\nin what you would call a pilot, saw that your users are developers\nreally like it. Then behind the scenes, because\nwe had a gateway sitting in between, behind the scenes, we changed the model\nto a smaller model and tested it. We changed it to a smaller open\nsource model. So my advice would be go with the big or the biggest model that you can find,\nand see if it solves a problem. Then using techniques like distilling\nor fine tuning and there are many others quantization\nsee if you can make the model smaller. So that's sort of the first step. Gotcha. Okay. So see if I can make the model smaller. Now let's fast forward some. I've got my pilot and I'm ready to grow\nnow, Anupam, I want to grow. So I need a team. How easy is it going to be for me\nto be able to find people who have the right skills in the\nAI space, like right now, today? That's a brilliant question.\nI'll tell you why. Because whenever we think about AI,\nwe think about models. Whenever we think about models, we start thinking about people\nwho can train these models. But what we have learned here is the magic starts a little before, which is data. So preparing data for AI is very different than preparing data\nfor business intelligence. If you remember your business\nintelligence software, what does it do? It creates charts. It creates\npie charts and swim lanes and whatnot. But preparing data for AI is different. You have to create vector embeddings. You have to put it into a vector database. We have learned that right now some of it is art\nand some of it is science. And finding that right mix in the engineer to think about data is sort of the hardest\nskill in the market. I want to give a shout out, by the way,\nto everyone who's listening right now. Especially some engineers\nthat I'm sure are tuning on into this one. I want you to speak\ndirectly to them, though. Let them know, how can today's engineers\nstart learning these skills? If you are a database person\nor if you are data person, start thinking about vector databases. Start thinking about what an embedding\nlooks like. It's not that bad. It's still a table. It's still data. Okay, data stays data. So that's one way you can get in. The second, of course, is learn a few model optimization techniques. Not all of us have to go and build GPT. Not all\nof us have to build these bigger models. If you want to get your\nyour feet wet on AI, go in and just learn these techniques like RAG, fine tuning,\nquantization and just play with a model. You don't have to do the training\nyourself. And the third kind of engineer\nwho will try, we didn't talk about performance as such, I\nemphasize cost, I emphasize data quality. But in the end, when you are typing in\nand your AI is taking too much time to respond, you\nas a user are not going to like it. So what is software about? Since many decades\nago, it's about performance and a lot of that performance\nis still distributed systems engineering. And so if you are a distributed systems\nengineer, you still have a lot to contribute,\nbecause in AI inference, all of these older\ntechniques are coming back. Since you're here, we obviously have\nto talk about your work at Roblox. All right. So in your view,\nhow's AI shaping the future of gaming? Oh, I thought you would never ask. So so, there's a few things that are that are all active simultaneously. So it's a very exciting time\nto be involved with Roblox and AI. So the first one is, of course, creation\nitself. You want to create a game. You come to the Roblox platform,\nwe'll help you with texturing. We will help you with code\nassistance. Okay. Your creation is ready, but now you have to send it out\nto millions and millions of users. In our case, it's\nessentially every corner of the planet. We have about 24 data centers at the edge\nwhere your creation is going to go. We have features\nwhich help you with rendering. As a creator, you don't want to spend\ntoo much time rendering it. So that's the creator. Now, let's say you're a user. Now, I don't know about you, but\nI have a really snazzy avatar on Roblox. It's got a beautiful white coat\nand it's it's got a, you know, weapon\nand a very nice mohawk. Imagine trying to build\nyour avatar used to be painful, but avatar auto setup on Roblox immediately\ngets you avatar to look amazing. So just these three things,\ncreators, users get enabled. Behind the scenes though, one of the biggest areas of investment always has been since Roblox was founded\nis safety. And a lot of our AI,\nI would say almost half of our AI spin is on safety. Whether you are texting a friend, chatting\nwith a friend on Roblox, and whether you can be colorful or not,\nthat's something that our AI helps with. But the most exciting one pertinent\nto our conversation right now is voice. You and I are chatting. This is, you know, a professional setting. If I suddenly used a colorful word,\nI think we should beep it, correct? Sure. Now, do you want to be in post-production\nor do you want to beep it in here? Right. And so our voice safety effort is that, depending on the context, we will actually immediately identify\nwhether our voice interaction is safe or not. And that's been\none of the most successful projects on AI. To your earlier question about pilots,\nI remember the pilot. It seemed very expensive. It seemed the model was too big. It seemed the data quality was not high. In a one year journey. We have addressed each one of these things\nand now the safety group is the biggest user\nand consumer of our AI, platform. I can only imagine the colorful language\nthat we would hear if we just stood outside the door\nduring that training. We had this great demo in which our, vice\npresident of engineering for safety, would be talking to our founder and CEO in the town hall, and it would nudge them\nto be less colorful. So it was a pretty impressive demo. Well, then what do you see coming next\nthen as gen AI gets better and pilots do start improving\nwhat's on the horizon? Firstly, if you live in San Francisco,\nhopefully you have seen these driverless cars. It's amazing that, literally in real time, this car is able to reason about what it is, seeing,\nwhat it should do. And because San Francisco is very narrow\nand steep street, sometimes it has to back away\nto make let a garbage truck go by. So in a way, I feel excited\nthat the future is already here in certain parts of the world. So that's that's part one. Part two,\nI think all the AI excitement today is legitimately about text. You know, I type in something,\nit type something back, but the next horizon is image,\nwhich is already here. People are talking about image. Then we are thinking about audio. Then we are thinking about video. And then we might think about the world\nitself. And for us,\nbecause we live at the intersection of the real world and the virtual world,\nbuilding these worlds in the most efficient way\npossible is a big deal. It takes too much effort for our creators to take what is in their mind and translate it into working code. We want to sit in between\nand let you become a storyteller on Roblox versus today, what you would have to do is\nyou would have to write some code, and you'd have to learn\nhow to, you know, build a Roblox world. Imagine you could just say it and out\npops a Roblox game, and you and I are playing that\nin five minutes. That's the future for us at least. So is there a world post code then? Is that what's on the horizon? It's possible. The beauty about AI today, apart\nfrom obviously what we started with, yes, there's a lot of failures that we will\nencounter like any other innovation. But every three months an entire set of of assumptions get broken\nand we see something new. So it's an exciting time, to be working in\nmachine learning and AI, for sure. Then my final question with that is, with everything\nbecoming so much more accessible, with creating pilots,\nbecoming more accessible, do you think that's going to lead\nto more pilot failure in the future, since people can feel so confident about it and just jump in,\neven without a ton of experience? Or do you think that that's going to\nimprove the quality of pilots that we get? I'll tell you what we saw here. The sophistication\nwill not be in the pilots. The sophistication will be AI platforms will become smarter to figure out that this is not a good use case,\nor that the data quality is not good, or the inference is too slow,\nor it is too expensive. You know how, if you go back to the time\nwhen cloud was new, I could just you know, ask my boss to give maybe, maybe their credit card\nand put it on the company tab. And that's it. That's my cloud pilot. Today,\ncloud has an entire set of disciplines, entire set of process\nto manage the cloud spend and performance. I think the AI platforms\nwill become sophisticated enough that they will catch these pilots. But I think we should let\ncreativity be unbounded. We should encourage our engineers,\nour developers, our creators to do a lot of new things with AI while the platform constrains what's going on. Okay, Anupam,\nthank you so much for your time. Listening to you, it makes me feel like the future\nis going to be super duper bright. But today people putting their blood,\nsweat and tears into pilots that never see the light of day still just breaks\nmy heart as a creator myself. So I've called in my friend\nIBM's Nick Renotte. He's going to help me to understand his point of view as one of\nthe brilliant minds behind AI builds. Nick, welcome back to the show, man. It's really good to see you. Yeah, no, thanks. Thanks for having me. Now, look,\nas someone who's really in the weeds developing individual\nAI projects every day, let's start here. Does it begin\nlike any other creative endeavor? Like, like just a fun idea. The biggest thing that I always think\nabout when I'm designing\nor coming up with ideas is like impact. So if I build this,\nhow is it going to be able to be used? Who's going to be able to use it?\nWhere is it going to go? What's the potential? One of the most popular projects\nthat I actually built on YouTube was the sign language detection model. And there's been other like a ton of other object\ndetection models that that I'd seen floating around YouTube before. But I thought, hey, this one's actually\ngot some, some, some real use and like, maybe I won't push this to the absolute\nNth degree, but if I can give people a start,\nit'll actually help kick people off. And I actually had, a father\nreach out to me yesterday who's actually taking the model\nthat I helped start designing on YouTube. And he's using object detection\nand embedding that inside of a set of glasses\nfor his daughter, who is blind, to help identify obstacles, in a way. So I thought that was a really cool sort of evolution of the project\nthat I sort of started off with. Geez, how validating\nthat must have sounded to you like to know that something that you just dreamt of\non a whim and just started, you know, doing is actually being placed\nin real life application? Congratulations on that. Yeah.\nThank you, thank you. And, I mean, the funny thing is\nthat, like, there's been so many different offshoots\nfrom from that project, there's obviously been others, but like this one because\nit's had that, that, that greater for, for the greater good type feel to it\nor or vibe to it. It's really gone a lot further. I know\nclearly that you have a ton of ideas. They must just like, hit you at all\ndifferent points in time. But when you're trying\nto narrow those ideas down and when you really try to plan a pilot,\nhow do you try to make sure that the pilots\nthat you do endeavor to create actually grow up, actually make it far enough\nto to take root? Yeah, I think I'm going to switch\nspeeds here, right. And then focus a little bit more on\nlike how I do it at work as opposed to like personal projects,\nbecause a lot of my personal ones sort of just go off the wayside,\nkind of like, the, the amazing footage that you mentioned at the start,\nlike they're always on the to do list. Whereas, when I'm at work, I'm a lot more driven\nto make sure that these do grow up. So I stay within inside of an organization\ninside of IBM called Client Engineering. And we actually created this framework\ncalled the Pilot Engineering method. One of the first steps\nwhen it comes to kicking off any pilot is actually looking\nfor a specific business opportunity. And then looking at use case discovery. Those two steps ensure\nthat you're at least going down the right path to begin with. I think we're going to talk about like one of my biggest failures\na little bit later on. But like the reason\nthat that that pilot failed or the project that I was working on\nfailed was because I didn't do that. So I didn't look and identify\na valid business opportunity. I didn't do proper use case discovery. And then most importantly,\nI didn't quantify, the business value. Like,\nhow much is that worth to the organization to solve this problem,\nbecause then they're like, they're actually going to want to solve\nthat particular problem. Like, I always talk about it, or I'll\nrefer to it as the bleeding neck problem. Like if you're next bleeding, you really\nwant to solve that problem, right? Is what we're trying to solve\na bleeding neck problem. So when it comes to to to actually going through that process,\nI think those two steps are critical. And that all sort of starts\nat the initial phases of the project. Right? So to actually doing workshops\nand working with a client like this stuff can't happen in isolation. It's absolutely critical\nthat the when you're looking for that, that that business case\nand when you're looking for the use case that you sit down with the people\nthat are going to be using it, not not just the project sponsor\nor the person funding it, it's like, is this going to be valid to the person\nthat's actually going to be using it in their day to day life? And then from there,\nnot just sort of disconnecting, they need to be critically engaged at every\nparticular step of that, that project. So, once we sort of decide on that, then,\nthen we really go into what we call the co-creation phase. And keep in mind, like co\nis the really important part in that it's not just engineers building stuff\noff on the side on their machine just hacking away. It's building alongside our clients. And then once we've gone\nthrough that process, along with a number of playbacks,\nit's really about transitioning, this off into production\nbecause you've probably seen it before, right, that there's a bunch of projects\nthey start off that they're really great, and then they never\nreally make it out there into the world. And that happens a lot, right? Like there's a lot of developers\nbuilding a lot of stuff and like, there's a lot of pilots being spun up. But if you haven't actually gone\nand established that, that business value looking specifically at a valid use case,\nthen there's not going to be, a bleeding neck\nneed to actually get this into production or actually use it\nwith inside the organization. So, going through those steps,\nthe workshops, the builds, the transition, we bake that into each one of our projects\nand our pilots to make sure that they do grow up. When you mentioned the co part,\nNick, that to me really seems to kind of like sum up\neverything that you shared there, because just listening, for me,\nI'm like, wow, it would be so much fun to brainstorm\nand to come up with different things. But at the same time,\neven though that is such a thrill, that also places so much responsibility\non just you as one person to stay personally motivated\nand to push it on through. But when you're working with the client, like you can't just shrug it on off\nbecause you become bored of the project anymore. So since you can't plan for everything,\nhow do you try to design your pilots so that they can adapt\nto what you can't know? But like at the same time, you can't know\nwhat you need to build into them. So I feel like we're stuck in this circle. So how do you fix it? There is that loop, right? Yeah. Like there's the known knowns,\nthe known unknowns. But then there's always going to be\nthe unknown unknowns, right? This comes with every project, right? It's not just AI projects\nthat that have instances of scope creep where something creeps in and it's like,\noh, this is an absolute critical thing that we didn't mention at the start\nthat we now need to go and handle. Part of good project management\nsort of hedges against that. Right? So like that, like agile project management\nmakes sure that like we're prioritizing to build stuff that is absolutely critical to ensuring\nthat this particular pilot succeeds. A lot of the risk, associated that with\nthat can be sort of hedged or mitigated against\nby doing that use case discovery and working alongside the client. Because really quickly, if the client's\ntesting as you're building, they'll probably point out like, oh,\nwe kind of have that filter there or oh, I need that filter there, or oh,\nwe can't show that data because it's super sensitive and this person shouldn't\nhave access to it. So co-creating, sort of alleviates a lot of that other concern,\nbut also doing playbacks. So whenever I do pilots,\nI try to make sure that anybody that is going to have a potential touchpoint\nor is going to be a decision maker for this potential solution going\nlive, needs to be in those playbacks. They need to be saying what we're building, because you never know\nhow one particular workflow might impact somebody else\nuntil somebody else is there in that room. So, making sure that that,\nthat those happen proactively and not reactively\nis, is critical as well. Well, look, it's funny\nbecause hearing you share all of that, as a listener, I'm like, you know, well,\nit sounds like Nick has it all down. He's got it all together. So how could anything\npositive go wrong like you? No, not at all. What is it like Bear Grylls,\nadapt, overcome, something else, like.... Right, right. So. But I know that that's not true\nbecause you teased us a little earlier\nby telling us that there was a failure. So I'm going to kind of push on the wound\na little bit here, and I'm going to ask you if you can tell us some more about that\nfailed pilot that you worked on. Yeah, yeah. Thankfully,\nthis, this, this wasn’t a pilot at IBM so that there's no brand rep damage\nlikely to occur as a result of this. A while ago,\nso I was just coming out of university. I was doing my master's. And as part of that,\nwe had a, like, a startup incubator. And then our startup got picked,\nto go into the incubator and, and to, to, to build it out. And the whole premise of it was like\nwe were going to be building an application or like a solution to help\nincrease transparency of patient journeys throughout a hospital,\nbecause like one of the big factors when you're inside of a hospital is like,\nyou don't really know what's happening and you don't really know\nwhat's going to be happening next. And that can really increase the stress\nand concern, when you're going through that process. So you're getting treatment. Now, I thought this was a massive problem because my girlfriend\nhad just been through hospital. She was going through surgery,\nand it was an absolute nightmare. Like we went into the hospital ward\none time and they're like, who are you? Like, why are you in this bed? And I was like, as if it's not enough\nto know what it's going to be happening to us at that particular point in time.\nThey don't know who we are. And so I'm like, like,\ndoes anyone know what's happening here? So I'm like, oh, this is a great idea. Like, we can help improve transparency\nin hospitals, improve patient experience. And that has a knock on effect. There's a bunch of research studies that\nlike improving patient experience ensures, like reduces the likelihood of\nreadmissions, it improves recovery rates. It and reduces like a whole ton of, costs associated to that hospital\nand providing care for that patient. And I'm like,\nokay, let's build a solution for this. Like I'm like, I'm I can do data science. I can build machine learning models. This is awesome.\nWe're going to bake it all into it. So we build for like three months. Right. And we just keep building like\nwe have a meeting with the with the like. We actually got a hospital on board\nto help us out with this. Right. Or like to,\nto potentially take on the solution. So we have a meeting where like we,\nwe're thinking about building this like yep, great. Cool awesome. Build it. So, heads down we build for like\ntwo months, like just coding. Like, so I'm working my day job\nMonday to Friday and then going to like the incubator from like 6 to 9 p.m.,\nlike Monday to Friday. And then I'm working Saturdays\nand Sundays, building this up with my co-founder, build it, build it,\nbuild it for three months, and I'm like, hey, we should really\nshould be showing this back to the client and going,\noh, like to the hospital. Like, hey, what do you think about this? And at that time we had,\nlike a startup advisor, like he was like, he was the one that got us the contact\nwith the hospital. And he's like, hey, at this point, right? Like, you've built more than an MVP. You really should be looking to,\nto get some sort of funding or like, like get the client\nto start paying for licenses, even if they're just token licenses\nand like lifetime licenses just because they're your foundation\nclient. I'm like, okay, great. So we've got a product. We, or a minimum viable product. Like it's enough to charge for. So we go to the client like, hey, we've built it, we can hook\nin, we can do all of this stuff. We went through a ton of regulation\nto make sure that we have it, and now we're like,\nokay, like we've built it all up. We're going to give you\nlike unlimited licenses for it for the entire lifetime,\nand it's going to cost you X dollars. And the client's like, yeah, but like,\nI don't know if we really need it now. And I’m like, what? Like, what do you mean, like, I'm like,\nI was still like, I didn't have as much experience in terms\nof, like, selling and building startups\nand doing like that. That whole process, and just sat there\nin that room and I'm like, I don't even know how to interpret that. Like what? Like you don't like there's like, you\ndon't need it and you don't need it now. So I like eventually\nI got like I gathered myself and I'm like, okay, when,\nwhen do you think you would need it? They're like, maybe you should go back\nto the drawing board and like, review it. And, I was just like, like eventually I\nrecognized I was getting the cold shoulder and I'm like, oh, this is just like,\nI, we just wasted so much time. Like, like three, four months of our lives\nbuilding this, like, on top of, like, the stuff that we did\nin the incubator prior to the hospital. And it's just like, exhausting. Like I was like, I'm gonna,\nthere is no value, right? There's opportunities\nand there's lessons learned. But like at that point in time,\nlike I can still see it. Like I was sitting in that, that, that, that like a demountable room because\nthey were going through a reconstruction. Or like construction\nof the, more construction on the hospital. And I was like, oh, man, I can't believe\nwe didn't validate this way more. I can't believe we didn't\nsit down with them and like, triple check that this is what they wanted,\nthat this is what what they were going\nto be able to pay for. And I've just gone, like I could have\nhad like, mitigated so much of this well ahead of time instead of waiting\nuntil the end to, to present that. But I mean, you live in you learn, right? That hurts. You just, and you just painted that room for us. You dragged us back into your trauma.\nNick. Thanks for that. I'm assuming that the reason\nthat you can remember that one so well is because there are quite a few pilots\nthat you've worked on that do succeed, right, that have succeeded. So I know you've got a bunch of those. What made those pilots\ndifferent than than this one? Because from where I'm sitting, it sounds\nas though you were able to identify, like maybe a commitment going forth\nwith everything else that you worked on. Was that one of the first things you did? Yeah, definitely. So like when we spin up pilots\nnow, there's a whole process, right? It's not just like, hey, there's a\nyou want to do a pilot? Cool. Let's go do a pilot and start\nbuilding. Right. We actually go through, ways of working. So like we set up\na document of understanding, so like what we're going to deliver,\nwhat the commitment on the client is. So, like,\nwhat are they going to be able to do? Do they have the sufficient amount of time\nto test this. Because again, it's co-creation,\nnot just IBM creating. Right. Like we're trying to build stuff\nto, to help their organizations. Close engagement with the client\nis absolutely critical. Like if I look back on like my startup,\nlike we got data from the hospital, but it it was like, I want to say\n1% of the amount of data that we needed. So ensuring that you have the right data\navailable, all the right data prepared and the right data\ncollected is absolutely critical. I want to say that, like a lot of the\nthe pilots that we do now are really successful\nbecause of the people, right? Like we have the right people\nin the right room. And that's not just IBMers,\nbut that's also like the client coming together with their right people\nthat are going to help push this forward and make sure that it's successful,\nbecause ultimately, like every pilot ends\nwith some sort of presentation to an executive or like a funder\nor like an executive sponsor, having everyone in the room\nand making sure that the like the right people are in the room ensures that,\nlike when we go and make that pitch that, that, that, that they know that, hey, it's not just something that some,\nsome random group is gone and built. It's like, this has been a collective,\nlike we've actually gone, gone ahead. We've scoped this out properly. We found a problem\nthat needs to be solved, and we've made sure that that\nthat it'll work and it'll deliver the business value\nthat, that that's needed. I imagine right now, I hope that\nthere are a bunch of developers that are listening to us,\nlistening to you specifically right now. Can you give them one word of advice as they think about whatever pilot it is\nthat they're dreaming of giving them? Just at least one word? My personal favorite is fail fast. Build a prototype as quickly\nas you humanly can and validate it. Right? So like build it, go and show it to to\nthe person that you think is potentially going to be using this or buying this. So that's really quickly going to validate\nor invalidate what it is that you're building. That, that\nthat's probably a big one around startups. Right. But if we had built in what we built in\nlike, two ways before,\ninstead of getting way too far down into the MVP and said,\nhey, will you buy this right now? Or like Will, is this exactly\nwhat your organization needs? And really quickly, it's a qualifying\nstatement or a disqualifying statement? Super early on. So, failure is not really failure, right? It's just, it's the lesson learned. Yeah. It sounds like you fell in love\nwith your pilot, Nick. Oh, man, 100% I was committed. I was like, this is this is so cool. It's going to improve people's lives. It's going to make hospitals way better. Not the hospitals are great\nanyway, but, like, it's gonna just get, it’s world changing. Yeah. Like, look,\nI'm still kind of vested in that idea. I probably need to go and do a ton more research\nand approach it from a different way. But now, like, there's so many other problems that I can solve\nthat I've got deep expertise in, like, I'm not a doctor,\nI'm not had like I wouldn’t, like I don’t know\nthe first thing about patient treatment. But I was like, I'm vested in this. I want to solve it. Look,\nand you clearly have a ton of free time, so I'm sure that you'll pick\nthis one up in your spare time, Nick. Yeah. Just like I'll do it between, sleeping\nand, and working, right. Well, with all that then said,\nthank you for squeezing us on in then within your time, I really do appreciate\nyou getting on here, enlightening us. It's always a true joy to speak with you. And also thank you again to Anupam. This has been a fantastic episode\nand that's it for today's episode, so we appreciate you all\nfor listening as always, and we will see you back here\nvery, very soon, I promise."
}