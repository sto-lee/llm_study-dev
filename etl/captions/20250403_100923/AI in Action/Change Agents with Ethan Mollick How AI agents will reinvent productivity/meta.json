{
  "video_url": "https://www.youtube.com/watch?v=VCA7wdZBuUE",
  "video_id": "VCA7wdZBuUE",
  "title": "Change Agents with Ethan Mollick: How AI agents will reinvent productivity",
  "upload_date": "20241203",
  "channel": "IBM Technology",
  "duration": "18:13",
  "caption": "AI is hyper persuasive. What does that mean? It's innovative.\nWhat does that mean? That, you know, in an ideal world,\nthat helps us as humans thrive. What I worry about is organizations\nthat aren't thinking about these issues. You don't have to look far to find news\nabout business leaders and employees exploring how generative\nAI can help us work better, work faster, work more efficiently. But real talk. Are we actually getting more productive? Or is this\njust the story we're telling ourselves? And what's up with all of the names? Copilots, assistants, agents, LAMs? It would be great to finally get\nan answer, simply speaking, to what's the difference\nbetween AI assistants and AI agents? And where should organizations\nand employees be directing their attention and resources\nto really accomplish efficiency? Well, today I'm joined by Ethan Mollick. Ethan is an associate professor\nat the famed Wharton School of Business, where he studies and teaches\nentrepreneurship, innovation and AI. And he's the co-director of the Generative\nAI Lab at Wharton. He's also a popular author and blogger,\nand his latest book is Co-Intelligence:\nLiving and Working with AI. Ethan, thank you so much for being here. It's a pleasure. Thanks for having me. When it comes to AI based productivity\ntools, kind of feels like\nthere are too many terms out there, right? So let's start with\nhow do AI agents differ from, say, AI assistants, copilots and large action\nmodels? Ethan, I need you to help us\nto get all of these names straight. Well, it doesn't help that even the term\nAI is, like, in dispute, right? It meant something very different prior\nto 2023 than it does today. So you're not alone, right? The easiest way to think about\nthis now is probably to think about what you've been using\nwhen you use ChatGPT is you're using a chat bot\nor an assistant it’s sometimes called. Then when you have a\nAI tool integrated into your software, like an AI help bot or, it's\na tool that helps you, you know, finish your graphic design or something\nthat's usually called a copilot. And then agents are autonomous AI systems\nthat will go off and do work on their own and set their own goals\nand just perform autonomous work. They're not there yet.\nThat's what everyone's aiming for next. And large action\nmodels are a new, made up term for an AI that can actually do things\nlike if you say, set up an appointment, it can actually act on your phone\nand set up the appointment for you. Okay, so there are some real distinctions that you just drew\nin between each of those. So does the name really matter after all? If you're the one who's building it? The one thing that I think we've learned\nabout AI over the last couple of years is AI\ncompanies are terrible at naming things. I mean, who would have ever called ChatGPT\n4.0 and Claude 3.5 sonnet and you know, like Llama 3.1 405 B, like,\nthese are things I have to say with a straight face now. So like,\nI don't think we should worry too much about the names because they're\na complete mess and it is confusing. I think that creates barriers\nthat aren't necessarily there. Like these systems\nare not that hard to use or to work with, and it just sounds harder\nthan it is when we use all these names. You've been doing a lot of research on the practical implications\nof generative AI, often hands on. In a recent talk,\nyou cited an experiment using gen AI that resulted in a 40% increase\nin quality of work. Can you tell us a bit\nabout that experiment? And then I also want to know what type of gen AI was used for this\nand what does quality mean? It's a really good question. So the particular study you're talking about is one\nI do with my colleagues at MIT, Harvard and the University of Warwick,\nwhere we went to Boston Consulting Group, and they gave us\n8% of their global workforce. And we did an experiment. We developed 18 business tasks ranging\nfrom like consulting, standard consulting and now analytics\nand marketing and persuasion ideation. Some of the consultants got access to GPT\n4, some did not. The people who got access to GPT\n4 had a 40% improvement in quality, 26% faster,\nand got 12.5% more work done. So when you talk about the amount of work\nthat's being done, can you still break down\nhow does that quality figure into it? Sure. So we found this 40% quality increase that matches a bunch of other work\nthat shows that when an AI does work, it produces pretty high quality\nwork out of the bat. I would say solid A-minus from a lot\nof the most advanced models out there. Not always a plus, but but solid work. And so we found that\nit increased the average quality, especially for low performers. So low performers\ngot the biggest boost in their quality. High performers got less of a boost. So this is an experiment. So now how can real life companies achieve\nsomething similar? What key actions did\nthey need to take in order to get here? So that's\nwhere it gets really interesting. We are still seeing these kind\nof large scale improvements, but they're at the individual level. So individual coders who use these systems\nare much more productive. And by the way, everyone's already\nusing them like penetration rates, from what we can tell from early studies,\nlike there's a study in Denmark of all places\nfrom January of last year that shows that, already 65% of marketers, 64% of coders, you know, 35% of lawyers\nwere already using AI at work. The productivity benefits\ngo to the individuals, though, not to the organizations. To have the benefits flow\nto organizations, organizations need to think hard\nabout how they're incentivizing people and how they're building\norganizational structures to succeed. Ethan, how can businesses empower these productivity gains\nthen, rather than having people hide them? Is reward systems the answer?\nSo it's a few things. Thinking about rewards is a big deal. Why are people incentivized\nto show you what they're doing? I've seen organizations give out $10,000 prizes once a week to\nwhoever has automated their job the best, but even just doing things\nlike having the company executives show you they're using\nAI can help make this different. And then there's\nthe organizational structure piece. What do you do\nwhen you're more productive? What am I supposed to do with my time? That feels like a big question\na lot of companies aren't asking. So are there any other recent studies\nthen that you want to name drop? There's a lot of interesting work. We've got a repeated set of studies\nthat show that AI is very creative. So my colleagues at Wharton run a famous\ninnovation entrepreneurship class. They had the students in class\ngenerate 200 ideas. They had the AI generate 200 ideas. And they had I'd say judges judge\nthe ideas by their willingness to pay, how much they'd pay for the\nthe product that was created. Out of the top 40 ideas by willingness\nto pay, 35 came from the AI, only five from the humans. So we're already seeing higher creativity. Similarly, if you get into a debate with an AI, you’re 81.7% more likely\nto change your view to the AI’s view then if you get to a debate\nwith an average human. So these systems\nare already extremely powerful. I'm trying to figure out\nif I should feel encouraged and empowered by that research,\nor if I should feel intimidated. I think a little of both. I mean,\nI think this is empowering and powerful, but I also think we haven't started\nto really deal with the implications of all of this. Like AI is hyper persuasive.\nWhat does that mean? It's innovative. What does that mean? That, you know, in an ideal world\nthat helps us as humans thrive. What I worry about is organizations\nthat aren’t thinking about these issues. Okay. So as long as the organizations\nare at least having this knowledge, that's a strong foundation\nfor them to begin to think about it. And thinking about actually changing\nthings like, what are they going to do? Like, I mean, look, the number one thing\nthat people tell me they use AI for secretly inside their company\nis writing all their performance reviews. Now, performance\nreviews are really annoying to write. They're meaningful\nwhen they're done by human beings. They're not meaningful\nwhen done by the AI, but it's the first thing\npeople automate, right? Like, similarly, like,\nI actually I had a great experience. I had to write letters of recommendation\nall the time for people. And the whole idea of a letter\nrecommendation is I purposely set my time on fire as a signal fire,\nthat I care about someone, right? Like I'm like, I’m going to spend\n45 minutes writing a letter for you. I have to read all of your stuff and your resume,\nand then I write a letter for you. And the letter doesn't matter. It's the 45 minutes I set on fire that’s\nan indicator that I care, right? Now, here's the problem. If I just put the resume in, the job\nthey're applying for, and the letter, then I get a much better written letter in 30 seconds\nthan it would take me to do in 45 minutes. Do I turn in the better letter\nthat didn't take the time to write. Or do I turn in the worst written letter\nthat took me 45 minutes to write? If you ask your students, they'll say\nlike, turn in the meaningless letter because it's better written\nand they'll get the you know, get the job more likely. That starts to challenge\nhow we view things. In fact, I had a student send me, for the first time, as when they asked\nfor a letter recommendation, they sent me a prompt that they just\nsaid, paste, this is into GPT four. It use this to write the letter. No joke. Did\nthat student end up getting the job? They did, yes. Well, that's a good letter. Well done. So based on where we are right now,\ndo you think AI agents are the future of productivity? So my book is about Co intelligence,\nthe idea that people working with machines do better. I think that that is still very relevant. I think if you can figure out a way\nto work with an AI, you do better, right? Agents are a different breed, right? Agents are the idea that I give an\nAI an assignment. Write me this code to do this, do\nthe market research, generate the report. Come back to me. It's almost like\nwe're with the contract worker. So all the AI companies think that agents of the future,\nwe don't know yet whether they are or not. Where do you sit on that? Based on what I've seen for other agents, I think they're going to be\na very big deal. I think assigning a tool to go out\nand do something in the world. I've already been using AI coding agents.\nI can't code in Python. I do a few hundred Python programs a week\nnow because the AI does it for me. So I actually think agents\nare going to be a very big deal. I mean, I'm going to put you on the spot\nhere. Can you give me a specific year\nor maybe like a range of time that you think it will take\nfor the future to be here? I would guess 2024 if I had to guess. 2025 on the outside. Okay, great. Along those lines too,\nI'm very curious about what will AI agents end up doing for us\nor with us that they aren't doing yet? Like, what are they lacking? Right now, when you use an AI system,\nyou have to direct it, right? It's designed to be a co-intelligence\nto work with you. I think that that is very different than\nan agent that just does the work for you. If I want to write a piece of code\nor write a document, I'm going to give the document to the AI. It will give me feedback.\nI'll give it back information. I might have to paste in some research. I'm directing the AI. With an agent based system,\nI would say something like, do all the market research\nyou need to, go out into the world and collect the data\nyou need, then write our initial draft, you know, simulate running,\na bunch of different people reading the draft, make changes and updated,\ngive it to me when it's done. And, you know,\nalso make sure it's on the website and well formatted\nand figure out how that works. And, you know, read up the latest research\nto make sure everything's up to date. But is this something that an LAM can start to solve rather than an agent\nto go back to our name conversation? So LAM is a little bit vaguely\ndefined still. But the way I understand LAMs are large\nlanguage models that could take action. So the most common version\nis like on my phone, I can ask the the large language model\nto do something. That is different from the agent because\nit doesn't require full autonomy, right? An agent is has autonomous goals\nthat it seeks to pursue as it wants to pursue them. While an LAM would be more like\nthe example of like, you know, telling your coffee machine\nmake me the perfect cup of coffee kind of set up, and it would push\nall the buttons for you to set that up. But it feels like gen AI is something\nthat people just need to dive in and start getting their hands dirty. What should companies be experimenting\nwith right now to get productive? The R&D process inside most companies,\nnot for their product, but for their own process, has largely been outsourced to enterprise\nsoftware companies like, you don't do the work yourself. You have, IBM has been thinking hard about\nthis problem and brings you a solution. And I think that the issue is, is that that's left a lot of companies\nwithout a lot of R&D bones, right? They're not used to think about\nhow to actually own, process or approach. They build good products or,\nyou know, services or solutions, but they're not thinking about how do\nI fundamentally change my organization. And I think the real key\nis experimentation. What is AI good for it? You're gonna have to figure that out. And the people that figure it out,\nor the subject matter experts inside your own company,\nthe people who actually do the research today,\nwho are using the job this all the time. So you need to empower everybody\nin your organization to be learning and testing in an ethical, legal way,\nbut not so constrained that they don't get anything done. What are Ethan Mollick’s top five ways\nthat Ethan Mollick stays productive? So I differentiate in both the book and our study between what\nwe call a cyborg and a centaur model. So a centaur is like an AI model,\nlike an AI approach where you like half person, half force,\nyou divide the work up to like, I like to do analysis,\nyou do the emails, I divide it that way. Cyborg work is more blended. You do the work with the AI back\nand forth, throwing off individual tasks. So for example, things\nI've done in the last day we were developing a logo\nfor a new internal project. So what we did was we sat down with Claude\nand said, here's the concepts we want to get across the logo, draw\nan image for us on the logo, try it against a blue background.\nWhat if this was more rounded? Can you think of a few other ways\nto do it? Another case was like,\nhey, I've got this document. I need it to be 50% shorter, can shorten it down without\nremoving any of the important context. There was another case of like, you know,\nI read this academic paper, I'm like, I think I get it. Can you just make sure this understanding\nis correct? Like so\nlots of little use cases all the time. Well then is there a world\nwhere you OD on AI? I mean, I think it's the same danger\nthat we have of OD'ing on our phone. Like there is this kind of like,\nwhat is human? When is it inappropriate to do?\nWe haven’t divided those lines yet. AI is a very profound technology,\ntechnological change. We call these kind of changes\ngeneral purpose technologies. They affect everything in our world. So the internet\nand the computers were one right? It took a long time to play out,\nelectricity before that, before that steam. So they have lots of varied effects. Some are good and some are bad. And we're going to watch these things\nplay out. So there's so many areas where\nusing too much AI is going to be harmful. There’s going to be areas where AI is\ngoing to be transformative in good ways. And we need to play this all out.\nI want to do a lightning round. Are you down with that?\nI'm always ready. Yep. All right. So yes or no. What would you let an AI agent do for you\ntoday? Plan your next vacation? Yes or no? Not yet. Not yet. Okay, okay. Be your manager. Not yet. Give you a health diagnosis. As a second opinion? Definitely.\nBut not as a first? I mean, I've got access to humans. My standard is always best available\nhuman. What's the human you have access to? And are they better or worse than the AI? AI is the cheapest\nsecond opinion in the world, and most of the studies show\nit's pretty great at medicine. I still wouldn't,\nyou know, I'm not going to tell you out of on a podcast that like, trust the\nAI rather than the doctor. Although I spoke to one of the most famous\ntherapists alive today, a guy named Marty Seligman,\nwho invented positive psychology, and he says that the\nAI is better than him at therapy. So, you know,\nyou draw your own conclusions. What about evaluate your performance? I absolutely use it for that today. Yeah. I was going to say if you said no\nfor that one, I was going to call you out. It's like you use it\nyourself. Yeah. All the time. Yeah. Of course. How is this what would you what would\nan outside person say about this? What would a high school student\nsay about this? What when someone is really critical, say,\nall the time. Can you complete this sentence\nfor me: in five years, AI agents will... Be ubiquitous in that\nyou will see them anywhere you're online. You're more likely\nto run into an AI agent than a person. What do you think is going to be the most unexpected place\nthat we run into an AI agent? That's a tough one. I mean, I like, by the very nature,\nbe unexpected. I will tell you the unexpected place where\nI think there'll be the biggest delay. I think teaching is not going to change\nas much as people think. Classrooms and how we teach will change,\nbut we're not going to replace teachers with AI agents, but we will supplement\nthem with AI tutors and things like that. I think you're going to see AI agents\nin more high end jobs than you think. I think a lot of first round legal work\nmight be done by AI agents for example. How did you use gen\nAI recently on the job, and did it make you more productive? As academics, you also review\nvery high end academic papers. I always review the paper myself,\nbut afterwards I give it to the AI and say,\nwhat would you add to this that I missed? There was a flaw or issue\nto improve the paper. It does a great job with that. That's very high end PhD level work. I like that.\nWhat would you add to... okay. Thank you. I'm\ngoing to use that prompt myself. Appreciate you. Also, does it matter if productivity increases\nif we're focused on the wrong things? Because how's gen\nAI gonna help us with that? So first of all it is a pretty good\nadvisor and manager. So it might help us with that. But I agree, like part of the moment\nrequires us to really think about work in a deeper way\nthan we're used to thinking about work. We need to be thinking about like,\nwhat is it? Why are we doing\nthe things that we're doing? What parts of the process can be improved\nor place changed? Really big set of questions. All of this builds up to an overwhelming\nidea that AI is going to be your coworker. What are the things that our listeners\nshould go do right now to be better at work? So I have four rules in the book,\nand I stand by them because like, even though I wrote them like a year\nand a half ago, people have been telling me they work. So the most important is just use\nAI for everything. Like, bring it to everything you do. Everything legally\nand ethically that you can, you know, I don't know if you used it before this podcast,\nbut I would, if I was in your shoes, I would be like,\ngive me some questions to ask. Then I'd be like, all right, let's\nrollplay back and forth some interactions. Then I'd take this transcript and say, what were the most interesting nuggets\nwhere I might make cuts? How would I summarize this down? How can I turn this into a digestible\nformat for different audiences? And then I might say afterwards,\nlike, well, how do I email all the people in my team to let them know what was good\nabout the podcast or not? You know, what questions should I redo\nor do differently next time? I would use it for absolutely everything. Absolutely everything. And that's how you learn\nwhat's good or bad, because it's going to be good\nat everything. It's going to suck at some stuff. So you need to figure that out\nby using it. Second thing is just to realize that\nit's going to do part of your job for you. That's not the end of the world.\nJobs are bundles of tasks. We lose tasks all the time. Like, I'm a professor, by the way, out of the 1016\nmost affected jobs by AI, according to most of the studies\non this, business school professor is number 22.\nSo I think about this a lot. And like my job is going to change, right? Like will grading be done with AI?\nWill other stuff... but like I'm still hopefully\nto be talking to you here. So what I do day to day\nmight change, my core job doesn't change. So you want to think about doubling down\non what your best at. Because whenever your’re best at,\nyou're almost certainly better than AI. Third thing, don't make prompting hard. Just talk to the AI like a person. Tell it what kind of person\nit is, and you're 90% of the way there. And then my last rule is this is the worst\nAI you're ever going to use. Ethan, you mentioned that\none of the things that you do before you publish a paper is you ask,\nis there anything that I missed in here? So now I'm going to ask you, Ethan,\nis there anything that I missed, anything that you wanted to cover\nthat we did not mention today? I would say that\nI think these were really good questions. I think that the real issue is this gap\nbetween individual and organizational. And my biggest concern\nis that organizational leaders aren't getting it, right? So there's huge transformation\nhappening under their feet. Organizations are getting filled\nwith secret cyborgs who are doing all their work\nwith AI and not telling anyone. And if they don't realize that, that is\nboth a huge risk and a huge opportunity, and if they only treat as a risk,\nthey're going to lose. This has been such a tremendous\nconversation. And again,\nI really appreciate you for joining us. For those of you\nwho are watching and listening along, please let us know your thoughts\nin the comments below. And absolutely stay tuned to this feed,\nbecause we've got new episodes biweekly on Tuesdays. We'll see you soon."
}