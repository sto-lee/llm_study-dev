We all
have something we hate about our job. Those time sucking tasks that take you
away from actually getting your work done. I know you're thinking about them
right now. But what at the tasks that you dread
could be handled not just by someone else, but by AI. Welcome to AI in action. Brought to you by IBM. I'm Albert Lawrence. I'm here
because I'm a learner. I'm a doer. I look at a big picture,
and I can't help but start asking exactly how does it work on the inside? On this podcast,
I'm going to be joined by AI experts, technologists and business leaders alike
who are really going to help us to get beyond the fury of AI and into
how we actually put it into practice. We're all starting to see more and
more stories about AI powered outcomes, but exactly how do I get to
those outcomes for my business? What are the actual steps
involved in changing not only my IT tools and infrastructure, but
also my business processes and culture? Mainly, how do I make AI I work for me right now. So let's do it, shall we? Today I'm joined by Jessica
Rockwood and Morgan Carroll. Jessica is VP client engineering at IBM. Welcome, Jessica. Thank you. Thanks for having me. Glad that you're here. And my other guest is Morgan Senior
AI engineer in client engineering at IBM. Welcome, Morgan. I'm excited to be here. I bet you're wondering how I chose you
for today's episode. Well, it's
not because your work is boring. Because it's not. But it's because you work
to make the boring stuff easy. And IBM client engineering is all about
making your AI dreams a reality. So let's take a look at a few places
where attention to detail, empathy, and responsiveness could make or break us
if we're being for real for real. So first off, I'm very curious. Look, people already
don't have enough time to do everything at the quality
and the speed that we expect every day. Work just seems to have gotten
more complicated. And I'm not alone in this. So how do you use AI to do
the boring stuff that you'd rather not? Jessica, let's start with you. For me, it always comes down to what are the things I hate doing
because they're repetitive. Quite frankly, I don't have to use
that many brain cells to do it. It's all the preparatory work. So every week I take a look at
how are we doing as a business, what are we doing in the team? Are we making progress? I can spend hours
just getting data together and trying to do,
let's say, the first pre-processing. If I can have I do that in a few minutes,
that actually gives me a few hours to do the critical thinking,
to think strategically. What are the next steps to take? I was telling Morgan earlier,
I would love that every time I look at some data and I think, ooh, I wonder
if there could be AI that goes and finds the right data, does the processing,
and gives me back some analysis. I now have like super powers. And that
time is that's like the most valuable. invaluable, yes. And what about you, Morgan? Okay,
I hate to admit it, but writing emails. I have a I'd rather be writing code. I have got, like, five points. I need to make it an email, and I'm like,
okay, now how do I phrase this? So it sounds appropriate? No, I'm just going to let I do it. For me. That's going to save me so much time. And in addition, code generation actually,
which is really interesting. Typically I'm like,
how do I write this function in Python? Maybe I don't want to go to the documentation,
I don't want to read the documentation. But with code generation I could say, hey,
how do I do this? How do I write this function in?
But there it is. I look like I already have a very clear
idea of who I'm speaking with today. Now. You just admitted you'd rather
be writing code than writing emails. So. Okay, we love it.
You're in the right gig, then. I think of Morgan's example
about getting a first draft, whether it's email or code or, let's say,
a history project. I was working with my daughter. She needs to come up
with a lot of different facts to support a thesis,
and she hates drafting anything and leveraging a search engine,
going out, pulling back all sorts of forms of information
really accelerated her progress on it. She still had to assess
what the search engines found, because we all know
there can be some fake news out there. You need to kind of do a bit of analytics
to understand the source of what's come back, should you trust it? But by being able to pull that together
in seconds, you actually can make a deadline. And that's what matters. We love it when they can make a deadline. Awesome. Congratulations to your daughter. Thank you. Now, but when we're thinking about these kinds of solutions
that both you and your daughter are using. I'm curious about the build behind them. Can you take me a little bit into that,
Morgan? Yeah, definitely. Everything starts
with the user, obviously. So we need to think of what
is the user experience going to be like. So what we want to start with
is sort of a conversational flow like hello user, how are you
come up with a persona maybe for the bot, which is my favorite thing
like Barry the bot, a little alliteration. and then we want to gather data
from the user, obviously. And at some point we're going to call out
to a large language model, we're going to take all of this
data and say, hey, here it is. Do something with it. Summarize this for me,
get an answer, it's going to come back. And then we present it to the user. So it's overall
a relatively simple process. Okay I mean you made it
sound really easy okay. But but I know that it really
can't be as easy as as you made it sound. So I'm curious about what problems though
the companies are coming up against when they are trying to figure out
how to make these a reality. Well, so I think one of the biggest ones
I see is how do you customize? So I think what Morgan took us through
is what I would call the standard. Right. Like let's say 80% of the time, yeah,
we can have just this back and forth flow. But what happens when you have a problem
or what happens when someone maybe is going to ask a question
of a virtual assistant It's never seen before. We all like to think
we're a little unique. We're a little different
than everyone else. And that's,
I think, where the challenges come. It's like, how do you figure out for
the edge cases to get the same response, the same experience
as if it was the common interaction? That word interaction
is really ringing for me right now, because I notice that both of you are
speaking of these as virtual assistants. Nobody's saying chatbot. What? What? Is that an intentional thing? Yes, absolutely. The reason we don't say chat bot anymore
is because we're not just chatting
with the virtual assistant. This technology is assisting us
with various tasks. So it's not just like,
hey, give me this information. It can, look up account information,
maybe fill a prescription. The options are endless, honestly. And especially that taking actions
associated with it. So I think most of us would think about
an assistant helps you do things. They don't just talk to you. Okay, so look, I think we can all agree
that we could all use an assistant, use some additional assistance. Right. And that's whether we're a big company
or whether we're a smaller company. But what is the data foundation
that you need in order to make AI I work for you. Can the small companies access
it just as much as the larger ones? That's
probably the thing I'm most excited about. With generative AI,
we're able to leverage foundation models, which are built off
of an incredibly large corpus of data. And so now when you're the smaller company
and you have a smaller amount of data to start with, you take advantage of everything that was already trained
into the foundation model. So we've lowered the bar. It doesn't take terabytes of data. In fact, it might be something
as simple as 3 or 4 questions and answers. And that alone can get you started. So in thinking about that,
if even the small companies can really tap on in and use a lot of the intelligence
that's already been formulated, the LLMs, why is integration a relevant thing? Can somebody just kind of like, grab it all from one source
and plug it on into their system? Not necessarily. So there are and integrations
are my favorite topic to talk about. So there are a number
of different sources. Maybe you have a database
that has all of your customer information or you've got an ordering systems. I always like to use the flower shop example, so maybe we have our inventory listed in a certain place, customer information
in a certain place, location information. If we're doing deliveries, you can't just kind of copy and paste
that into your virtual assistant. You have to work with integrations
which connect your virtual assistant to all of this data so that you can use it
in your virtual assistant. okay. Okay. So you're reaching into different sources, all in order
to still connect with your one main task. So even if we're just asking
maybe one question, the response might be pulling
from several sources. Yes. And I think it's partly about customizing. So when you interact with a virtual agent,
you want it to know who you are. And to have all the right context. And then I think the other integration Morgan spoke to is when you're going
to take that action, that workflow might be in a different system
or a different application. And so it's really it's
not just integrating the data, it's integrating the tools or the actions
you're going to take as well, making it a seamless journey throughout. So when I look at my phone,
when I look at my devices, I see that I've got all sorts of different
like virtual assistants I've got, whether
it's like my calendar app over here or whether I've got
another scheduling app on over here. How in the world can
all of those different spaces be woven together and integrate to just be
one super duper virtual assistant? I mean, again, as your assistant, I've got my work calendar,
I've got my personal calendar. I need to know when to take my dog
to his doggy play dates, but I also need to know
when I'm traveling for work. I want to see everything in one location,
so he or she is reaching out to all of these different places
and grabbing all of your data. So it's connected to maybe my work
calendar. It's also connected to my personal
calendar, it's connected to my email, and it can consolidate
all of this in just one place. So if I say like, hey,
what's going on today? Okay, let's give you a summary. I just pulled your email, pulled your calendar, checked on Mr. Hubble, the dog. Now, we're going to put all this together and say like,
okay, here's a summary of your day. And I think the other thing
we're also seeing is many of the applications are starting to figure out how do we
proactively build those integrations in. I did a prescription online
refill the other day, did it through virtual assistant.
It said it's done. It then sent a text to me with the time
to pick it up, which created an entry on my calendar and a reminder
to say, like, you got to still pick it up. And so I think to your point, it's
either from the assistant outwards trying to engage and connect
and integrate, but also as we build these applications, we need to be thinking
about those touchpoints and how we proactive
send information to be included. I hear you, Jessica. So but Morgan, how do you go about
actively building these integrations? Yeah. So let me give you an example
for what I do specifically. I will first build sort of a dialog in a tool that we have called watsonx Assistant. So that's just the base like, hello,
how are you? How can I help you? and then I will add something called
extensions, which are the integrations. So for each data source
I might have a different extension. For instance, to reach out to a calendar,
I've got a calendar extension. if I have a data repository with all
my documents, that's another extension. If I want to reach out to a large language
model, another extension, and then in the dialog itself
in assistant, that's where we kind of bring everything together and navigate,
you know, how to guide the customer. But when we are thinking about all of
the different sources that are out there, this is where I can start
to get a little bit intimidated from just keeping it real here. How can you make sure that you're actually
finding the right AI model, and how do you start? First and foremost, it's
about finding a trusted model. So we know that there's an incredible
amount out in the open source world. There's a lot of proprietary models
as well. So first and foremost
you want to find one that you trust. and that's looking at what information
is shared about the model. What data was it trained on. The same way that when you go to buy food
at the grocery store, you check the ingredient list,
you look at the calorie count. It's the same kind of thing you're
assessing as you look at these models. And then I think the second piece
is to understand what type of actions are you going to be taking. So Morgan referenced earlier
we talked about summarizing something. Or maybe you're classifying
these different models typically are strongest at a certain set
of activities or actions you might take. And so it's about finding the right fit. And then maybe last
but definitely not least, how big is the model
and what's it going to cost you to use it. Because you got to balance
all those factors. I wish I had unlimited funds, but I don't. And so really trying to find the best mix
across those dimensions. Is it inaccurate to assume, though,
that like the bigger the model, the better that it's going to be for any business,
regardless of what the industry is? Definitely. Yeah. Like Jessica was saying that different
models are good at certain things. So there's actually one
that is really good at code generation. I'm not going to use that
for writing emails. Otherwise
my emails are going to be very weird. and so there is the concept of parameters
and I won't get too deep into it, but how many parameters
go into a large language model? So I think what you were kind of saying
is just because something has more a larger number of parameters,
it doesn't mean necessarily that it's going to be better
for every task out there. Gotcha. Okay. Still,
it really does matter. It does. And I think when you think
about the size of the model, sometimes I would say
if something is going to cost you twice as much and it's
maybe only better in one case out of ten. Is it the right balance. Right. Yeah. So there's really some real human
discernment that needs to happen here. There's a. Lot of work to be done. To make sure you find the right fit. Yeah. So that's of testing lots of testing. So let's talk about how this can actually
go into practice as well. Like I'm thinking specifically
about so many of the professional tasks that we do today that we just kind of
we automatically think about it. Right, because it's a part of our routine. But some of those things are going to look
really outdated when our grandkids think about it. Right.
They're going to laugh about it. Right. So like,
what is today's fax machine, for example? And and what's today's email? I think we're already seeing it
even with the generation of our kids. And I think it's only going to amplify
when we get to our grandkids. Really simple example. To give you a sense, most kids today work
only in online applications. So my children do not understand
the save button because they've only ever worked in like
Google Docs or some kind of online form. So like it
just isn't even a concept to them. And I think what we're really going to see
is this idea that you have to talk to people
to get something done. It's going to sound like this really hokey
thing, like, what do you mean? You had to line up somewhere and you had to talk to human to accomplish something They're going to be doing things
from a phone. That mobile device is going
to just become central to everything. And they'll be like,
oh, you just press a button or you just speak to it
and everything happens behind the scenes. I think that concept of manual
to accomplish anything is going to be a little bit
of a thing of the. Past, and I don't think the kids know what a floppy disk is when you refer to the save button, but another thing is, you know, if you're typing in a text message,
you you've got autocomplete. That's AI, like that's. What I mean. But it's funny that you mention that
because I feel as though even though sometimes there can be a fear
surrounding those two letters, A.I. we are all using it in several
different ways. G.P.S. like texting. Yeah. Well, and I think you comment on fear. I also think generationally it's
interesting to watch because I do think for our kids
and our grandkids, those generation AI is going to be so pervasive that
they may not have the same degree of fear of adopting it, that maybe some of us do today
because we know what it used to be like. And so there's that. There is that culture divide
that you have to cross. But as kids come
up, as they're learning in school, I think every career,
no matter what you're in, is going to require
some level of knowledge about AI. That's going to mean they all come up with a set of awareness
and education that none of us have had. You mentioned career. So I'm thinking now, how will this growth, how will this development impact our work? Oh, it's going to make everything easier
for us. it's that's why we call it an assistant. It's not going to take an assistant
cannot do what I do. Let's be honest. But it's going to help me with the things that are either
just super repetitive or maybe the things I'm not good at,
like writing emails, things like that. But it's definitely not
going to take over. What I do. I kind of hope that that phrase,
grunt work is a thing of the past. It becomes a word that is just not used anymore, because
those are the things that I can handle and we're all going to be doing things that are creative, thought provoking, strategic, and let's go change the world. Okay, well, you just brought up a word
that I'm sure really made people's ears perk up grunt work. It's the thing.
Like we all run away from that. So how do you even start to diagnose
what some of that grunt work is? That I might be able to replace? Yeah. So, we have a concept called design
thinking here at IBM. And something we do as part of
that is called empathy mapping. We put ourselves in the shoes of the user. We do like interviews with them. So we're going to see
like what is their day to day? What are the tasks that they're spending
the most time on, and can we automate those like you were talking
about your kids earlier, doing the, the research and all that. I remember back in my day
when we had dial up manually having the first way
for the internet to load and then having to go and read through
all of these different documents. And I mean, let's think of a, customer
service agent. You know, they're like, how do they update
a user's account information or something like that?
They're going to have to go and read through the manuals,
but that's grunt work. We don't want to do that. We can use. A.I., hey, go check in
within a few seconds, get an answer. And we know then, though,
that people are evolving over time. Like what you talk about back in my day,
you know, I would like to say
I think today is still your day. I'm not ready to give our days
up, you know? but I'm thinking, how are these roles also going to evolve over time? Right. Because I know since
we're evolving, our roles have to as well. What do you think
that's going to look like? So I think we're going to see
a lot more time being able to be spent
on engaging with each other. If we're not having to spend this time,
you know, searching on things or entering things into spreadsheet. Now, we actually can spend the time face
to face and interacting and engaging. I think we're going to see
a big focus on that. I also think we're going
to be having more opportunity to create. We're going to have things that will help
us bring to life what we envision, right? But we have to spend the time on the big,
the big ideas, the big thoughts, the big visions,
and I do. I think we're going to see
a lot of advancements and a lot of ideas about how to make all
of our lives better and more fulfilling. Okay, now
this has been such a rich conversation. I wish that I could somehow
grant us more time, with this, but, I'm taking a few things away from this,
so here are a few takeaways I've got. Time is the most valuable resource, so using AI to free up your time is absolutely key. "The bigger the model, the better." It's like,
that's not a true statement at all. So you got to pick the best model
for your task. And then looking to the future,
every career is going to require understanding of AI and honestly
it will make them better and easier. Does that sound about right? Sounds pretty right. Okay, cool.
I think I passed the test today. well, thank you both so much for being here. Jessica, Morgan,
this has been a complete blast. That's it for this episode. So thank you so much for listening.
Thank you for watching. But hey, look, there's a ton more where this came from. We're going to be bringing you AI insights
all throughout the season. So stay tuned to this feed
and we'll see you here again soon.