{
  "video_url": "https://www.youtube.com/watch?v=DGO60Zrdle8",
  "video_id": "DGO60Zrdle8",
  "title": "The art of delegating to AI: Using AI agents and chatbots to do the boring work",
  "upload_date": "20240618",
  "channel": "IBM Technology",
  "duration": "19:44",
  "caption": "We all\nhave something we hate about our job. Those time sucking tasks that take you\naway from actually getting your work done. I know you're thinking about them\nright now. But what at the tasks that you dread\ncould be handled not just by someone else, but by AI. Welcome to AI in action. Brought to you by IBM. I'm Albert Lawrence. I'm here\nbecause I'm a learner. I'm a doer. I look at a big picture,\nand I can't help but start asking exactly how does it work on the inside? On this podcast,\nI'm going to be joined by AI experts, technologists and business leaders alike\nwho are really going to help us to get beyond the fury of AI and into\nhow we actually put it into practice. We're all starting to see more and\nmore stories about AI powered outcomes, but exactly how do I get to\nthose outcomes for my business? What are the actual steps\ninvolved in changing not only my IT tools and infrastructure, but\nalso my business processes and culture? Mainly, how do I make AI I work for me right now. So let's do it, shall we? Today I'm joined by Jessica\nRockwood and Morgan Carroll. Jessica is VP client engineering at IBM. Welcome, Jessica. Thank you. Thanks for having me. Glad that you're here. And my other guest is Morgan Senior\nAI engineer in client engineering at IBM. Welcome, Morgan. I'm excited to be here. I bet you're wondering how I chose you\nfor today's episode. Well, it's\nnot because your work is boring. Because it's not. But it's because you work\nto make the boring stuff easy. And IBM client engineering is all about\nmaking your AI dreams a reality. So let's take a look at a few places\nwhere attention to detail, empathy, and responsiveness could make or break us\nif we're being for real for real. So first off, I'm very curious. Look, people already\ndon't have enough time to do everything at the quality\nand the speed that we expect every day. Work just seems to have gotten\nmore complicated. And I'm not alone in this. So how do you use AI to do\nthe boring stuff that you'd rather not? Jessica, let's start with you. For me, it always comes down to what are the things I hate doing\nbecause they're repetitive. Quite frankly, I don't have to use\nthat many brain cells to do it. It's all the preparatory work. So every week I take a look at\nhow are we doing as a business, what are we doing in the team? Are we making progress? I can spend hours\njust getting data together and trying to do,\nlet's say, the first pre-processing. If I can have I do that in a few minutes,\nthat actually gives me a few hours to do the critical thinking,\nto think strategically. What are the next steps to take? I was telling Morgan earlier,\nI would love that every time I look at some data and I think, ooh, I wonder\nif there could be AI that goes and finds the right data, does the processing,\nand gives me back some analysis. I now have like super powers. And that\ntime is that's like the most valuable. invaluable, yes. And what about you, Morgan? Okay,\nI hate to admit it, but writing emails. I have a I'd rather be writing code. I have got, like, five points. I need to make it an email, and I'm like,\nokay, now how do I phrase this? So it sounds appropriate? No, I'm just going to let I do it. For me. That's going to save me so much time. And in addition, code generation actually,\nwhich is really interesting. Typically I'm like,\nhow do I write this function in Python? Maybe I don't want to go to the documentation,\nI don't want to read the documentation. But with code generation I could say, hey,\nhow do I do this? How do I write this function in?\nBut there it is. I look like I already have a very clear\nidea of who I'm speaking with today. Now. You just admitted you'd rather\nbe writing code than writing emails. So. Okay, we love it.\nYou're in the right gig, then. I think of Morgan's example\nabout getting a first draft, whether it's email or code or, let's say,\na history project. I was working with my daughter. She needs to come up\nwith a lot of different facts to support a thesis,\nand she hates drafting anything and leveraging a search engine,\ngoing out, pulling back all sorts of forms of information\nreally accelerated her progress on it. She still had to assess\nwhat the search engines found, because we all know\nthere can be some fake news out there. You need to kind of do a bit of analytics\nto understand the source of what's come back, should you trust it? But by being able to pull that together\nin seconds, you actually can make a deadline. And that's what matters. We love it when they can make a deadline. Awesome. Congratulations to your daughter. Thank you. Now, but when we're thinking about these kinds of solutions\nthat both you and your daughter are using. I'm curious about the build behind them. Can you take me a little bit into that,\nMorgan? Yeah, definitely. Everything starts\nwith the user, obviously. So we need to think of what\nis the user experience going to be like. So what we want to start with\nis sort of a conversational flow like hello user, how are you\ncome up with a persona maybe for the bot, which is my favorite thing\nlike Barry the bot, a little alliteration. and then we want to gather data\nfrom the user, obviously. And at some point we're going to call out\nto a large language model, we're going to take all of this\ndata and say, hey, here it is. Do something with it. Summarize this for me,\nget an answer, it's going to come back. And then we present it to the user. So it's overall\na relatively simple process. Okay I mean you made it\nsound really easy okay. But but I know that it really\ncan't be as easy as as you made it sound. So I'm curious about what problems though\nthe companies are coming up against when they are trying to figure out\nhow to make these a reality. Well, so I think one of the biggest ones\nI see is how do you customize? So I think what Morgan took us through\nis what I would call the standard. Right. Like let's say 80% of the time, yeah,\nwe can have just this back and forth flow. But what happens when you have a problem\nor what happens when someone maybe is going to ask a question\nof a virtual assistant It's never seen before. We all like to think\nwe're a little unique. We're a little different\nthan everyone else. And that's,\nI think, where the challenges come. It's like, how do you figure out for\nthe edge cases to get the same response, the same experience\nas if it was the common interaction? That word interaction\nis really ringing for me right now, because I notice that both of you are\nspeaking of these as virtual assistants. Nobody's saying chatbot. What? What? Is that an intentional thing? Yes, absolutely. The reason we don't say chat bot anymore\nis because we're not just chatting\nwith the virtual assistant. This technology is assisting us\nwith various tasks. So it's not just like,\nhey, give me this information. It can, look up account information,\nmaybe fill a prescription. The options are endless, honestly. And especially that taking actions\nassociated with it. So I think most of us would think about\nan assistant helps you do things. They don't just talk to you. Okay, so look, I think we can all agree\nthat we could all use an assistant, use some additional assistance. Right. And that's whether we're a big company\nor whether we're a smaller company. But what is the data foundation\nthat you need in order to make AI I work for you. Can the small companies access\nit just as much as the larger ones? That's\nprobably the thing I'm most excited about. With generative AI,\nwe're able to leverage foundation models, which are built off\nof an incredibly large corpus of data. And so now when you're the smaller company\nand you have a smaller amount of data to start with, you take advantage of everything that was already trained\ninto the foundation model. So we've lowered the bar. It doesn't take terabytes of data. In fact, it might be something\nas simple as 3 or 4 questions and answers. And that alone can get you started. So in thinking about that,\nif even the small companies can really tap on in and use a lot of the intelligence\nthat's already been formulated, the LLMs, why is integration a relevant thing? Can somebody just kind of like, grab it all from one source\nand plug it on into their system? Not necessarily. So there are and integrations\nare my favorite topic to talk about. So there are a number\nof different sources. Maybe you have a database\nthat has all of your customer information or you've got an ordering systems. I always like to use the flower shop example, so maybe we have our inventory listed in a certain place, customer information\nin a certain place, location information. If we're doing deliveries, you can't just kind of copy and paste\nthat into your virtual assistant. You have to work with integrations\nwhich connect your virtual assistant to all of this data so that you can use it\nin your virtual assistant. okay. Okay. So you're reaching into different sources, all in order\nto still connect with your one main task. So even if we're just asking\nmaybe one question, the response might be pulling\nfrom several sources. Yes. And I think it's partly about customizing. So when you interact with a virtual agent,\nyou want it to know who you are. And to have all the right context. And then I think the other integration Morgan spoke to is when you're going\nto take that action, that workflow might be in a different system\nor a different application. And so it's really it's\nnot just integrating the data, it's integrating the tools or the actions\nyou're going to take as well, making it a seamless journey throughout. So when I look at my phone,\nwhen I look at my devices, I see that I've got all sorts of different\nlike virtual assistants I've got, whether\nit's like my calendar app over here or whether I've got\nanother scheduling app on over here. How in the world can\nall of those different spaces be woven together and integrate to just be\none super duper virtual assistant? I mean, again, as your assistant, I've got my work calendar,\nI've got my personal calendar. I need to know when to take my dog\nto his doggy play dates, but I also need to know\nwhen I'm traveling for work. I want to see everything in one location,\nso he or she is reaching out to all of these different places\nand grabbing all of your data. So it's connected to maybe my work\ncalendar. It's also connected to my personal\ncalendar, it's connected to my email, and it can consolidate\nall of this in just one place. So if I say like, hey,\nwhat's going on today? Okay, let's give you a summary. I just pulled your email, pulled your calendar, checked on Mr. Hubble, the dog. Now, we're going to put all this together and say like,\nokay, here's a summary of your day. And I think the other thing\nwe're also seeing is many of the applications are starting to figure out how do we\nproactively build those integrations in. I did a prescription online\nrefill the other day, did it through virtual assistant.\nIt said it's done. It then sent a text to me with the time\nto pick it up, which created an entry on my calendar and a reminder\nto say, like, you got to still pick it up. And so I think to your point, it's\neither from the assistant outwards trying to engage and connect\nand integrate, but also as we build these applications, we need to be thinking\nabout those touchpoints and how we proactive\nsend information to be included. I hear you, Jessica. So but Morgan, how do you go about\nactively building these integrations? Yeah. So let me give you an example\nfor what I do specifically. I will first build sort of a dialog in a tool that we have called watsonx Assistant. So that's just the base like, hello,\nhow are you? How can I help you? and then I will add something called\nextensions, which are the integrations. So for each data source\nI might have a different extension. For instance, to reach out to a calendar,\nI've got a calendar extension. if I have a data repository with all\nmy documents, that's another extension. If I want to reach out to a large language\nmodel, another extension, and then in the dialog itself\nin assistant, that's where we kind of bring everything together and navigate,\nyou know, how to guide the customer. But when we are thinking about all of\nthe different sources that are out there, this is where I can start\nto get a little bit intimidated from just keeping it real here. How can you make sure that you're actually\nfinding the right AI model, and how do you start? First and foremost, it's\nabout finding a trusted model. So we know that there's an incredible\namount out in the open source world. There's a lot of proprietary models\nas well. So first and foremost\nyou want to find one that you trust. and that's looking at what information\nis shared about the model. What data was it trained on. The same way that when you go to buy food\nat the grocery store, you check the ingredient list,\nyou look at the calorie count. It's the same kind of thing you're\nassessing as you look at these models. And then I think the second piece\nis to understand what type of actions are you going to be taking. So Morgan referenced earlier\nwe talked about summarizing something. Or maybe you're classifying\nthese different models typically are strongest at a certain set\nof activities or actions you might take. And so it's about finding the right fit. And then maybe last\nbut definitely not least, how big is the model\nand what's it going to cost you to use it. Because you got to balance\nall those factors. I wish I had unlimited funds, but I don't. And so really trying to find the best mix\nacross those dimensions. Is it inaccurate to assume, though,\nthat like the bigger the model, the better that it's going to be for any business,\nregardless of what the industry is? Definitely. Yeah. Like Jessica was saying that different\nmodels are good at certain things. So there's actually one\nthat is really good at code generation. I'm not going to use that\nfor writing emails. Otherwise\nmy emails are going to be very weird. and so there is the concept of parameters\nand I won't get too deep into it, but how many parameters\ngo into a large language model? So I think what you were kind of saying\nis just because something has more a larger number of parameters,\nit doesn't mean necessarily that it's going to be better\nfor every task out there. Gotcha. Okay. Still,\nit really does matter. It does. And I think when you think\nabout the size of the model, sometimes I would say\nif something is going to cost you twice as much and it's\nmaybe only better in one case out of ten. Is it the right balance. Right. Yeah. So there's really some real human\ndiscernment that needs to happen here. There's a. Lot of work to be done. To make sure you find the right fit. Yeah. So that's of testing lots of testing. So let's talk about how this can actually\ngo into practice as well. Like I'm thinking specifically\nabout so many of the professional tasks that we do today that we just kind of\nwe automatically think about it. Right, because it's a part of our routine. But some of those things are going to look\nreally outdated when our grandkids think about it. Right.\nThey're going to laugh about it. Right. So like,\nwhat is today's fax machine, for example? And and what's today's email? I think we're already seeing it\neven with the generation of our kids. And I think it's only going to amplify\nwhen we get to our grandkids. Really simple example. To give you a sense, most kids today work\nonly in online applications. So my children do not understand\nthe save button because they've only ever worked in like\nGoogle Docs or some kind of online form. So like it\njust isn't even a concept to them. And I think what we're really going to see\nis this idea that you have to talk to people\nto get something done. It's going to sound like this really hokey\nthing, like, what do you mean? You had to line up somewhere and you had to talk to human to accomplish something They're going to be doing things\nfrom a phone. That mobile device is going\nto just become central to everything. And they'll be like,\noh, you just press a button or you just speak to it\nand everything happens behind the scenes. I think that concept of manual\nto accomplish anything is going to be a little bit\nof a thing of the. Past, and I don't think the kids know what a floppy disk is when you refer to the save button, but another thing is, you know, if you're typing in a text message,\nyou you've got autocomplete. That's AI, like that's. What I mean. But it's funny that you mention that\nbecause I feel as though even though sometimes there can be a fear\nsurrounding those two letters, A.I. we are all using it in several\ndifferent ways. G.P.S. like texting. Yeah. Well, and I think you comment on fear. I also think generationally it's\ninteresting to watch because I do think for our kids\nand our grandkids, those generation AI is going to be so pervasive that\nthey may not have the same degree of fear of adopting it, that maybe some of us do today\nbecause we know what it used to be like. And so there's that. There is that culture divide\nthat you have to cross. But as kids come\nup, as they're learning in school, I think every career,\nno matter what you're in, is going to require\nsome level of knowledge about AI. That's going to mean they all come up with a set of awareness\nand education that none of us have had. You mentioned career. So I'm thinking now, how will this growth, how will this development impact our work? Oh, it's going to make everything easier\nfor us. it's that's why we call it an assistant. It's not going to take an assistant\ncannot do what I do. Let's be honest. But it's going to help me with the things that are either\njust super repetitive or maybe the things I'm not good at,\nlike writing emails, things like that. But it's definitely not\ngoing to take over. What I do. I kind of hope that that phrase,\ngrunt work is a thing of the past. It becomes a word that is just not used anymore, because\nthose are the things that I can handle and we're all going to be doing things that are creative, thought provoking, strategic, and let's go change the world. Okay, well, you just brought up a word\nthat I'm sure really made people's ears perk up grunt work. It's the thing.\nLike we all run away from that. So how do you even start to diagnose\nwhat some of that grunt work is? That I might be able to replace? Yeah. So, we have a concept called design\nthinking here at IBM. And something we do as part of\nthat is called empathy mapping. We put ourselves in the shoes of the user. We do like interviews with them. So we're going to see\nlike what is their day to day? What are the tasks that they're spending\nthe most time on, and can we automate those like you were talking\nabout your kids earlier, doing the, the research and all that. I remember back in my day\nwhen we had dial up manually having the first way\nfor the internet to load and then having to go and read through\nall of these different documents. And I mean, let's think of a, customer\nservice agent. You know, they're like, how do they update\na user's account information or something like that?\nThey're going to have to go and read through the manuals,\nbut that's grunt work. We don't want to do that. We can use. A.I., hey, go check in\nwithin a few seconds, get an answer. And we know then, though,\nthat people are evolving over time. Like what you talk about back in my day,\nyou know, I would like to say\nI think today is still your day. I'm not ready to give our days\nup, you know? but I'm thinking, how are these roles also going to evolve over time? Right. Because I know since\nwe're evolving, our roles have to as well. What do you think\nthat's going to look like? So I think we're going to see\na lot more time being able to be spent\non engaging with each other. If we're not having to spend this time,\nyou know, searching on things or entering things into spreadsheet. Now, we actually can spend the time face\nto face and interacting and engaging. I think we're going to see\na big focus on that. I also think we're going\nto be having more opportunity to create. We're going to have things that will help\nus bring to life what we envision, right? But we have to spend the time on the big,\nthe big ideas, the big thoughts, the big visions,\nand I do. I think we're going to see\na lot of advancements and a lot of ideas about how to make all\nof our lives better and more fulfilling. Okay, now\nthis has been such a rich conversation. I wish that I could somehow\ngrant us more time, with this, but, I'm taking a few things away from this,\nso here are a few takeaways I've got. Time is the most valuable resource, so using AI to free up your time is absolutely key. \"The bigger the model, the better.\" It's like,\nthat's not a true statement at all. So you got to pick the best model\nfor your task. And then looking to the future,\nevery career is going to require understanding of AI and honestly\nit will make them better and easier. Does that sound about right? Sounds pretty right. Okay, cool.\nI think I passed the test today. well, thank you both so much for being here. Jessica, Morgan,\nthis has been a complete blast. That's it for this episode. So thank you so much for listening.\nThank you for watching. But hey, look, there's a ton more where this came from. We're going to be bringing you AI insights\nall throughout the season. So stay tuned to this feed\nand we'll see you here again soon."
}