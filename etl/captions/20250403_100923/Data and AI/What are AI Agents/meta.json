{
  "video_url": "https://www.youtube.com/watch?v=F8NKVhkZZWI",
  "video_id": "F8NKVhkZZWI",
  "title": "What are AI Agents?",
  "upload_date": "20240715",
  "channel": "IBM Technology",
  "duration": "12:28",
  "caption": "2024 will be the year of AI agents. So what are AI agents? And to start explaining that, we have to look at the various shifts that \nwe're seeing in the field of generative AI. And the first shift I would like to talk \nto you about is this move from monolithic models to compound AI systems. So models on their own are limited by the data they've been trained on. So that impacts what they know about the world and what sort of tasks they can solve. They are also hard to adapt. So you could tune a model, but it would take \nan investment in data, and in resources. So let's take a concrete example \nto illustrate this point. I want to plan a vacation for this summer, and I want to know how many vacation days are at my disposal. What I can do is take my query, feed that into a model that can generate a response. I think we can all expect that this answer will be incorrect, because the model doesn't know who I am and does not have access \nto this sensitive information about me. So models on their own could be useful for a \nnumber of tasks, as we've seen in other videos.  So they can help with summarizing documents, they can help me with creating first drafts for emails and different reports I'm trying to do. But the magic gets unlocked when I start building systems around the model and actually take the model and \n integrate them into the existing processes I have. So if we were to design a system to solve this, I would have to give the model access to the \ndatabase where my vacation data is stored. So that same query would get \nfed into the language model.  The difference now is the model would \nbe prompted to create a search query,   and that would be a search query that \ncan go into the database that I have.  So that would go and fetch the information \nfrom the database, output an answer,   and then that would go back into the \nmodel that can generate a sentence to answer, so, \"Maya, you have ten days \nleft in your vacation database.\" So the answer that I would get here would be correct.  This is an example of a compound AI system, and it recognizes that certain problems are better solved when you apply the principles of system design. So what does that mean? By the term \"system\", you can understand there's multiple components. So systems are inherently modular. I can have a model, I can choose between tuned models, large language models, image generation models, but also I have programmatic components that can come around it. So I can have output verifiers. I can have programs that can that can take \na query and then break it down to increase the chances of the answer being correct. I can combine that with searching databases. I can combine that with different tools. So when we talking about a system approaches, I can break down what I desire my program to do and pick the right components to be able to solve that. And this is inherently easier to solve for than tuning a model. So that makes this much faster and quicker to adapt. Okay, so the example I use below, is an example of a compound AI system. You also might be popular with retrieval augmented generation (RAG), which is one of the most popular \nand commonly used compound AI systems out there. Most RAG systems and the example I \nuse below are defined in a certain way.  So if I bring a very different query, let's \nask about the weather in this example here.  It's going to fail because this the path \nthat this program has to follow is to always search my vacation policy database. And that has nothing to do with the weather. So when we say the path to answer a query, we are talking about something called \nthe control logic of a program. So compound AI systems, we said  \nmost of them have programmatic control logic. So that was something that I defined myself as the human. Now let's talk about, where do agents come in? One other way of controlling the logic \nof a compound AI system is to put a large language model in charge, and this is only possible because  \nwe're seeing tremendous improvements in the capabilities of reasoning  \nof large language models. So large language models, you \ncan feed them complex problems and you can prompt them to break them down \nand come up with a plan on how to tackle it. Another way to think about it is, on one end of the spectrum, \nI'm telling my system to think fast, act as programmed, and don't deviate \nfrom the instructions I've given you. And on the other end of the spectrum, you're designing your system to think slow. So, create a plan, attack each part of the plan, see where you get stuck, see if you need to readjust the plan. So I might give you a complex question, and if you would just give me the \nfirst answer that pops into your head, very likely the answer might be wrong, but you have higher chances of success \nif you break it down, understand where you need external help to \nsolve some parts of the problem, and maybe take an afternoon to solve it. And when we put a LLMs in charge of the logic, this is when we're talking \nabout an agentic approach. So let's break down the components of LLM agents. The first capability is the ability to reason, which we talked about. So this is putting the model at the core of how problems are being solved. The model will be prompted to come up with a plan \nand to reason about each step of the process along the way. Another capability of agents is the ability to act. And this is done by external programs \nthat are known in the industry as tools. So tools are external pieces of the program, and the model can define when to call them \nand how to call them in order to best execute the \nsolution to the question they've been asked. So an example of a tool can be search, searching the web, searching a database at their disposal. Another example can be a \ncalculator to do some math.  This could be a piece of program code \nthat maybe might manipulate the database.  This can also be another language model that \nmaybe you're trying to do a translation task,   and you want a model that can be able to do that. And there's so many other possibilities of what can do here. So these can be APIs. Basically any piece of external program \nyou want to give your model access to.  Third capability, that is \nthe ability to access memory.  And the term \"memory\" can mean a couple of things. So we talked about the models thinking through the program kind of how you think out loud \nwhen you're trying to solve through a problem. So those inner logs can be stored and can be \nuseful to retrieve at different points in time.  But also this could be the history of \nconversations that you as a human had   when interacting with the agent. And that would allow to make the experience  \nmuch more personalized. So the way of configuring agents,   \nthere's many are ways to approach it. One of the more most popular ways of going about it is through something called ReACT, which, as you can tell by the name, combines the reasoning and act components of LLM agents. So let's make this very concrete. What happens when I configure a REACT agent? You have your user query that gets fed into a model.\nSo an alarm the alarm is given a prompt.  So the instructions that's given is don't \ngive me the first answer that pops to you.  Think slow planning your work.\nAnd then try to execute something.  Tried to act.\nAnd when you want to act, you can define whether.  If you want to use external tools to \nhelp you come up with the solution.  Once you get you call a \ntool and you get an answer.  Maybe it gave you the wrong answer \nor it came up with an error.  You can observe that.\nSo the alarm would observe.  The answer would determine if it does answer the \nquestion at hand, or whether it needs to iterate   on the plan and tackle it differently.\nUp until I get to a final answer.  So let's go back and make \nthis very concrete again.  Let's talk about my vacation example.\nAnd as you can tell, I'm really excited   to go on one, so I want to take \nthe rest of my vacation days.  I'm planning to go on to Florida next month.  I'm planning on being outdoors \na lot and I'm prone to burning.  So I want to know what is the number of two ounce \nsunscreen bottles that I should bring with me?  And this is a complex problem.\nSo there's a first thing.  There's a number of things to plan.\nOne is how many vacation days   are my planning to take?\nAnd maybe that is information   the system can retrieve from its memory.\nBecause I asked that question before.  Two is how many hours do I plan to be in the sun?\nI said, I plan to be in there a lot,   so maybe that would mean looking into the weather \nforecast, for next month in Florida and seeing   what is the average sun hours that are expected.\nThree is trying maybe going to a public health   website to understand what is the recommended \ndosage of sunscreen per hour in the sun.  And then for doing some math, to be able \nto determine how much of that sunscreen   fits into two ounce bottles.\nSo that's quite complicated.  But what's really powerful here is \nthere's so many paths that can be   explored in order to solve a problem.\nSo this makes the system quite modular.  And I can hit it with much more complex problems.\nSo going back to the concept of compound AI   systems, compound AI systems are here to stay.\nWhat we're going to observe this year is that   they're going to become more agent tech.\nThe way I like to think about it is   you have a sliding scale of AI autonomy.\nAnd you would the person defining the system   would examine what trade offs they want in terms \nof autonomy in the system for certain problems,   especially problems that are narrow, well-defined.\nSo you don't expect someone to ask them about the   weather when they need to ask about vacations.\nSo a narrow problem set.  You can define a narrow system like this one.\nIt's more efficient to go the programmatic   route because every single query \nwill be answered the same way.  If I were to apply the genetic approach here,\nthere might be unnecessarily   looping and iteration.\nSo for narrow problems, pragmatic approach can   be more efficient than going the generic route.\nBut if I expect to have a system, accomplish very   complex tasks like, say, trying to solve \nGitHub issues independently, and handle   a variety of queries, a spectrum of queries.\nThis is where an agent de Groot can be helpful,   because it would take you too much effort to \nconfigure every single path in the system.  And we're still in the early days of agent systems.  We're seeing rapid progress when you combine the \neffects of system design with a genetic behavior.  And of course, you will have a human in the \nloop in most cases as the accuracy is improving.  I hope you found this video very useful, and \nplease subscribe to the channel to learn more."
}