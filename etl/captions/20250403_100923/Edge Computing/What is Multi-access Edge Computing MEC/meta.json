{
  "video_url": "https://www.youtube.com/watch?v=Do7gsyXWj4E",
  "video_id": "Do7gsyXWj4E",
  "title": "What is Multi-access Edge Computing (MEC)?",
  "upload_date": "20210326",
  "channel": "IBM Technology",
  "duration": "5:29",
  "caption": "What is multi-access edge computing? How is \nit different than regular edge computing? Hi,   I'm Dan Kehn from IBM Cloud, and before I answer \nthose questions, please click like and subscribe.   Edge computing is about bringing compute capacity \ncloser where data is created to reduce response   time and the load on back-end servers. Multi-access \nedge computing is the next logical step in edge   computing for telco cloud. It brings compute \ncapacity directly to network's edge, literally   on the same infrastructure as the network itself. \nLet's go through it using an example. So we have   say an image application that does image \nanalysis. It communicates with the core network. That in turn works with a back-end server. For sake of discussion, on that \nback-end server, let's assume we have   a service called \"image analysis service\" installed. Okay, this is a classical \napplication design pattern;   the user makes a request, it \ngoes to a back-end server,   it formulates a response that it returns the end \nuser. The round trip for that including latency   might be on the order of 100 milliseconds. \nThat's perfectly fine for many applications.   But let's assume we have a more demanding \napplication, for example, one that does video.   And it isn't using just one user that it wants \nto capture, it's capturing a crowd. Maybe it's   used for security purposes, maybe it's used for \nthreat analysis -- those are just some examples.   What really drives us towards an edge computing \nsolution are two things: First, there's a lot   of data. Now an HD video camera, that could \nstream as much as six megabits per second.   The other thing is the real-time \naspect -- we need a real-time response,   It would be difficult to send all that data \nback to the back-end server, process it, and   return it in real-time. That's why we install edge \nservers closer to where the source of data is.   So say, for example, we install some edge servers, and on those we install \nthe \"video analysis service\". This really helped with our latency problem. We \nno longer have to send data across the network   to a far away server. It also \nhelps with our data volume problem.   We're no longer sending huge \namounts of data across the network. Where multi-access edge computing comes \ninto play is when we add a third element, specifically mobility. In the prior examples, we were assuming that \nthese edge computers were in a fixed location,   for example, at a retail location providing a \nshopping experience, maybe an IoT device at a   factory that's doing assembly. Those are examples \nwhere the edge computer location is known.   In this case, for multi-access edge computing, it \ncould be anywhere. We cannot predict where the   edge computers might be located, so we install \nthem on the network itself. So, for example, we   have a radio access network and then install \nit at the base station; or, we could install it   at the data center for the network itself. This \nreally drives latency to its absolute minimum,   as little as 10 milliseconds. It also reduces the \nload on the back-end server for the enterprise.   We could then repurpose that for something \nelse, for example, we could do machine learning. So, for example, say we do machine learning \ntraining, then we take that result and we   give it to the video analysis service \nto improve the quality of its results.   There's a couple other different benefits \nthat are worth noting. Because this is   running on the network's infrastructure, \nif there is a temporary outage between the   back-end server and video analysis, it can continue \nto process. Thus you have continuous operations.   Finally, there is the ability to take \nadvantage of radio access network data. For example, the radio access network would \nknow where the location of the users are   and it could potentially predict where additional \nload would be required. This allows their network   to be much more responsive to users' needs and \nbeing able to deploy capacity where it's going to   where it's going to be needed in the future. Multi-access edge computing means communication service   providers can bring compute capacity directly to \nyour users no matter where or how they connect to   the network. Thank you for watching. If you \nhave questions please drop us a line below.   If you want to see more videos like this \nin the future, please like and subscribe."
}