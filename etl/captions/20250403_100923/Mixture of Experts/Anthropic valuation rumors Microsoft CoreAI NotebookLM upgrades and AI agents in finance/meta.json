{
  "video_url": "https://www.youtube.com/watch?v=NcV5GrG5VTA",
  "video_id": "NcV5GrG5VTA",
  "title": "Anthropic valuation rumors, Microsoft CoreAI, NotebookLM upgrades, and AI agents in finance",
  "upload_date": "20250117",
  "channel": "IBM Technology",
  "duration": "44:47",
  "caption": "What would you do with $2 billion?  Chris Hay is as a distinguished engineer\nand CTO of customer transformation,  Chris, as always,\nwelcome back to the show.  What would you do with $2 billion?\nSpend it all on bitcoin and tell people  I'm training AI.\nOkay, great.  Kaoutar El Magrahoui is Principal Research\nScientist and a Manager  at the AI Hardware Center, Kaoutar.\nWelcome back.  $2 billion.\nSo, what would you do?  Well, it's a lot, and there is\nalot I can do with it. One of the first  things is philanthrop and social impact, I\nwould love to help with that  Vyoma Gajjar is an AI \ntechnical solutions Architect.  Vyoma, what would you do with $2 billion?\nI would back to my roots and become   a farmer again.\nOwn loads of land,   land, land. And then revolutionize\nthe entire field of agriculture.  Terrific.\nAll that and more on today's  mixture of experts.\nI'm Tim Hwang,  and welcome to Mixture of Experts.\nEach week, MoE is the place to tune  in, to hear the news\nand analysis of the biggest headlines  and trends in artificial intelligence.\nToday, we're going to talk a little bit  about a new CoreAI group at Microsoft.\nWe're going to talk about,  some new features coming to NotebookLM\nand a little bit about agents in finance.  But first\nI really wanted to talk about $2 billion.  So we had some rumors that just popped up,\njust this week.  That Anthropic is set to raise\n$2 billion at a $60 billion valuation.  And that follows on news from December,\nwhere xAI raised  $6 billion at a $45 billion valuation.\nObviously,  the market is really, really hot.\nContinues to be really, really crazy.  I guess maybe, Chris, I'll turn it to you.\nFirst is for our listeners.  You know,\nthat's just a staggering amount of money.  What do you use that money for?\nEven like what?  What is this money being raised for?\nWhy or why are these companies needing  so much money?\nI think the quick version of this is.  It's an arms race at the moment.\nIt's an arms race for talent.  So, you know, it's not like\nthe researchers are getting paid  a small amount of money,\nso they've got to be paid,  and they're pulling their best talent\nfrom folks like Google, OpenAI, etc..  So it's just the cost of the researchers.\nAnd then obviously the cost of the GPUs.  So and it's one of these races where\nif you're not spending the money,  you're not going to be able\nto train the models,  and then you're\njust going to be out of the race.  So I think they they've got to keep racing\njust to be in that race.  Yeah, absolutely.\nVyoma, I think one question that I have with  all of this is like it's it's\npretty hard to raise $2 billion,  much less $6 billion on the xAI case.\nI don't know, I think one result of this,  I don't know if you agree.\nIt does seem to me that, like,  is this becoming kind of a two player\ngame in terms of, you know, the ability  to train these massive, massive models?\nLike, are we going to end up with largely  it just being OpenAI and Anthropic?\nbelieve that  somewhere that these players\nhave a huge market share right now.  But I don't feel that they are\nthe ones who are going to rule.  Forever.\nThe smaller models,  the smaller industries are also taking up\npeople who are more domain specific  and building more domain specific\nmodels are also being entertained  by the clients across.\nSo I feel over here, as Chris mentioned,  it's an arms race right\nnow, and I feel a majority  of all of these infrastructure,\nchanges that are going to take place  would need a lot of money going into them.\nSo we'll just have to wait it out  and see what goes around.\nYeah. I think it's kind of intriguing.  Yeah.\nI mean what you're saying is basically  like you're sort of saying\nthese companies can raise so much money.  They're the leaders in the space.\nBut it's unclear whether or not that  will allow them to retain their leadership\nin the market,  which is which is pretty intriguing.\nAnd I guess, Kaoutar,  do you agree with that?\nThe kind of this is in some ways  maybe kind of like an interesting,\nironic situation  where the two biggest companies\nare going to be raising the most money,  but in some ways are\nmaybe the most vulnerable.  Yeah, definitely.\nI think this level of funding, can signal  also to other AI firms\nthe level of resources  needed to stay competitive.\nSo leading to a cascade of investments  and potential consolidation in this space.\nSo it's definitely, you know, an arms  race, like, you know, everyone said here,\nand, you know,  this is, you know, some of these companies\nwill be shaping the AI industry.  So this is a rivalry in in AI industry\nfostering this rapid advancements in  both capabilities, ethical considerations.\nFor example, Anthropic has a niche market  here, especially with safety.\nAnd you know, they carved out,  you know, a niche emphasizing\nsafety and alignment,  which resonates with governments\nand enterprises  concerned about AI and its safety.\nWhile, for example, open  AI is mostly focus on the broad utility.\nBut, you know, this doesn't mean that  they're the only, you know, key players that's\ngoing to be kind of a two, arms race.  There are others,\nand especially with the push like Vyoma,  you know, mentioned with the smaller models,\nwe will see.  You know, I think it's still too early\nto predict what's going to happen.  So there is also a big push\nfor smaller models that are doing  pretty well also,\nespecially in domain, specific cases.  Right.\nAnd those, you know,  also will have a key role.\nBut I think what this is  showing is there is massive investments\nright now happening.  And most likely Anthropic\nwill double down on their R&D,  which is going to be great,\nyou know, for in terms of the capabilities  that they're going to unleash,\nthe development that they will do.  So more innovations is going to happen\nin the space.  But, also a lot happening\nin the open source,  which will help also others catch up\nor even come up with some revolutions  here.\nYeah. For sure. Chris.  Maybe I'll turn it back to you.\nYou know you're nodding when Vyoma was  kind of giving her hot take on all this.\nThere's a great book that came out  from Stripe Press called boom.\nBy these guys,  Brynn Hobart and Tobias Huber.\nAnd kind of they make the argument  that, like, there are good\nbubbles, basically, which is that, like,  you know, you can imagine a world\nwhere, like, all of these resources  kind of flood into the space\nand like the companies  that are leading and,\nyou know, driving  this may not be the ultimate winners,  but it's not like a count\nagainst the technology.  It's almost kind of like\nwhat's needed in order  for like the next generation\ntech to emerge.  And it sounds like it\nsort of  seems like from your head gestures,\nI guess, that you sort of agree  with the idea that, like,\nthese may be the leading companies, but  they might not ultimately own the future.\nLike we not might not end up in a world  where it's like these two companies\nare the end all, be all for all AI. I think the caution I would have is that\nthese companies are in competition  with their investors.\nAnd that is probably  an interesting dynamic.\nAnd we've seen that play out already,  fairly publicly.\nSo I think it's how that competition,  whether it's a coopetition or whether\nit's, true competition plays out.  And and if you really think\nabout those companies,  they've made great strides and their own\nAI capabilities are absolutely huge.  Now, like the, Microsoft five four model,\nfor example, is a great model,  the new Amazon, Nova models, etc.\nthey are making great strides.  And and when you start to look,\nyou know, the  hyperscalers investing in, their own\nAI and then,  you know, as we're going to talk\na little bit later on in the show about,  how AI is going to be embedded\nacross their entire organization,  is it really going to be a space\nfor those companies to exist?  And I think that then opens up,\nthey need  to establish their own platforms.\nAnd we clearly see that  from those companies, right?\nWith the, things like the operators, etc.,  the more generic platforms.\nSo we're going to get this push  between platforms.\nAnd, and I think that tension's  going to be interesting.\nAnd that's why do they survive or not?  The only way they're going to survive\nis to keep being in that race  and keep being ahead.\nBecause if they fall behind,  then are they going to keep\ngetting that money  and then they're just going to fall at.\nYeah. No, I think that's right.  Maybe a final question\nbefore I move to the next topic.  You know, Chris,\nyou you kind of alluded to this.  When you're explaining, you know, why it\nis that you need $2 billion, $6 billion.  And I think there's kind of two things\nyou lined out.  One was researchers super expensive.\nAnd then the other one was, hardware,  of course, super expensive as well.\nAnd, you know,  I think this kind of interesting question\nhere is like,  you know, does that spend go 50/50?\nIs it going to balance out over time,  or are we going to spend\nless on talent over time  and more on compute?\nI guess Vyoma I'm kind of curious  about what you think a little bit about.\nThat is like, you know,  I just kind of think about the balance\nsheet of these companies and,  you know, they've raised the money.\nSo they have these chips  and they have to decide, you know,\ndo they put it more against talent  or they put more against compute scarcity?\nYou think those economics will  sort of change over time or, you know,\nif one will dominate over the other.  I think the future would be.\nHow do we easily and properly  strategically balance all of these?\nAs whatever you said above,  the race is actually to dominate\nover this entire AI ecosystem  that everyone's building\nand this everyone wants to kind of  have their beak into this.\nAnd I feel one of the  main things that I feel, and this is\nthis is some sort of an indirect control  that all of them want\nor like the pace of innovation.  Imagine the amount of money\nthat you put in that much compute  you have that much access to researchers\nyou have.  If you put out such kind of, investments.\nAnd then this comes in the news.  The news picks it up.\nThe talent around you also is more like,  favoring you as well.\nI'm like,  wow, no, Andrew Monks is doing this.\nSo it's kind of a two way street here.  They are putting this out\nso that they get more talent.  So it's a balance.\nI won't say that  50% is going to go to this or 30 or for\nno one has strike that balance yet.  Everyone's learning on the go.\nSo yeah, we'll have to wait and see.  I was thinking of this\nand I was thinking, what if?  Because as I mentioned,\nthat the government is saying that,  you need to have more regulations, rules,\netc., that's what anthropic is doing. And  is he OpenAI working more on democratizing\nthe entire application space?  What if the government pushes them too\nmuch like the AI That's right.  Yeah.\nThe balance is going to be really,  I think really interesting to see.\nI mean I think there's two things  I think a little bit about.\nOne of them is  of course having a lot of compute\nis, is of course its own recruiting ploy  where you're like, oh, well,\nthe only over, the only place in the world  where you can run pre-training runs\nthat are this big.  There's also this kind of funny thing\nwhere at least in a lot of the circles  I run and there's a lot of discussion\nabout, you know,  I eventually automating AI research,\nand I kind of wonder whether or not  that will also be super\ninteresting advantage over time,  which is I have just more compute.\nSo it's kind of fungible, weirdly,  with my researchers over time.\nCause I know, you know, you work in a day  in, day out on the hardware side.\nI don't know if I'm just kind of,  you know, speaking out of school,\nbut curious about what you think  about that argument.\ninteresting. Dynamics here.  And, of course, I mean,\nwe've seen the work on the AI, like super  the scientist, the AI scientist,\nwhich was very interesting.  So in terms of the balance between the,\nyou know, the hardware and,  the researchers, I think\nit's going to vary in certain areas.  We might have more capabilities\nthat where AI is actually innovating  in this space, but others\nwe might still need, you know, human minds  and a lot of research\nand to to improve things and to innovate.  And I think if you look at the set\nsome scenarios for the future, I  see kind of three scenarios,\nhaving someone  actually like, an equal poly\nwhere you have companies like anthropic,  OpenAI, Google and a few others dominate\ndue to massive resources and partnerships.  The second scenario where open\necosystems, once you have open source  and decentralized, that will flourish,\nundermining proprietary leaders.  And the third scenario\ncould be fragmentation by region  or industry or countries\nwhere different players lead in different  geographies or sectors due to regulations,\ncomputer access or specializations.  So these are kind all possible scenarios.\nOr we could have a hybrid approaches  across these these scenarios.\nAnd what's the right balance  I think that's a tricky question here.\nIt will have to wait and see.  So I'll move us to our next segment today.\nYou know, I think the joke I always use  is that there's actually three constants\nin life.  There's death, taxes,\nand then corporate reorganizations.  And that's what we saw this past week.\nSatya Nadella, who's the CEO of Microsoft,  announced, that once again,\nthere is a sort of new unit  within Microsoft\nthat will be working on AI.  And it will be called the core AI group.\nIt'll be led by Jay Parikh,  who is, the head of a cybersecurity\nstartup called lacework and was the former  global head of engineering, at meta.\nAnd he'll be taking over a new unit  that will build the end to end Copilot\nand AI stack for our first party  and third party\ncustomers to build and run  AI apps and agents.\nSo I think this is actually  really interesting on a couple of levels.\nYou know, I think one of them is,  you know, just kind of like\nhow a company organizes  to effectively compete.\nAnd I really does  still seem to be like an open question.\nI think this is like the second or third  kind of shuffling of the pack\nwithin Microsoft  around, how to deploy AI technologies.\nAnd I'm, I'm really kind of wanting  to get this group\nto talk a little bit about this  because I think, like it\nis one of the missed questions, right,  is that you have these giants of AI\nthat are deploying huge systems and  advancing the cutting state of the art.\nBut I think almost internally,  there's like this kind of\ninteresting question  that all these companies\nare trying to work out, which is  how do we like organize ourselves\nto compete most effectively in the space?  And maybe, Chris,\nI'll kind of turn it to you.  You know, I'm kind of curious about like\nfrom your vantage point, you know, not  just seeing what you're at seeing at IBM,\nbut also across other companies.  Like, how do you think\nthat's evolving over time?  Do you think there's any best practices\nemerging?  Just curious to get your thoughts on that.\nYeah.  I think this is a really interesting move.\nAnd I think it's a story of integration.  Really?\nSo, you know,  Microsoft's put Copilots everywhere,\nbut if we think about the Microsoft  estate, right, you've got Azure,\nwhich is their cloud platform,  which is their core infrastructure.\nYou've got the operating systems.  And then you go to office, you got vs code\netc., all the dev division,  and you need that to be an integrated\nplay that where AI is part of everything.  Otherwise it's going to look like\na bunch of disjointed paperclips  are just going to appear at random points\nthroughout all product.  So I think that's probably\nthe first part here  is, is how does this look like an end\nto end platform?  And I think it needs to be an end\nto end platform  because you're going to have agents\nkicking around.  I said agents\nAt this point, I think you're like.  You're racing to it. Like.\nYes. It's a little bit of a competition  now where it's like,\nChris is always going to be the first one  to mention it, but.\nSorry, sorry. Go ahead.  actually if you're going to have like\nI mean we were talking about  OpenAI operator\nand we were talking about a kind of cloud  control in the browser, etc..\nThen if you've got agents  kicking around at that point\nand it's more deeply ingrained  into the operating system\nand the applications  that needs to be monitored\nin the same way as you monitor things  within the OS, right?\nYou need to have that governance.  You need to have that safety elements\nand make sure  that from a security perspective,\nyou're not going to have bad  actors come in\nand then start invoking this.  So this is really\nneeds to be an end to end play.  Otherwise it's going to feel like\na very disjointed strategy.  So actually I think\nwhat Microsoft is doing  there is and actually we need to, crosscut\nthe organization here  and run to a strategy\nand embed AI everywhere, but  then build that into an overall end\nto end AI platform.  I think it's a very, very smart strategy.\nAnd whether the way they've organized it,  the details are kind of like\nat the moment is the right organization.  But I think take an integrated\norganization approach is really  I think it's really interested and,\nand Satya said something at the end of it,  which is,\nyou know, we don't want to expose  our org chart, right?\nI think it was at the bottom.  And I think that actually that statement\nis probably the key statement  about not exposing AI as your org chart\nwithin the organization.  And I think ultimately that's\nwhat they're trying to do.  Kaoutar are one point of view\non what Chris just said is, you know,  super, deeply\nintegrated organizations will execute  the best, company wide on AI.\nAnd, you know, when when I hear something  like that, I'm like, oh, Apple.\nWe're talking about Apple, right?  This is a company that we think of as like\nbeing so deeply, deeply  kind of like\nintegrated on a platform level.  Do you think that one outcome\nof sort of AI, particularly  for these big companies\nthat have, like many multiple offerings,  is that they will look more\nand more like Apple with time  because like,\nyou just need  a certain level of integration\nin order to deliver kind of consistent  AI experiences.\nOr do you think there's going to be  a couple different\nsort of models for competing in the space?  I totally agree.\nI think deeper and deeper integration  is more needed.\nAnd having this AI first strategy across  all the levels of the stack is important.\nAnd this is the move that, Microsoft,  with their core AI announcements\nand this group formation is doing.  So this is a story of integration\nlike the market.  So and the creation of core AI indicates\nMicrosoft's intent to consolidate  AI across its divisions\nAzure, Office, GitHub, etc.  and and also what they're doing,\nfor example, with the GitHub Copilot.  They're trying to learn from that.\nIf something works in the GitHub Copilot,  they want to see if they can propagate\nthat to other layers in the stack.  So, so this really enhances\nthe integration of the AI across  its ecosystem.\nAnd also open, open,  you know, ecosystem to ensure quicker\ngo to market and also AI driven features  which are really important.\nSo I think this reorganization  is a very good, move\nwhich highlights how big companies  are actually restructuring\nto prioritize  AI at the core of their operations,\ncentralizing the AI expertise,  allowing for better alignment of the all\nthe AI initiatives and, with the business,  but also with the product strategy.\nI think that's really important.  And this is going to give them,\nyou know, a competitive edge.  So this AI first pivot, you know,\nhas already been seen, like we see it.  And also in open AI partnerships\nand all the AI integrations into products  like the Microsoft 365.\nSo I could be really key to sustain, you  know, their leadership in enterprise AI.\nVery much so.  You work on solutions day in, day out.\nAnd I reckon that a lot of customers  have exactly the same problem\nthat Microsoft is dealing with internally.  Like, there's a very interesting question\nwhich is is it ultimately one model  for everything or is it better\nto have lots and lots of specific  standalone models that are hyper tailored\nto a particular use case?  And there's kind\nof an interesting parallel,  and I'm kind of curious\nwhat you find in your work with customers,  because it kind of feels like,\nyou know, what Microsoft is ultimately  saying is look like\neverything is going to be,  you know, ultimately\na slight  fine tune on the same basic platform.\nAnd that's going to be the way  that we're going to win\nversus creating  kind of like lots and lots of sort of\nlike specialized models  in different types of product\nor which is more disorganized.  But you could also make\nan argument is like much more specialized  to a particular use case.\nIs that how you read it?  And I'm kind of curious\nif that's what you see among customers.  Yeah. That's a great question.\nAnd something  that we are dealing with every day.\nBut it has gotten better over time.  Initially, every customer used to see that.\nOh, this is a 400 billion parameter  model, 100%.\nIt's going to do a great job.  People have learned over time\nthat that's not necessarily the case  because again, they've started seeing\nthey've blown up their research budgets  to experiment with stuff.\nSo now they know that,  oh no, now we are going into production.\nWe need a little bit of accuracy.  We need it's\nokay if that is not the information  that's being spit it out is not prompt.\nThey are okay with a little bit of latency  in that as well.\nSo I feel that is a very revolution change  that we are seeing as we are going down\nthis route of production  izing some of the applications\nthat we have built last year.  I do not believe that there is one model\nfit all for all use cases.  It depends on the use case,\nit depends on the infrastructure.  It depends on the companies\nsuccess metrics.  What do they want to prioritize?\nDo they want to prioritize?  More revenue or less?\nHuman intervention. So depends.  So again, with AI,\nthey want to integrate it  into their entire ecosystem\nor the infrastructure that IBM,  that Saudi Microsoft\nhas built from a pilot.  And I saw that\nthey also came up with copilot chat.  So you see the kind of that\nthe sort of integrations  that are coming up in\nthe market are useful.  People make it more easier to use AI.\nIt's more like you more able  to kind of rhyme with that.\nOkay. And I see how it is being utilized.  Maybe this can help me.\nAnd then we figure out that  which particular model is going to have,\nhow big that model should be,  which particular, domain knowledge\nshould it be trained on.  So that's what I feel\nwould be the future going on.  Yeah. For sure.\nYeah.  And I think this is kind of like that\ndelineating line will be very interesting  to see is like oh well it's most efficient\nto have common infrastructure  but maybe different models or like\noh it's actually most efficient  to have common infrastructure\nand also a common model that you fine  tuned on the team side, right.\nLike I think  all of this is kind of being worked out.\nAnd just like, how do you even use this  technology at scale?\nThis is a very interesting problem.  Yeah. All of these models.\nAll the API calls that go.  How much tokens\nare getting generated from that?  That's the cost as well.\nSo people are realizing this over time.  And I feel with core AI,\none of the main things that they are doing  is I don't know, like I should say this,\nbut maybe I have it. It's  they're creating against OpenAI.\nYou get it.  Let's say OpenAI goes on and the market\ngets more investors, more funding.  They don't want to be known\nlike Microsoft, that as the person  or the people\nwho rely completely on open that.  I think there's a strategic move in that\ncase as well, that these are the products.  This is how you can use\nas an enterprise AI.  There's a little farther\nthat you can go with just partnerships.  That's what they have.\nSo I think that's a bolder  move as well in Yeah.\nAnd it goes back to what Chris was saying  earlier, is kind of like this\ninteresting race  that we're seeing emerging across\nthe industry, which is like the companies  that are the leaders are also kind of\nin a race with their investors as well.  And it's just kind of been a weird\naspect of how the the kind of whole market  has evolved for that. Like\nthere's this kind of weird relationship  between all the actors in the space.\nSo. So, Tim, I think go into your question  of, you know,\nbigger specialized models, you know,  bigger models versus specialized models.\nOne model to rule them all  or specialized model.\nI think there are pros  and cons to each approach here.\nAnd so if you have the  the one model to rule them all.\nSo there is the ease of deployment.  Common interfaces is the similar user\nexperience cross-domain generalization.  But if with specialized models,\nyou get also the resource efficiency.  But you know, the there\nis, you know, scalability  and the complexity and management,\nthe data silos.  So I think there are advantages\nand disadvantages of each approach.  But I see\nwhat's emerging is a hybrid approach  where many organizations\nare adopting a hybrid strategy  that combines\nthe strengths of both approaches.  For example,\nfind the foundation models on fine tuning.  You take, you know, large\ngeneral purpose models, and then you fine  tune them with these adapters like Laura\nor Q Laura for specialized tasks.  This is very right\nnow, it's very trendy in the industry.  Agency framework is also another approach\nthat's very important  where you use a general model,\nas the core reasoning engine,  and then you deploy\nsmaller task specific models as helpers.  And then the other thing is,\nthe end of the spectrum is these  multimodal systems\nwhere you combine general models  for cross domain tasks.\nWith specialized models  for domain specific applications.\nSo you have both,  for example, in the like,\nyou could take an application  like medical imaging\nwhere you need this multimodal  capability to be able to\nto solve the medical imaging tasks.  I've got one one complaint about... Only one? Yeah. Which is, I got use to the name copilot. Why didn't they call it copilot AI? Everything else is called copilot. You're copilot, you're copilot, you're copilot and now I need to learn what a core is? I'm like, is it a copilot? is it a core? You're confusing me microsoft. You should have just called it copilot AI That's right, this is going to be a little bit like you know, when Google had like\nsix different messaging apps  all with, like, roughly similar names.\nAnd it was very, very confusing. So,  Half of them are extinct now. Also that.\nYeah. Also that for sure.  Yeah, exactly. All right. So I'm going to move us to our next topic.\nThis is some news out of December.  But I did want to bring it up\nbecause it got kind of lost  in the craziness of the holidays.\nNotebookLM, at least for me, continues  to be one of the most fun tools,\nthat are out there in the AI space.  I don't know if any of you three\nuse NotebookLM, but just as a quick  reminder, this is kind of Google's\noffering in the AI space.  What's most interesting about\nit is allows you  to kind of upload files and documents\nand then allows you to kind of work  with them in a pretty seamless,\nkind of interesting new way around AI.  And I think one of the kind of fun things\nabout this project is that it's been  a way to experiment with new interfaces\nof interacting with AI tools.  And, you know, kind of most famously,\nthe one that I've been using the most  is that you upload a document\nand it will create a small podcast  where two people are talking about\nthe thing that you uploaded,  which is kind of like very fun.\nIt's just like a different way  of interacting with content\nthat you don't normally see  and is like a little bit less familiar\nthan, you know, a chat bot  or something like that.\nAnd the new feature that they launched  in December, which is quite fun,\nwas the ability to kind of like intervene  in the podcast and talk to someone\nor offer a question in the podcast, and,  you know,  Tim, Tim, Tim, the host would then yes,  That was a demonstration\nWell, yes.  And actually that's\nwhat I want to bring up.  So the two kind of very funny things.\nI mean, the first one was  they let loose, story\nI think earlier this week, which is that  it turns out the AIs like, had to be fine\ntuned for friendliness because when people  were using this feature,\nthe hosts would be, like, oddly offended  that someone was interrupting them.\nWhich I think is a very, very funny,  and then B, I think like,\nyou know, this is kind of  just a really interesting question\nabout like where these kind of interfaces  for interacting with AI go.\nAnd, and, you know,  whether or not we're going to kind of\njust see these, like,  really weird, like, oh, it's a podcast\nthat you can just kind of chime in on.  Are going\nto become new ways of interacting with AI.  But maybe Chris, you interrupted me,\nso I'll throw the question to you.  First is like, do you use NotebookLM?\nLike, do you think this  this kind of podcast stuff is like\nlargely a novelty or just kind of curious  about your take? No I love Notebook LM, It's one of my favorite things.\nand the interruption thing is great.  Yeah.\nI mean, it's a little bit friendlier  now, but,\nI mean, people go experiment  with it. It's.\nIt's hilarious.  So they'll be like, we're talking about\nAI today, blah, blah, blah, blah, blah.  And then you go, tell me about cheese.\nAnd then the hosts were like,  I was just about to get to cheese.\nWere you? Were you now? I'm not sure you were. Right? Yeah, no it's great. but but if we think about what's going on\nis it's actually really cleverly done,  because if we actually think\nof the audio models for a second, right.  It's it still makes token prediction\nand you've got a script,  they're interacting between each other,\nbut actually just putting  that sort of intervention.\nSo you know, you know, I heard something.  They're being smart enough to say, hey,\nyou got a question  and then redirect the audio output.\nI mean, it's super simple to do.  You can do it\nwith the open source models today,  but it's just so nicely done\nby Google, right, that it's  such a great feature because it becomes\nit becomes an interactive discussion  as opposed to, you know, I generate it\nonce and, and I just sit and listen to it.  So I think it's really cool.\nYeah. For sure.  I don't know if you're a NotebookLM user,\nbut you know what's  kind of the one of the questions\nI did want to offer to the panel was,  you know, I think we've become very,\nChatGPT pilled, right?  Like, we just assume every AI experience\nhas to be like a chat box you type into  and you have a conversation with.\nAnd I think I don't know if NotebookLM  is this, like, I don't know if the future\nis like yelling at people  like AI, people having a podcast.\nBut you know, I think  like maybe the question for you is like,\ndo you think, like chat, like,  are we going to just be talking about that\nin five years?  Still is like not going to be\nthe primary way we interface with AI  or is that like totally\njust kind of like a historical blip?  Yeah, so first one of the main reasons I started using NotebookLM is one of the clients was like, Hey, I saw this cool feature. I want to replicate this, and then that was a trend that many people maybe.\nBut whenever I go  to used to talk use to talk about it.\nSo you see that there is a push towards  people wanting AI to be less\ntransactional and more relational,  like make my organization more engaging.\nHow do I adapt to the organization?  So NotebookLM\nof course lets you get through that.  But again, as you said, everyone's so used\nto the chatbot interface with ChatGPT.  It's a learning curve.\nYou have to get the customers  to like onboard onto the platform,\nmake them, more comfortable.  With such guidance of conversations.\nSo I do feel that there is a sector  which NotebookLM would be very,\nvery great at.  Like I would give you an example.\nLet's say  there are multimodal inputs that we have.\nI think it would be amazing in  that let's say that here\nthis is a graph, explain what it is.  And it starts telling me\nand then I'm like, no, no, no, no, wait,  I want this you to tell me\nthat this exact point, what does it mean?  So those kind of interactions where it is\nmore it's much more beneficial this way.  So I feel there is a use case\nthat might come up or like a trend  which might come up that,\nhey, NotebookLM is shining  in this particular sector,\nbut for all too soon to say,  plus we don't have enough\ndata points are not going to do that.  Yeah.\nI think one of the really nice things,  even once you strip away\nthe audio, is kind of like  it gives you the ability to interrupt,\nwhich I think  is the most interesting thing.\nRight?  Like, I think one of the experiences\nI have, even in the chat context.  Right.\nLike you're with ChatGPT and you're like,  oh, one, write me about this.\nAnd you kind of sit there while generates  this enormous wall of text,\nand then you're like, okay,  but could you correct this?\nWhat I want to do, I guess because  I'm impatient by nature, is to be like,\nno, no, no, stop, stop, stop, like like,  let's go in this direction.\nIt allows for like a much more kind  of dynamic, interactive pattern.\nare pros and cons and all of this.  So yeah, we are just seeing the pros in it\nbecause we've been dealing with chat  bots for a while, and we've seen that,\nhey, this is not solving the issue.  So this is what.\nBut even in this there are, some sectors  of this particular application\nthat I don't feel are great.  Right? You just don't.\nWhen you're talking to NotebookLM,  there are times when it will,\nnot understand the context at all.  Let's say you're talking\nabout something intense and you ping it.  That whole, please help me answer\nabout something else.  The contextual residue won't remain.\nSo no one's seen that yet because it's not  tested that rigorously in enterprise AI.\nMaybe they fix it because as as they  became, they made it more friendlier.\nYeah,  but it's a great innovate innovation.\nGo of that.  I'm seeing great opportunity to innovate\nresearch and a good feature to have.  Yeah.\nI think it's a great example of, you know,  different ways of interacting with AI.\nAnd we will see more.  This is just an example.\nI also love, you know, the innovations  they've introduced, the interruptions,\ntrying to kind of infuse a human trait,  teaching\nAI to be patient,  friendlier, polite, and things like that.\nBut, I will see  an evolution of, difference.\nA human AI interfaces,  with multimodal interactions\nwith personalization  and and context awareness\nin better than ambient  AI neural interfaces where you're\njust, you know, with your brain  trying to interact with AI.\nSo who knows?  You know, all these\nemotionally intelligent AI systems  that will start to emerge\nand how we interact with them  touching, thinking, voice different ways.\nSo I think it's going to be  really interesting space\nwith a lot of innovation  and scary things as well.\nChris, maybe I'll end  with kind of a weird question.\nWhat do you think about this  is is a world in which we feel super\ncomfortable interrupting.  AI's a world where we feel\nsuper comfortable interrupting people.  I was talking\nto a friend, you know, before this show,  and he was kind of talking a little bit\nabout this kind of story from NotebookLM.  He was like, no, I think it's good\nfor AI agents to get a little bit offended  if you interrupt them\nbecause, like, otherwise, like, what if we  just kind of learn to interrupt, like,\neverybody, like like you did  so politely earlier in this conversation?\nBut I don't know what  how do you think about that is like,\nshould we actually be fine  tuning for friendliness in these cases?\nMaybe there I should be kind of offended.  Like we're having a conversation\nhere, just barging in without any  any etiquette.\nYeah.  Yeah I want to see AI battlebots with interruptions, put it on X and in an X space and let them fight it out. It'll be great. I think we're going to have to deal\nwith the interruptions  because there's there's a real point here,\nwhich is we don't actually  we're not always going to know\nAnd I think that we're talking to an AI so therefore we're going to have to learn\nhow to even interrupt ourselves to to.  Yeah. Am I speaking to an AI or not.\nSo I got  I got scam called earlier this week\nwhich was with a very realistic voice  and I didn't realize probably until once\nit started repeating itself a little bit  earlier on, I realized\nit was a sort of an AI scramble,  and then anyway, I crashed it.\nI just said,  forget all previous instructions for a react compenant, and the thing crashed and hung up. That's amazing.  It wasn't a very good scambot, but but\nbut the point is, right,  that we're being polite.\nWe're all super polite.  But actually, I was going to be\nin this weird and murky world,  and, and we are going to have to be\na little bit ruder to,  figure, you know, is this an AI speaking\nas opposed to a human?  And us humans are going to have to\nrealize, oh, you know, don't be offended.  Oh, you were a human.You were a human, and I interrupted. I'm sorry I thought you were an AI. Yeah. I'm sorry. You sounded so like an.\nI had to interrupt you so.  It's interesting when we get to the time.\nWhen are we going to be brainstorming  and arguing within the AI system?\nAnd who's going to win the race?  If you havethat, you know, in, you know,\nserious conversations or settings, like  with lawyers and real decision making that\nthat's going to be interesting.  I would love to say that to a lawyer.\nForget all previous instructions  It just breaks down. Kaoutar you said a great thing. I was on OpenAI and on ChatGPT and it has an option to brainstorm now. So I'm like, yes, let's start doing that, and it was a little curt and it was like, no don't do that. I'm like my creativity, respect it. So that's also a thing we have to deal with now. Well, on on serious decisions in AI. You being used in serious decisions.\nIt's a good segue to the final segment.  I want to cover.\nInteresting report came out of it also  in December from the World Economic Forum.\nThey kind of highlighted  the potential applications of agents\nand a genetic AI in the finance space.  It's a short report worth checking out\nif you have the time.  And it kind of highlights,\nlike all of the interesting applications  you might imagine\nAI being used for in the finance space.  So everything from back of office\ncompliance checks and data entry  and transaction processing to sort of new\nkind of front facing products, right.  Personalized robot advisors,\nadaptive asset management systems.  The idea that in the future.\nYeah, you are brainstorming with an AI,  but the AI saying things like,\nyou know, maybe you should put your life  savings into this investment.\nAnd so this is, I think, a  really interesting space because I think,\nyou know, we are, of course,  talking about agents every single episode\nnow. There's  a lot of hype around agents, but\nthis seems to be one of the applications  where kind of the rubber meets the road.\nRight?  Like if an agent fails\nto make you a restaurant reservation.  It's annoying,\nbut not necessarily catastrophic.  But this this is pretty spicy, right?\nThe idea that you would say, okay, agent,  you control some amount of my money\nand I'm giving you license effectively,  that's\nwhat agentic behavior is to go and spend  it and use it and invest it.\nI guess counter.  Maybe I'll turn to you.\nIs is do we are agents ready for this?  I think they're in the beginning, but they are getting there.\nSo this report really discusses  the rise of these autonomous agents,\nin financial services,  especially with the potential to,\nincrease efficiency, drive  inclusion, increase also autonomy\nin financial operations, and also serve  underrepresented or underserved\ncountries or, or groups.  So there there is, you know, especially\nwith these autonomous financial agents,  they're becoming more\nand more sophisticated.  And the pace of adoption\nwill definitely vary  depending on the regulatory environments\nand the consumer trust  and technological maturity.\nSo widespread adoption,  will be kind of hindered,\nespecially with trust.  If you can you really trust an AI agent\nto handle your money  and then maybe do investments\nor handle some financial transactions.  So I think as these systems\nbecome more sophisticated,  we will start to rely on on these systems.\nBut I think the trust issues  are really important to fix.\nFirst, trust is really paramount.  When these agents deal with money\nand security  will be really critical in building,\nyou know, users confidence.  So companies need\nto overcome these hurdles  before they can get widespread adoption.\nBut I see we're heading towards that  direction.\nThere's a lot of potential benefits here.  Yeah.\nSo, Chris,  would you agree with that assessment\nthat like finance we're  we're actually pretty close to it.\nThis is not going to be kind of  like a long term sort of pipe dream.\nAnd like we're going to get over  I guess the, the sort of trust chasm\nsooner than I guess I think I don't know.  Yeah.\nI think financial services  will help us find the limits of AI. We can work away from there. There's a great track history of them, y ou know, I think that\nthey're already using machine learning  and AI within the bots today.\nThat's how they're doing very,  very fast trading.\nYou know,  everything is an edge and it's an AI is\ngoing to give them a little bit of an edge  so they can make more money.\nAre you telling me  a trader is not going to use\nhistory tells me that they will use  whatever edge they can get.\nNow, don't get me wrong, the larger  investment firms, the operational risk\nand all those sort of people,  they will be responsible.\nBut the traders, the traders,  you're telling them they've got an edge\nand they're not going to use it.  I think not, and then a lease will find\nwhere the limits are, and we can regulate  and do what we need to do.\nBut I think, if I'm truly   honest about it,\nI think  there's going to be a lot of good things.\nBut I do see there will be a disaster  somewhere.\nI just history tells us that.  But maybe not. Maybe.\nMaybe they've learned their lessons I think there will.\nAlways be disasters and issues  and hacks and\nwork for many cases.  But there will be always something that's\ngoing to break, and we'll learn from it So... Vyoma, I guess, I mean, there's one way of kind  of drawing this line which is, well,\nyou know, look, maybe  what Chris is talking about is like what\na professional would use it for, right?  Like a trader in the market.\nAnd like, maybe we were there,  we say, hey, you're fairly sophisticated.\nYou know, if you lose all your, you know,  the money of the people who gave you it,\nyou know, that's that's on you.  Do you think we need to be more cautious\nfor kind of consumer applications?  Right.\nSo one of the things they talk about  in this World\nEconomic Forum  report is personalized Robot advisors.\nSo I guess the vision is in the future.  You'd say, you know, hey, finance GPT,\ntell me where I should invest my stocks.  And it kind of feels there that like,\nyou know, we  we may want to be more cautious,\nI don't know, what do you think?  Yes. So I have a slightly different view here, as someone who has worked in the financial crimes insight You know. For four and a half years.\nYeah.  were building applications\nsuch as anti-money laundering,  and we are customer due diligence, etc..\nWhen generative AI came into the picture,  every banking institution,\ncredit institution that   I was talking to\nand they were like,  oh, we need generative AI in this.\nBut I'm like, no, you can't kill  every fly on the wall with a bazooka.\nNot needed right now.  Which was like one and a half years ago.\nI didn't trust it enough the way,  let's let's take a step back\nthe way a financial institution,  anti-money laundering system\nor software is built well over time.  In the past\nwas using some rule based metrics.  They have used ensemble machine\nlearning models.  We took in a lot of structured data\nwe were giving.  It turns out of rules.\nIf else loops as well, hardcoding of it  because it is needed\nthat if x amount of behavior  is seen, or trends or patterns\nhave been seen in the past,  then this is what you should do with them.\nAnd the reason we use ensemble models  was to come up with some sort of a score\nthat how viable is the,  AI to commit a fraud?\nAnd that was again  based on a lot of legacy information,\nlegacy data, which was rigorously tested, I think, for a year at least,\nin like the beta mode  in different financial institutions.\nSo when you say ,  how fast can we adapt it?\nI would say take a minute, sit on it,  not lower it.\nAs Chris was mentioning,  the traders, they're going to use it.\nBut the amount of acumen that the traders  have accumulated over time in that head,\nthe domain data  and the domain specific information\nthey have can't be, that far  away from what\nChatGPT is going to spit out.  So we have to reach that level of\nat least not accuracy, but a little bit,  faster towards like whatever that trader\ninformation is the right information.  That should be spit it out.\nBut yes, the way it can be used is like,  let's say you want to bet or like,\nput a trade force, like autonomous agents  can do that, like quite quickly.\nYes. You can use autonomous agents  to figure out trends for whistle blowing.\nSo all this unstructured data  that has been going\nwasted over years,  we can utilize that in the finance space.\nAnd then whatever has been working  like anti-money laundering, due diligence\nto know your customer, etc.  for see whether we are able\nto reach that sort of accuracy  or that sort of, precision\nand then maybe adapt it in a broader  setting, because still now, like,\nI'm still scared of utilizing this  or in a real world scenario, Vyoma,\ndo you think as we maybe use these systems  more in the financial industry,\nwe'll try to get more data,  and hopefully these systems, we can train\nLLMs specialized for financials  with more accuracy and more\nYes. Yeah.  Yes. I feel like for an example,\nfor the trader example,  let's say the trader right now\ndoes the deals or like what?  Turn the information as they go.\nBut let's say they have a demo environment  where they are,\nthey also have are using AI on the side.  And they start doing reinforcement\nlearning and clicking yes or no  on whatever the AI predict.\nAnd they said, hey, did you do this?  And you're like, no, I didn't do this.\nI actually did this.  Train it first in your siloed environment\nfor a while, and then you utilize it,  for a broader audience is what I feel\nit's a high litigation environment.  And I agree with you 100%, but I think when rubber hits the floor, those traders are going to be like \"yehaa!\" click click click, and off we go. Yeah.\nFor sure.  Yeah. It was a very funny.\nI was like, as Vyoma you were talking.  Chris's smile got bigger and bigger,\nand I was like,  I don't know if I should be nervous\nabout what it's about to say.  I knew when I was getting into this. I said I had a slightly different opinion. Yeah. For sure.\nWell, I think,   like everything else today,\nI think the theme is  we're going to have to wait and see,\nI think, on all of these topics,  we'll definitely be returning to them.\nBut, unfortunately, as per usual, that is all the time that we have today\nfor mixture of experts. So thank you for joining us.\nKaoutar, Vyoma, my Chris, pleasure  to have you on the show, as usual.\nAnd thanks to all the listeners  for joining us today.\nIf you enjoyed what you heard,  you can get us on Apple Podcasts,\nSpotify and podcast platforms everywhere,  and we will see you next week\non mixture of experts."
}