{
  "video_url": "https://www.youtube.com/watch?v=86rz0mV3jZE",
  "video_id": "86rz0mV3jZE",
  "title": "DeepSeek-R1, Mistral IPO, FrontierMath controversy, and IDC code assistant report",
  "upload_date": "20250124",
  "channel": "IBM Technology",
  "duration": "39:44",
  "caption": "At the end of 2025, is DeepSeek\nleading the state of the art in artificial intelligence? Abraham Daniels is a Senior Technical\nProduct Manager with Granite. Abraham, welcome back to the show,\njoining us for the second time. What do you think? They're definitely making a splash\nin the open source, uh, space, but you know, it's, it's a really\ncompetitive, uh, landscape, so I guess we'll have to wait and see. Kaoutar El Maghraoui is a Principal\nResearch Scientist and Manager at the AI Hardware Center. Kaoutar, I feel like you're\nbecoming a regular here on the show. Uh, what's your take on this question? DeepSeek is definitely reshaping the AI\nlandscape, challenging giants with open source ambition and state of the art\ninnovations, but talking about leading, I think that's remains to be seen. It's not just about the raw performance,\nbut it's also about the whole integration. And finally, last but not least\nis Skyler Speakman, who is a Senior Research Scientist. Uh, Skyler, welcome back. What is your take? Um, amazing technology. Great splash, as we said earlier. But I think there's really some\nreally big geopolitics at play on how these models really get developed\nand are used across the world. All right. All that and more on\ntoday's Mixture of Experts. I'm Tim Hwang and welcome\nto mixture of experts. Each week, MoE is the place to tune\ninto to hear the news and analysis. on some of the biggest headlines and\ntrends in artificial intelligence. Today, we're going to cover\nquite a lot as per usual. We're going to talk about Mistral,\npotentially going IPO, uh, controversy around the FrontierMath benchmark,\nuh, and a recent interesting IDC report on generalized versus\nspecialized coding assistance. But first, I want to start with DeepSeek. Um, so just this past, uh, last week\nor so, um, DeepSeek released R1. And if you recall and you're a listener\nto the show, you know that just a few episodes ago, I believe we were\ntalking about DeepSeek v3, uh, which is their release, uh, which at the\ntime I think kind of blew everybody's mind where they were showing really,\nreally incredible performance with incredibly sort of less compute. and costs than what we're\ntraditionally used to in the AI space. And with R1, um, it basically is\nDeepSeek's pretty fast on its heels release, showing that it has performance\ncomparable with kind of state of the art stuff coming out of OpenAI,\nspecifically to wit, uh, o1 and kind of the inference compute sort of techniques\nthat really seem to give it a bunch of, um, sort of benefit, uh, for that model. Um, and so I guess maybe Abraham,\nI'll, I'll start with you. Do you want to talk us through a\nlittle bit about like why this is a big deal because I remember when, you\nknow, o1 was released, people were like, this is a huge innovation and,\nyou know, really shows that OpenAI has this big technological edge. Pretty soon afterwards, it\nseems like DeepSeek's doing almost the same thing, though. So I don't know if you want to\ntalk our listeners to like, how do they, how do they do that? How do they catch up so quickly? Yeah, that's a great question. Um, so I think there's kind of two\nthings that are really cool here. One is, of course, just, you know, the\ncomparative performance with, you know, a state-of-the-art kind of, leading\nedge, bleeding edge model, like, uh, o1. But, um, unlike o1, it's been pretty\ncool that DeepSeeker has decided to open source it, which, you know, has\nbeen able to kind of proliferate some pretty powerful models across the\ncommunity without the blockage or, you know, added need for commercial license. So I think they're really kind of\nshifting the paradigm, given a lot of these model providers are starting to\nslap on more, um, you know, specific licenses that are tailored to more\ncommercial practices, given, you know, the business model that they're in. So I think it kind of shifts\nthe idea of, you know, what does it mean to be transparent? What does it mean to be open\nwithout having to risk performance? Skyler, it strikes me a little bit that\nlike, I think when we've talked about this issue in the past, you know, we've\nreally talked about it in terms of. You know, OpenAI versus\nMeta, you know, right? And Meta's trying to kind of go\ncompete with OpenAI by releasing these incredibly powerful models open source. This almost feels like\nnow like everybody's after OpenAI exactly the same way. And obviously the distinction\nhere, which is pretty interesting is you know, DeepSeek is, is\nnot a kind of classic player. It's not a big tech player. Um, so do you want to\nspeak a little bit to that? I know you kind of mentioned that,\nlike, you think the competitive dynamics here are really interesting to watch. So, uh, first off, I think we'll get to\nthe competitive dynamics in a bit, but reinforcement learning back on the scene. And I know it was, it kind of sort\nof died out for a while when, uh, uh, deep neural networks really took over. But, there now are multiple companies,\nand I think DeepSeek is an example of making it quite public, of bringing this\nback into, uh, the large language models. So, uh, cool to see these ebbs\nand tides of various parts of AI and machine learning come and go. Uh, so that's kind of more\non the technology side. It's really cool to see some of\nthese things, uh, pop back up. Yeah, totally. And I guess a quick comment on that. I mean, I think it is funny that, um,\nyou know, for DeepMind, right, which originally made its bet on reinforcement\nlearning, I think the rhetoric of the last year was, ah, they made the wrong\nbet and now they're trying to catch up. And now it's like, were they just really,\nreally far ahead of everybody else? Like, I don't know. Yes. No, great comment. There were, there was this big push\nin reinforcement learning before, I think the transformer basically. And now these things seem to be, uh,\nyou know, I'd say cohabitating, or at least, uh, being, uh, being in the\nsame technology, uh, DeepSeek's has shown that they can put both of those\ntechniques into the same package. And I think that is a really\ncompelling argument, uh, for their strength going into 2025. Kaoutar, maybe I'll turn to you. I know out of the kind of set, uh, of\nfolks on the panel, you know, I think you sounded the most, uh, sort of,\num, you know, cautious about DeepSeek. Um, you know, I think there's\none point of view, which is, oh man, they're releasing V3. That's incredible. Not like a month or so later,\nyou know, oh my God, now they're releasing R1, you know, they're,\nthey're catching up so quickly. Uh, you know, I guess there's a, there's a\nway the human mind is just like, well, if we continue these trends, then, you know,\nAGI by the end of the year from DeepSeek. Um, Do you want to speak up a little bit\nabout why you're still ultimately kind of skeptical that, you know, DeepSeek,\nthis is like the arrival of a genuine deep challenger to something like OpenAI? Yes, I think the key question\nis, what advancements does R1 introduce compared to V3? And how does it compare to o1? Are we talking about incremental\nchanges or really like through innovations and new things that\nare leapfrogging the AI community. So they're claiming that they're improving\nthe search precision, the scalability, the usability, while their V3 release\nfocus on optimizing the core algorithms. So they're saying that R1 has\ncapabilities, you know, such as better contextual understanding,\nand especially for these complex reasoning tasks, which makes it\ncompetitive, kind of toe-to-toe with R1. So, so I think we need still to test\nthese models to see really whether they're there because this is a new\nrelease, so it still remains to be tested and to see what capabilities\nthey're really bringing to the table. And how do they really compare with o1? I mean, they're showing some of\nthe benchmark that sometimes, you know, they exceed o1. So I think something that\nneeds to be validated. Um, But one thing that I'm a bit\nskeptical about is, you know, I think o1 still benefits from their\nproprietary integration with enterprise grade features, which R1 might lack. So, and that's something that still\nneeds to be tested and evaluated. So, uh, you know, the, and another\nthing is, what are, what's the broader implications, you know, in this rapid\nintegration for open source ecosystem? You know, the release cycles are, it's\npretty impressive, they're very fast. cycles. And, you know, this release space\nshow showcases the power also of community driven innovations. However, maintaining quality while\nscaling adoption remains a challenge here. And, you know, the open nature of DeepSeek\ncould accelerate AI democratization, and it's also challenging the big players like\nOpenAI so and putting, you know, kind of pressure is visually that they're coming\nwith very competitive pricing much cheaper compared to a one OpenAI's pricing. So I think it still needs remains to\nbe validator, whether we're really talking about true innovation that\ngoes, you know, kind of hand in hand with what one is doing or even better. So that needs to be still validated,\nbut I still think, you know, the fine tuning capabilities, the integration\nwith the enterprise enterprise use cases that probably are still lacking there. Yeah, for sure. I guess, Abraham, that's like a very\nnatural place, I think, to turn to you. You know, what I hear in Kaoutar's\nargument is kind of the idea that the models are going to become kind of more\ncommodity with time and sort of the competitive edge is integration, right? Which is, well, OpenAI can kind of\nwin now because it's like hooked into all these other types of systems. And that's actually where the advantage\nis, you know, as someone who's working on Granite, is that kind of how you\nsee, see the market or I'm kind of curious about your response to all that? Yeah, I think there's kind of\ntwo people that we gear towards. There's the commercial users, you know,\nwhere, you know, they're, they're really focused on enterprise use cases, ensuring\nthat there's proper governance wrapped around the model and demonification\nand just that safety and support. And then there's the open source\ndevelopers that, in my opinion, kind of dictate what is the best on the,\nyou know, outside of benchmarks, which, you know, to Kaoutar's point\nis, is, is not always exactly what it seems, you know, our developer\ncommunity really dictates what the best is given what the adoption rate is. So, um, I think over here at Granite,\nyou know, we're focused on open source, so I think DeepSeek is a phenomenal play\nin terms of being able to open up the aperture when it comes to some of the\nmost performant models on the market. Um, and honestly, I'm looking forward\nto kind of seeing what this, what comes from this in terms of the learnings\nthat are shared and, you know, how developers in the community actually\nstart to use, uh, o1 to start to, you know, develop new ways, uh, of, uh,\nyou know, creating, uh, creating, um, to your point, like applications and\nspaces where this model can perform. Yeah, I think really to, to truly lead,\nyou know, LLMs or these, um, you know, large language models need to move just\nbeyond the role benchmarking performance. And to really reach true innovations\nthat you have to innovate across efficiency, ethical framework, specialized\nadaptability, ecosystem support. So pushing the boundaries, not\njust in AI, but also how it's going to transform human interactions,\ntechnology, enterprise applications. So it's really a story about\nend to end integration while being safe, being ethical. So that's, you know, when you can really\ncan claim true leadership in the AI space. So a full story of integration, not just\nlooking at the benchmark performance. Benchmark performance is, I'm not\nsaying it's not important, that's important, but I think integrating it\nfull end-to-end and meeting all the regulations, safety, and the ethical\nconsiderations will be really important, uh, drive adoption, wide scale adoption. And if I may just add a the release\nof the DeepSeek did come along with a number of distilled versions. Um, so just to the point of adoption,\nlike, you know, the 650 billion model is not gonna fit everywhere in terms\nof compute use, you know, availability. So the fact that DeepSeek understood that\nin order to adopt the model, you have to have, you know, different weight classes\nfor different use cases, I think that just adds to, you know, their story as well. Yeah, totally. Sounds like Skyler wants to get in. I think Skyler also, before your\nresponse, if I can prompt you a little bit is, um, distillation. You should explain a little bit\nwhat distillation is, because I think it is super important. It's going to totally change a lot of the\ncompetitive dynamics in the space, but, um, you know, even I have kind of like\nthe barest understanding of what it is. So I think probably you should\nstart with an explanation of like, what does it mean that they've\nreleased a bunch of distilled models? And then, and then you should do\nwhatever hot take you're going to do. All right. I'll, I'll try not to get\ninto lecture mode too much. Knowledge distillation is when a much\nlarger probably a much more complex model is used as a target for a,\nuh, smaller or less capable model. So what do I mean by a target? Hopefully our users understand the idea\nof the next token prediction task, right? You have to complete the\nrest of the sentence. Knowledge distillation doesn't care\nquite as much about predicting the next token, but rather taking a smaller model\nand asking it to match the internal representation of a larger model. So before that larger model gives\nits answer, it has its own internal representation of the answer. Now we are tasking the smaller model to\nmatch that representation rather than making a prediction of another token. And actually last year, Llama showed great\nresults of getting Lama 3.2, I believe. Smaller through knowledge distillation,\nbut what's different here is they are now fine tuning a Llama-based model, but\nthe larger one is coming from DeepSeek. So this is kind of, uh, you know,\nspending across different companies here in different ways of training\nthe original DeepSeek model. Way too large to actually run\nin a lot of circumstances. But as part of this release, they\nalso have Llama-based models that have been fine tuned as guided or as\ndistilled from the DeepSeek model. And I think that's something that was\na very, very smart play because people are used to kind of the Llama sizes and\nyou can, uh, Llama APIs, and these seem to be plug and play with those existing,\nuh, with those existing tools already. So knowledge distillation is a way of\ntaking a much larger, much more complex model and using it to guide the training\nprocess of a smaller, um, uh, smaller model that uses a lot less VRAM and\nmakes a lot of the users much happier. Yeah. I think I like the analogy of\nthe teacher students model. Think of the Big model as a teacher\nand the smaller models as a student, and they're just trying to mimic like\nSkyler said, the internal representation and mimic the final answers while\nstill having much smaller footprints. So I'm going to move us on to our next\ntopic, Mistral, the French open source AI company, um, was recently, uh, appeared at\nthe World Economic Forum happening Davos. Um, and uh, sort of after much rumors\nconfirmed that they were not attempting to sell the company or be acquired,\nbut instead we'd be pushing for IPO. Um, and I think it's a kind of nice\nopportunity to talk about Mistral because, you know, I remember like many\nmoons ago, and by that I mean, I don't know, 18 months ago Mistral was like\nthe thing that everybody was talking about in terms of open source AI. Um, and candidly we haven't really\nheard from them in some time, right? Like we haven't talked about Mistral\nat all in the last, say, 10 episodes of Mixture of Experts and open source\nseems to have appeared to become much more dominated, say by Meta. And I guess the question I wanted\nto kind of ask the panel first is. You know, uh, is open source\nreally Meta's game right now? Or do, is there kind of a chance for\nthese kind of like earlier players that really moved along open source\nAI in a really big way in kind of the early innings of this game? Um, you know, do they still\nhave a fighting chance here? Or is it really kind of\nMeta's game in some way? Um, and Abraham, maybe\nI'll toss it to you. I'm curious about what\nyou think about that. Uh, I mean, in short, I don't\nthink it's only Meta's game. Um, so the, the most recent Llama\nlicense, although it allows for open source there are some intricacies in\nterms of, you know, you do have to model nomenclature has to include Llama. So they do still wrap some, you know,\nuh, restrictions around how you use your model, especially if you are,\nyou know, an IBM or a different model developer that wants to distill, uh, you\nknow, DeepSeek into Llama, so I think the, I think the market is still open. IBM is 100 percent\ncommitted to open source. Our entire roadmap will ensure that\nour dense models and our ML models are released on Hugging Face, uh, fully\nopen source under Apache 2 licensing. So, um, personally, I think it's, you\nknow, I think the market is still, uh, the field is still kind of open to, to,\nyou know, who wants to lead that charge. And just based on our last conversation,\nyou know, obviously DeepSeek now entering the space with, uh, you\nknow, extremely high, extremely high performance model it's, uh. I think right now it's just like, you\nknow, who's committed to it more so than, you know, who owns it right now. Skyler, do you agree with that? Yes, I do. I'm rooting for them. I think, uh, perhaps, um, I\ndon't know, living in the global majority, I do pay more attention\nabout where these models come from. And so I'm, I am rooting for models\ncoming from, uh, EU or any of kind of the kind of non-traditional large players. So, uh, I great to see them, uh, you\nknow, not at least being up for sale. Um, you know, we'll see how\nlong that that stays out. But yeah, it was really\ncool to see that statement. And, uh, again, rooting for models\nthat are coming from as diverse parts of the world as possible. And so I'm still holding out\nfor Mistral to still represent, uh, large parts of the world. Yeah, of course, because I think that\nthat is a big part I did want to bring up is, is the global majority and kind\nof the geography of all this, right? I mean, we talked about DeepSeek, right,\nChina, Mistral for a long time, it's kind of considered like, oh, okay,\nEurope's also going to have its kind of open source player in the space. And so, yeah, I think it is exciting. I guess, Skyler, to kind of push you\na little bit further, you know, do you think that different countries, different\nregions of the world will produce very different kinds of models, right? Like, I guess that's kind of the thing\nthat you might be suggesting here, but I don't know if that's what you imply. Should they or could they might\nbe the, the key difference there? Um, I think, um, I think if\nthey could, they would have yet. I think it is proving much more\ndifficult to kind of, you know, uh, these efforts, uh, scale across the country. And it's also why I think, uh,\ntwo, uh, two countries have really dominated this space. Um, so I would like to see\nmore of that again, why I would be a Mistral, uh, a fan. Um, I think it would take lots of\ninvestments, uh, from governments, from universities if that money\nexists to really push that type of homegrown effort of models. And I don't really see that now. That's why, again, Mistral,\nstay strong still, uh, still represent other parts of the world. Definitely. Yeah. So Kaoutar, are you going\nto buy into the Mistral IPO? I think it's a great\nstrategic move by Mistral. So, uh, you know, especially it's\ngreat for the European startups ecosystem because they often face\nthese challenges, uh, around scaling due to limited vendor capital\ncompared to what we see in the U.S. So the Mistral's IPO will test\nreally whether Europe can foster this globally competitive AI companies. And of course, you know, I think it's\nimportant not to have this centralization just, you know, between U.S. and China. It's good also to see other countries,\nyou know, uh, Middle East and Europe and also contributing models. I think going to the question you had,\nwhether we're going to see different models coming from different regions,\nthere might be some nuances there. For example, the cultural, uh, cultural,\nuh, implications or the, um, the, the language, the, you know, all these\nthings, maybe some of these regions might tailor their models to their specific\ncultures, their specific traditions, uh, focus more on incorporating, you\nknow, their languages also in terms of the APIs and answering questions\nand things like that, which would be great, uh, while also, but of course\nfor general questions and so on, there will be commonalities, but I think there\nmight be also some, uh, regionalization that might happen in the future. Yeah, for sure. I think that'll be so interesting because\nI think it'll, you know, I mean, there's almost nothing mysterious about it. It's almost like, okay, if you're\nbased in a country, you may think to use certain data sets that people in\nother countries may not think to use. Right. And like, I'll actually have a material\neffect on the behavior of the model. And so, you know, I think it's like,\nthere's really kind of interesting aspects of like, Oh, what would you choose to use? You know, if you're based in France\nversus, you know, Menlo Park, California. And I think that that's, that's\na really interesting twist of it. Even I think the way that the model\nresponds to you, for example, maybe the tone of the language, uh, whether\nyou want it to be polite or didn't want it to be aggressive, I think if we\ncan inject some of these human traits in this human, uh, AI interactions. and kind of taint it with some cultural\naspects, which would be really great. You know, the way you greet a person will\nbe different from a region to region. Would you incorporate maybe some religious\naspects to it or some cultural aspects? It would be nice to see some of\nthese specializations per regions. Yeah, definitely. I'd love to do the test, which is,\num, you know, talk to this chatbot. Which country do you think\nthis chatbot is from? Like whether or not you could be\nlike, oh, that's definitely an American chatbot, I would know. Next topic that we're going to cover\ntoday is a pretty interesting one. Um, a few episodes ago, we talked\nabout the release of a benchmark called FrontierMath from a group called Epoch AI. And FrontierMath is\nfascinating, uh, to me at least. because it is an attempt to kind\nof create evaluations that can keep up with how high capability\nthese models are coming becoming. And so what FrontierMath is that you work\nwith a group of um, uh, really kind of graduate mathematicians, kind of like\nprofessional expert mathematicians to put together incredibly hard math problems\nthat even they have a hard time solving. Um, and uh, using that as the\nsource of the eval benchmark, right? And you know, here is that\nall the classic evals, right? Like MMLU or whatever have kind\nof become saturated, like no one really thinks that they give us good\nsignal anymore on model performance. Now I bring it up again today because\nthere was sort of an interesting controversy that emerged where it sort of\ncame out that OpenAI had been involved in the development of this eval, and in fact\nhad gotten sort of access to, um, sort of these kind of initial test questions. And um, you know, I think there's a couple\nof kind of responses that Epoch had, you know, one of them is that there's a\nholdout set, right, that that the open AI team won't be able to get access to. There's kind of a commitment not to\ntrain on these questions, right, which might also distort the eval performance. But I kind of wanted to raise it because\nI think we're kind of in this interesting time where everybody knows the existing\nevals that are kind of the main benchmarks in the industry are kind of broken. Everybody's seeking to\ncreate better evals. And we're kind of in this new world\nwhere we're trying to work out, like, what should that look like exactly? And, uh, and I guess, Skyler, I want\nto kind of throw it to you, is like, you know, how, how should we sort\nof think about the involvement of companies in developing benchmarks? I guess the skeptical part of me\nwould just say, expect that type of back-and-forth between the eval, the\ncompanies and the evals, and then take whatever performance gains they're\nadvertising with a grain of salt and wait for third party confirmations. So that's, that's probably the,\nmy, my largest takeaway there is it don't say it's never going to happen. In some cases, perhaps it really\nis great to have smart people get into the same room and break down\nbarriers between companies and the goals of making benchmarks. But don't just take that\nparticular company's word about how amazing their product is on\narguably Uh, overfitting results. So yes, just add overall to, uh,\nskepticism and just kind of raise the bar a little bit on consumer education of what\nthese kind of results really mean and, and make people really be appreciative\nof, of third party confirmations. Definitely. I, cause I think, I don't know. I, I, I, I take that. And I think that you know, I'm a\nlittle bit sympathetic to Epoch, right? Which is, well, you want to create an\neval that challenges the very best models. And part of that involves\nworking kind of closely with the companies to design those evals. Like the worst thing is you\nrelease an eval that is completely irrelevant to actually testing\nany model performance at all. And so almost by necessity, there\nis this kind of interaction. You know, Abraham, do\nyou kind of buy that? This is sort of like inevitable. I know I have some friends who are\nlike, you know, church and state, right? Like you should, you know, the\neval people should never talk to the companies, which I think is at least in my mind is a little broken,\nbut curious about what you think. Yeah, I would echo the same\nsentiment, to be honest. I think it's, um, I think the evaluations\nand benchmarks over the last, you know, year have become less and less,\nI wouldn't, I mean, not trustworthy, but, um, uh, transparent in terms\nof what they're actually using as part of their, uh, you know, what\nbenchmark you did, it makes it into the training, uh, versus, you know,\nwhat they're actually evaluating on. Um, I think in a space like this,\nit really is the community that dictates the performance of the model. Um, you're even starting to\nsee where, you know, you'd have ubiquitous benchmarks across models. You're starting to see model\nproviders pick and choose which benchmarks they publish versus which\nones they leave out to be able to narrate the story that they want. So I think as, as, you know, as that trend\ncontinues and as you know, data curators work with model developers to figure out\nwhat the best way is to evaluate these models, I think it's just going to be on\nthe community at large to be, you know, the judge jury, um, in terms of, you know,\nis this model actually performing what the benchmarks say, or is this another\nkind of, you know, gaming the system? Because a model comes out every few\nmonths and somehow every single model is better than the previous one, so everything is always state of the art. We should have been at AGI months ago,\nbut it's, you know, why are we not there? Kaoutar, I guess this kind of leaves us\nin a funny place though if we take sort of Skyler's rule, right, which is we\nshould see all these evals with a bit of skepticism, is it true that kind of in the\nend, like, vibes still are the best eval? Like, you know, is there, can\nwe trust any eval anymore? Like, it kind of leaves me in a fun\nplace because I'm like, well, I really desperately want to have some kind\nof quantitative metric here, but it sort of feels like maybe that's\nultimately kind of a lost game. Yeah, I think it's, it's a very\ncontroversial thing here, you know, what do you really What can you trust here? So there are all these\nbenchmarks out there. But you know, with this controversy\nthat happened around FrontierMath, you can see that OpenAI has this advanced\naccess, which raises concerns about fairness, because it gives them an\nadvantage in optimizing their models specifically for those benchmarks. And this compromises the integrity\nof this fair benchmarking. where all the participants should\nstart from the same baseline. So how can we fix this? Can we maybe establish some governance\naround, you know, these evals? Can we have some transparent access rules,\nsome independent oversight, like a third party that makes sure that everybody has\naccess at the same baselines and, you know, that they don't get access maybe\nto data that will help them tune their models for those specific use cases. And then can we have an open\nreview process for these results? So that's going to require a lot of\nwork, but I think it can be done. Technically, it can be done to have\nthese third parties that are completely independent that establish a governance\nand write these tools and processes and so on to be able to really\nensure a fair evaluation process. And I hope we get to that some\npoint because what can you trust? And you have to do these\nevaluations sometimes yourselves. And I think maybe the community\ncan also contribute to all these evaluations and provide more validation. Yeah, I think the incentives are\nkind of a little bit interesting here too, because I think, you know,\nEpoch gets burned in this story, but OpenAI gets burned as well, right? Because like, it doesn't, it's\nnot a great look in some ways. Um, and I feel like, you know, almost\nthere's incentive to, like, be as hands off as possible, because look, when o3\ncomes out, I really do believe it will be better at very hard math, right? Like, I think there is actually some\ngenuine signal here, but like, where we are now is maybe a little bit,\nyou know, happens in the shadow of, oh, well, we know this arrangement,\nand they had access, and all that. I mean, the jump was pretty\nsignificant in the benchmark. I think it went from, uh,\nbefore the o1 results. It was a 2 percent and jumped\nto 25 percent with a one result. That's a big jump. Yeah. The question is like how much of\nthat delta is the model, right? Yeah. And how much of it is, you\nknow, being able to kind of study for the test basically. Yeah. And I think there was also someone,\nI think Chollet, the creator of the ARC-AGI benchmark, he refuted OpenAI's\nclaim of exceeding human performance. You know, he highlighted, you\nknow, that o3 still struggles with some of the basic tasks. So, so then, you know, it remains,\nyou know, what do you trust? You know, 25% leap here\ncompared to the 2%? Or maybe there are still some,\nuh, gaps that they're not, they're not telling the full story. So yeah, I think we're going\nto have to keep on this. Um, you know, there's a great article\nthat I saw from, um, uh, they just came out, I think a few weeks back that was\nkind of making the observation that models are getting better, but we don't,\ncan't really measure how, you know, we live in this kind of funny world where\nlike all the evals kind of seem broken. We have a general strong intuition\nthat things seem to get better, but like we have no way of actually\nassessing that, which I think is is kind of a funny situation to to be in. Can we create an eval LLM? So some model that evaluates\nall of these other models. Can we automate this evaluation process? Yeah, I think that's kind of where we\nend up is like I think if we think that vibes are going to be a powerful way\nof evaluating models and what we really say by vibes is like an interactive\nevaluation like you talk with the model to get a better understanding. It seems very intuitively obvious\nto me that at some point you will end up with like, well, to scale\nthat we need LLMs talking to LLMs. And that kind of like they're\nconducting a scaled Vibes eval. I don't know where that goes, but it kind\nof feels like that's like maybe one set of research paths that you'd go down. You might be onto something. Yeah, we'll see. I just host the show. Someone else needs to do that work. So for our final topic today, we're\ngoing to talk about a report that came out of the research group\nIDC, uh, about generalist versus specialized coding assistants. Um, and it was released, uh, or\njust earlier this month, I believe. Um, So the report kind of takes a look at,\nyou know, what programmers are getting out of, um, uh, out of, uh, coding assistants. And they show a lot of the results that I\nthink we are familiar with at this point. So they report that 91 percent of\ndevelopers are using coding assistants. They say that 80 percent of\nthose developers are seeing productivity increases with the\nmean productivity increasing by 35%. So all kind of the good news that\nwe're used to, which is that these coding assistants really do seem to be\nhelping people along and doing better at their job as software engineers. I think the really interesting\nthing, though, that they make a distinction on is between generalist\nand specialized coding assistants. So generalist are basically like overall\ncoding help with specialized assistants focusing on specific programming\nlanguage, specific frameworks, um, industry specific requirements. And they kind of make the\ndistinction, these are actually like two different markets. And right now like, you kind of\nneed both to do coding assistance. And I guess maybe the question, you\nknow, maybe I'll throw it to you, Abraham, first, is like, you know, I\nalways thought that, like, where we're headed with these coding assistants\nis that they will just be one coding assistant model to rule them all. Um, but it is kind of interesting to me,\nthey seem to be making the argument that like, no, there's going to be these really\ninteresting niches for like, you know, my joke is like the FORTRAN model, right? It's just like, just specific\nto this particular use case. Is that what you guys\nare seeing at Granite? Like, I'm kind of curious because I know\nyou've done a fair amount of coding work. Yeah, yeah. So I, I agree at least in the current\nspace right now, you know, there, the, the perfect world there would be,\nyou know, uh, one ring that fits all, like, you know, that rules them all- The one ring that fits all. kind of methodology, but here at IBM,\nyou know, we support, uh, we develop our resource specific languages and the\nreason behind that, there are these legacy applications, you know, COBOL Z, where\nit's a low-resource language, there's not a ton of, you know, data that we can\nuse to be able to do that trade on models where if we were to start to bake it\ninto our more general code model, some of the capabilities might get lost in terms\nof being able to support that use case. So we find that, you know, you do have\nthese legacy systems that people are still on where, you know, a resource\nsupport might not be as prominent as it was 5, 10, 15 years ago, where\nyou do need to backfill some of the work with, you know, code assistants. And then you do have your larger, more\ngeneral models that support, you know, your more uh, widely used languages,\nso in our space, we really do have that two pronged approach in terms of\nhow we develop our, our code models. And of course, you know, the, the\nultimate goal is to start to consolidate into something that can fit everything. But right now, that's just not the case. So I guess your prediction is that\nwe will actually just see, like, this is temporary and we will see\nthe merger, like generalists will become specialized at some point. You know what? I'm, I'm, I'm trying not to make\npredictions in this space because everything changes so fast. Yeah, I think it's hard. But what I will say is that, um, there's\na shift in workforce specifically around, you know, capabilities. So I think that for organizations\nthat need to be able to maintain their environment, they will\nlook for models that help that. And if that can be provided as a part\nof a general model, all the better. But I think right now, it's,\nit's still looking to be more of a specialist model focus. Skyler, do you want to talk a little\nbit about, I mean, the interesting kind of labor impact of all this? Um, you know, I was joking with a\nfriend recently, I was like, what you really need to do now, talking about\nthe Fortran code assistant, is like, you need to specialize in languages\nthat no one programs in anymore. Right, because if you do Python,\nyou do, you know, any of the popular languages, you're about to get wiped\nout because the models are going to get really good really fast. And so the main thing is to flee into\nlike what weird obscure version of Haskell, you know, and kind of that's\nyour that's your defensive moat if you're a coder, is that good advice? Or is that just crazy? That's a great anecdote, um, and I\nthink actually it's not just a story. I do think actually IBM's got a lot\nof vested interest in keeping some of those old languages up and running. So, uh, beyond, beyond just a, um,\na punchline, I think here, here's a great breakdown in as part of this,\num, the survey that was done from the IDC, they also said what particular\ntools, or what particular tasks. Do you use these assistance\nfor and at the top of the list was unit test case generation. So this is like the really boring part of\nsoftware engineering, writing all these unit tests to try to break your code. In that sense, I would say to your friend,\ndon't specialize in building unit tests. That is something that I think machines\nare doing a great job of, and people are already leveraging for that task. But at the bottom of this list of where\nthey don't, aren't using these tools as much, is code explanation, which is now if\nI copy in a set of this code, can I have an LLM tell me what this code is doing? So I think there's this really\ncool breakdown between what tasks software developers really want to\nbe automated for them, things like coding up unit tests and other areas\nwhere they actually need to, you know, use kind of higher level processing\nof, Ooh, what is this code doing? Can I explain what this code\nis doing to somebody else? And That kind of breakdown here of how\nat least software developers in the U.S. are currently using tools,\nI think represents that gap. So to your friends, don't tell them to\nspecialize in unit test generations, but maybe have them skill up a little\nbit on the ability to explain what that code is doing, because that's something\nthat currently the AI assistants at least are not being used for. I see the future as an AI\nco-creation, uh, software developers. So where the future of programming will\ninvolve human, AI collaboration with AI as a coding assistant helping to brainstorm,\noptimize, and refine solutions. But going to your friend, I think where\nthey should focus on is where areas, uh, is on areas where AI struggles, things\nlike system design, security and handling edge cases, uh, creative problem solving. So, uh, you know, it's\nresponsible AI use cases. Those are still areas where AI struggles\nbecause I think designing and solving and programming complex software\nsystems involves not just coding. But a lot of other elements and, and,\nuh, angles here, and especially the collaborative nature of understanding the\nend users requirements, the client edge cases, the requirements, the security\nimplications, all of that, and putting it all together in a full, full end to\nend solution with testing with coding with so there are a lot of elements here\nthat still AI cannot handle completely and software developers are still needed\nbut I think they need to focus more on those situations that AI struggles with\nbut of course enhance their productivity with these code assistants and copilots. Yeah, I think that's right and I\nthink I don't know Skyler's emphasis I think on like don't do unit tests but\nwork on explaining the code I think is very interesting, um, you know,\nI mean, classically, documentation is always terrible for any software. Um, and I guess, Skyler, kind of\nwhat you're saying is maybe that's actually where the future is. Like, you really, you really\ngotta get better at that soon. I was actually having a conversation\nwith a former, uh, co worker and, uh, I don't want to date him, but when\nhe was in computer science, when he was doing his grad school in computer\nscience, he said they didn't code. They just, their goal was to think\nabout how to strategically, um, you know, outline your code and what's the\nthought process behind building it, as opposed to just going and building. And he recently took on a new,\nuh, role in a new space and he's had to learn a new language. And it was funny. He was saying, I don't\nhave to build code anymore. I think the gap that I see with a lot of\nthese, you know, PhDs coming out is they don't have to build code, but they're\nnever taught how to think through and explain why we're doing what we're doing. So he found it a lot easier to\nactually learn given that that was kind of where he started. So to your point, Skyler, it was, uh,\nhe's actually seeing that the better you can actually structure your code\nin your head before you actually start to write it, the easier it is to learn. I agree with you, Abraham. I think the problem solving process. How do you decompose a problem into\nsubproblems and also the algorithms think understanding, you know, how to\ncreate a very innovative algorithm. This is something, you know, that\nrequires deeper thinking, deeper expertise that probably AI cannot solve today. Like coming up with a new algorithm\nthat solves something, um, like, uh, some of the existing problems. So it's still challenging\nfor an AI system to do. Well. Let that be a lesson to, or a, the\nword of advice to all you coders out there who are listening to the show. Um, as always, I say this every single\nepisode, but we are out of time for all the things that we need to talk about. Um, thank you for joining us, Abraham,\nwe'll have you back on the show. Kaoutar, as always. And, and Skyler, thanks for coming\non and thanks for joining us. If you enjoyed what you heard, you\ncan get us on Apple Podcasts, Spotify, and podcast platforms everywhere. And we will see you next\nweek on Mixture of Experts."
}