{
  "video_url": "https://www.youtube.com/watch?v=CgqHN38l6Ko",
  "video_id": "CgqHN38l6Ko",
  "title": "DeepSeek-V3-0324, Gemini Canvas and GPT-4o image generation",
  "upload_date": "20250328",
  "channel": "IBM Technology",
  "duration": "41:39",
  "caption": "It's 2026 is the top model in\nthe world an open source model? Kate Soule is Director of Technical\nProduct Management for Granite. Kate, welcome to the show. What do you think? I don't know.\nI agree with that framing, Tim. I don't think any model is top. I don't think there'll be one model\nthat is overall best at anything or that will rule them all, so to speak. Alright, uh, Kush Varshney,\nIBM Fellow AI Governance. Uh, Kush, welcome to the show. What do you think? I think Open is here already and\nOpen's gonna dominate into 2026. All right, great. And Skyler Speakman,\nSenior Research Scientist. What's your hot take on\nthis question, please. If you define the top as the most\nused, then definitely open models will be the most used models in 2026. All right, everybody's fighting my\nquestions today and all that, and more on today's Mixture of Experts. I am Tim Hwang and welcome\nto Mixture of Experts. Each week, MoE brings you the best\nminds and artificial intelligence to walk you through the biggest\nheadlines, uh, that are dominating news. Um, as always, there's a lot to cover. We're gonna be talking\nabout Gemini's new release. We're gonna be talking about a new\nthermodynamic computing paradigm. We'll be talking about OpenAI's  image\ngen. But first I really wanted to start by talking a little bit about\nDeepSeek-V3, and specifically not V3, but a checkpoint that DeepSeek  released. Um, so to just give the full numbers if\nyou're interested, is DeepSeek-V3-0324 um, and, uh, there's a lot of kind of\nhype about this release because by some measures, um, one specific one is this\nartificial analysis intelligence index. It is now kind of the best\nreasoning model, the best model out there in the world. But maybe, Kate, I'll start with you. I know you kind of fought the\npremise of this question when I just asked you it a moment ago. Um, should we think about models\nas being the best in the world? Like is that even a useful way\nof thinking about this space? Well, well, a couple of things. I think DeepSeek-V3 is a non reasoning\nmodel, so I think a lot of the press's, best non reasoning model in the world,\nuh, according to, uh, reports like artificial analysis, you know, I,\nI think a lot of these analyses are trying to come up with tools to help\npeople better evaluate models and pick ones to, um, use in, in production. The reality is these models all\nare differentiated by like 0.01. You know the differences in performance. Do we really think that tiny lift\nin performance of one benchmark is going to result in meaningful\nperformance improvements on a rag or even a agent based task that you're\ntrying to deploy in production? I don't think so. I think there are great ways to give\nyou a list of models to start to test, but ultimately the best model\nis the best model that does best on your task that you care about. And that could be any model, regardless\nof how it kind of scores on some of these top level benchmarks. You're almost saying like we're like\nposts almost benchmarking in some ways. Like all the models are so performant\nnow that like, it's almost difficult to say like there's one absolute measure. I don't know if that's putting\nwords in your mouth, but. I mean, I think different model\nproviders have different priorities. I think DeepSeek  is\nactively chasing OpenAI. They're trying to have the same,\nyou know, pursuit of  AGI, and so some of these benchmarks are being\nused as demonstrations of capability on that broader pursuit of AGI. That's fair. I don't think that means for like a\neveryday production task or use case that really reflects a, necessarily a,\na meaningful difference in performance. I think there's a, you know, some of these\nbig models are frankly overkill, uh, and so boosting it a little bit further isn't\ngoing to make a real actionable impact. And the benchmarks that matter the most\nif you're trying to deploy a model is. What is the performance\nfor a given cost profile? And those are some things that\nyou know, really you just have to test use case by use case,\nusing information like artificial analysis to help you get started. But ultimately, you know, you\nhave to run your own experiments. Kush, maybe I'll turn it over to you. I don't know if you agree. I guess there's a one way of reading\nyour answer, which might be like, almost like a. Uh, a contrasting\nposition, I guess, to Kate, right? Where I think the way I heard you\nsort of respond to the question was, by any measure, open is winning. And so like, it doesn't matter\nhow you measure this, open will be the best in the world in 2026. Is that another way of thinking about it? Or maybe you were nodding,\nso maybe you actually agree. Violently with what Kate just said, um, with, uh, both Kate and Skyler\non this point, that, I mean, there's different ways of measuring what is best\nand like even asking the question of what is best is probably, um, kind of\nnot the, the right way to think about it. But, um, I think the\nmain point is that Open is, uh, a way the, that\nthe world is gonna move forward. So, um, whether we wanna count best or\nnot best, um, or usage, or adoption or not adoption, um, I think open is, uh,\ngonna have a, a very strong sort of play. Um, uh, just continuing. Uh, so whether the, that number is,\nuh, a little bit above a little bit below, that's not the, the critical\npoint, just that it's in the same ballpark as the, the important point. And, um, I think, uh, a couple of months\nago when I was on the show, um, I was talking about just the culture of,\num, how DeepSeek is doing their work. Um, the fact that they can\nrapidly iterate and, um. Uh, kind of make this difference and,\nuh, and, and reach their goals, whatever those happen to be, uh, very quickly. And, uh, I think that's the continuing\nstory in, in my mind that, uh, whatever happens, uh, I think deeps\nseek will be able to adapt to, to the changing environment, whatever the\nneeds happen to come across, uh, in the, in the actual world. So, um, uh, just in terms of, uh, the,\nthe culture aspect, uh, I mean, Open culture is gonna be what's\ngonna dominate actually, um, not maybe the, the open model. So maybe I'll clarify that a a little bit. I'd like to jump in on, on Kush's point\nthere about the role of DeepSeek and for sure the headline that got me to\nclick was Open Source is now Best. Uh, but below that headline. Was this really cool graphic that\nshowed where Deepseek from January was to where DeepSeek, DeepSeek-V3 in March\nnow is, and that delta, I think is worth paying attention to. I agree about the difference\nfrom the other leaders. Depends what metric you're\nusing at, et cetera. But for this same metric, the increase\nthat DeepSeek has made from January to March, uh, really quite, quite impressive. So think about that change that has\nhappened in that short period of time. And I think that just kind of\nechoes, uh, Kush's sentiment about the way DeepSeek  is going about\ncreating and releasing these models. Very cool release in January and a\ngreat follow up 3 months later. So that's how, that's, that's\nthe really cool headline after the fact, after that line. Yeah,\nthat's right. Yeah. I think it's like very interesting as\na way of looking at these metrics is that we, we tend to think about them\nas like, is the model good or not? Right? And I guess, Skyler, kind of what you're\nseeing is like almost maybe like, well maybe that's not the real question. Like this is really\nuseful for almost knowing how good the kind of team and\ntheir improvement method is, right? Like it's almost like how\nquickly can the team hill climb? That's the really interesting thing\nthat's kind of revealed by these numbers more so than like the quality of the\nrelease in some objective, uh, sense. Well, and I also think there's\nsomething interesting going on about being able to kind of bootstrap reasoning models to improve\nnon reasoning model performance. So the initial V-3 that was launched\nback in December, uh, DeepSeek  had a internal version of R-1 , which was their\nreasoning model that they said they used to train it and then they released R-1\nin January and that was, uh, you know, market moving and now they've released\nan updated version of V-3. And I think what, so part of that momentum,\nwhich is really exciting to Skyler's point, is that we see them able to\nkind of innovate on some of these core building blocks that they've released. And that's probably gonna unlock\nall sorts of ways that the broader open source community can\nalso innovate given that they've released these building blocks out\ninto the world, like the R-1 model. Yeah. There's a final theme I guess I\nwanna pick up on from Skyler's original response, which is,\nyou said maybe one metric we should just look at is usage, right? Like, nothing beats usage, right? Like if there's a lot of adoption,\nyou know, almost like we can not, we can debate what's better and\nwhat's not, but it's almost like it's the one that's being used. Uh, do you wanna talk a\nlittle bit about that? Like, we don't really talk about that so much. I feel like often we're very obsessed with\nlike, how did it do on this benchmark? But I wonder if like usage over time\nbecomes like a more important way of kind of measuring, not model\nquality exactly, but like who's winning I guess in some sense. I think, I think downloads on Hugging\nFace is a thing, right? That's, that's kind of a stab at that idea of usage. And I, and I think that is something\nthat these model developers, uh, keep track of it and watch over time. So, uh, no, I don't think we're\ntoo far off the mark by talking about adoption and, and usage. I will push back a little bit just\nbecause DeepSeek  is a huge model. Like, you know, if we talk about downloads\nand usage, I think small models are gonna lead and win something a developer\ncould literally download and run. Uh, the DeepSeek  model is kind of a bear. I mean, it's 600, uh, 70 plus\nbillion parameters that would have to be loaded in memory to run. So I, I think usage is really\nimportant, but I think usage for these larger models is going to be\npredominantly more in a, a hosted setup. Uh, and you know, there are interesting ways to look at demand\nbased off of model size. Uh, and I think we see a lot of small\nmodels that are more cost effective, are gonna get more usage in 2025 and\n2026, and some of the bigger models that are just monsters to, to run. Yeah, for sure. I, one of the things I've always been\nobsessed with is like, one of my data, like secret data points of the world that\nI would love to know is like, what's the book that's most downloaded on Kindle? That's like never read. And I actually wonder if there's\nlike, almost like a similar dynamic for language models where you have like\nthese models that are widely hyped and very much downloaded, but the\nquestion is like, how much use are they actually getting in practice? And we have a lot more\nlimited sense of like that. Right. And that, that's almost kind of like\nan invisible part of the, the question of like, you know, who's winning? Right. You know, and I think we're already\nattacking the premise of that question. Great.\nI'm gonna move us on to our next topic. Um, speaking about big models\nand, uh, and also, you know, the battles over benchmarks. Um, Google did another\nkind of raft of releases. They've, seems like they've\nreally been picking up the pace. Um, there was an announcement for Google,\nuh, Gemini 2.5, um, and then also kind of the release of this sort of canvas feature\nthat they've been playing around with. Um, and you know, because we've. Spoken just a lot about kind\nof models and benchmarks. I do wanna maybe start\nby talking about Canvas. Um, one of the really cool features\nabout it I thought was actually the idea that you can kind of be coding\nand then also automatically see a preview of what you're building. At the same time, and we've talked about\nthis a little bit in the past about just like we're still trying to figure out how, you know, kind of AI assisted\ncoding will look in the future and a lot of the innovation seems to\nbe like on the interface level. Um, and so I guess maybe Kush, I'm curious\nto get kind of your thoughts on, you know, these types of approaches, right? Where like, it seems like\nwe're moving away from pure, just kind of auto complete. Um, but um, just kind of interested\nin how you think about it, uh, as a research run some of these issues. Um, let me start, uh, with a little\nbit of a, of a history lesson, just if you'll, uh, accommodate that. So, um, of course there was an, uh,\na person, an IBM Fellow, Irene Grief. And, uh, she was in\nour, uh, Cambridge lab. She's pretty much started it. Um, and she founded the field of computer supported, uh, cooperative work\nand, uh, that, um, she started it in Lotus and then IBM acquired Lotus, which became\npart of IBM Research and, and so forth. And that field brought together\nall these different sort of things. It was the human factors sort of things,\nthe distributed systems, I mean like a lot of different stuff of what it really means\nfor humans to work together, supported by computers and computer technologies. And I think the paradigm is shifting a little bit,\nand it's more about individual work. So, um, and how that's supported by\nAI and, uh, the collaboration between humans and AI and, and doing that. So kind of the co creativity and,\nand, and these sort of things. And I think, uh. Just the fact that this whole\nparadigm is changing is calling for exactly that, the innovations in the\ninterfaces, in the, um, interactions. And, uh, I think there needs to be a\nlot more kind of control given to the user, the ability to tinker with the\ninterface to make it what works for them. And the canvas is very much a, a great\nstarting point, but I think, uh, because I mean, just a single chat box is not. The answer. I, I think everyone can,\nuh, appreciate that. But um, uh, once we go beyond\nthat, then the world opens up into lots of different possibilities\nand I think the canvas is one. Um, but why not just let me\nas the user determine what is the right in interface for me? And maybe that'll actually\nbe the, the next step. Oh, like that. The future will be like almost purely like\neverybody will have their own basically interface for this sort of stuff. It's very interesting. I guess my question to the rest\nof the panel, is this the first broadly released multiplayer AI? You know, the, the, the interface\nwhere you've got multiple people interacting at that with the same interfaces; have there\nbeen versions of this before? Is this the, is this the one to make the\nsplash where we look back and say, this is the first time where  people are going\nto be, uh, interacting together over the canvas, you know, over that case? Or am I, am I blanking\non some, uh, examples? Previous examples? No.\nI mean, I think like the Google Docs, I mean, you're\njust all editing at the same time. And then you can have some AI,\num, helping each of the people a little bit is in that same pathway. It's not like, uh, we haven't seen\ncanvas type things when you, uh, we use mural for, um, design thinking sort\nof things then, and there's multiple people moving things around and our\nteam, um, to develop kind of a AI Mural version sort of thing,\nuh, in, in our Cambridge Lab. So, um, yeah, a lot of things\nthat are happening, but uh, yeah, it, it is a step I would say. Yeah. I think there's one question we've\ntalked a little bit about in previous shows is, you know, it's kind of funny\nthat in some ways because ChatGPT  was like this big kind of moment for AI. All of the interfaces that kind\nof have followed since have like fallen into the gravitational well\nof everything needing to be chat. And it feels like maybe, I think\nwhat's exciting about Canvas is like, and you know, a bunch of other\nexperiments as well is like kind of like finally people are trying to\nlike, kind of stretch beyond that. Um, and I think it's kind of an\ninteresting debate on just like how much path dependence there is here, right? Like whether or not people will. Sort of, I, I mean myself, I'm\nkind of like, oh, there's no chat. Like, or like chat is like a\nless part of this interface. It feels like a little bit weird for me. Um, and, and I think that's\nlike pretty interesting to see. Kate, any thoughts on this? I don't know if Canvas is like something\nyou'd use or, uh, how you feel about it, kind of particularly from sort of thinking\nabout this from a product standpoint? Yeah. I mean, in general, I'm, I'm always\na fan of finding ways to move beyond kind of the initial\nchat based constraints. I think Canvas is probably more of a\nstepping stone than a final destination. I, I think it's got that a little bit of\nchat feel while still being different. For coding, I really think\nit's about being embedded in where developers are coding today versus having a standalone\nkind of canvas app where you kind of iterate in terms of where\nyou'll get the most productive use. So, you know, I, I think it's a little\nbit more of a, a demo perspective there. From a product strategy I think it's interesting to\nkind of look at how some of the big players are focusing on more of the endpoint side of\nusage, like Entropic, I think is focused pretty heavily there,\nversus more the application side. Um, with UIs where, you know, it\nseems like Google's focusing a little bit more on that with this release. Um, certainly with some\nof these new features. Honestly, from my perspective,\nI was most excited by the Gemini 2.5 model\nsimply from the reasoning. Uh, I do a, a basic sniff test,\nuh, for different reasoning models and just ask what is two plus two\nand see like how much thought will the model put behind this answer? Like, can it, can it figure out how not\nto reason if it's simple? I like that a lot. Yeah, and the, the model did actually\npretty well, like compared to DeepSeek  it'll give you like five\nparagraphs of R-1 will give you five paragraphs of, okay, I've got 2 fingers on this hand and\n2 fingers on this hand. And, you know, it goes way into it. Um, you know, uh, Gemini was able\nto give a very reasonable short response that was still correct. So, you know, I, I thought that\nboated, well, I haven't done more, you know, exhaustive testing. Obviously that's just a quick sniff\ntest, but that's the first time I've seen like a, a more practical, just like a... It is an easy question. I'm not gonna spend a million paragraphs\nand tokens trying to give you a response. Mm-hmm. Yeah.\nThat's great. I love that. Is like, the idea is like, actually\nnow we need to be doing simpler evals because the question is whether or\nnot you're overcommitting resources. It's like death by reasoning. Very, very interesting. Yeah. Um. Kush, Skyler, other sniff\ntests, vibe checks on 2.5. I do think these qualitative like\nevals are pretty valuable, I think in terms of people like navigating,\nlike, is this something I should spend time on or look into? Not in the last 36 hours, sorry. No. Okay. Same here. I also do, where is Rome? That's my other go-to. Uh, similarly, you know,\nparagraphs of debate on where Rome is compared to mm-hmm. a short response on Gemini. So I thought that was pretty good. Yeah, I will need to\ntry that with deep seek. I just love the idea of like,\nkind of grinding away for like a very simple question. It is.\nAnd really stressing about the answer. It, it Literally is like, okay, two\nfingers plus two fingers. But then if I have two toes plus\ntwo toes, how many toes do I have? Like it, it gets mind blowingly intricate. Um, I think one final thing I\ndid wanna touch on and Kush, I think we should recognize that\nyou're wearing a safety vest. Um, before I kind of tee up this\nsession, do you wanna explain why you're wearing a safety vest on the show today? Yeah, this is, uh, safety vest because,\nuh, IBM Research with our Granite program is, uh, very focused on safety,\num, through our, uh, uh, red teaming our, uh, granite safety alignment\nand our Granite Guardian model. So yeah, that's, uh, just\ntrying to represent that. Yeah, absolutely. And I did wanna finally just\ntalk a little bit about. Like model safety here. Um, and you know, uh, I think one of the\nthings we've talked a little bit about in the past is like how much safety is\nbuilt into the model versus kind of a future where safety is kind of like a\nseparate model that you're working on. Um, and I don't know, I guess Kush\nlike looking at a release like this, it still feels like at least a lot of\nthe big companies are still kind of rr I would say like at least kind of,\nyou know, Google, like, let's just say, um, is kind of still chasing after\nthis kind of like, well, it's just all gonna be embedded in the model\nversus kind of safety being outside. You wanna talk about kind of\nlike the pros and cons of that? And I guess why, you know, Google\nisn't kind of like doing what a lot of other companies are doing is saying,\nwell, like Meta or like IBM like, hey, we're gonna actually separately think\nabout safety as a, as a its own kind of like model construct in some ways. Um, just was curious to\nget your thoughts on that. I mean, Google does have, uh, something\ncalled Shield Gemma, so they do have, uh, uh, a player in, in this,\nuh, separate model sort of field. But, um, yeah, it, it's really not\na question of like choosing between the, the different ways of doing it. I mean, you really should\ndo everything because, um. Uh, there's never any\nperfect sort of solution. So yes, do the safety alignment as best\nas you can, um, and then still have, uh, an input and output guardrail, um, because\nI think, uh, it's, uh, it's critical. And then even on the data curation side,\nI mean, um, uh, try to exclude as much of the, uh, the bad content, uh, as possible. And. Uh, to me a big reason for keeping\na separate guardrail model alive is because, um, uh, beyond the performance\nsort of question, um, where yes, I mean, that does show that, uh,\nyou can do a little bit better. But, um, the other thing is\ncustomizability because, um, not every, um, sort of application, every use\ncase is gonna be exactly the same. So. Uh, the notion of safety, the\nnotion of what is, uh, desired and undesired is gonna change. And so, uh, if you just pick\neverything in, uh, you don't have that flexibility anymore. So, uh, just, uh, we need to think\nthat, uh, uh, every, uh, customer, every sort of application needs some level\nof customizability and that applies to the overall model, but uh,\nuh, also on the safety side. Yeah. And I do think that's actually a\ngreat way of sort of thinking about it, is you, you're sort of saying\nsafety at every level, right? Was like do safety everywhere. Um, and it's like how\nwe'll end up doing it Kush in 10 seconds. Could you compare and\ncontrast safety and security? Uh, the reason I ask is the UK recently\nrebranded their AI Safety Institute into the AI Security Institute tour. Yeah.\nWhat's, what are your thoughts? Not necessarily on that particular\nrebrand, but along those two dimensions? Yeah. No, I mean, both of us were in\nSan Francisco in November, right? When, uh, it was a convening\nof the AI Safety Institutes. Um, you were a part of\nthe Kenyan delegation. Right. And, um, uh, the, yeah, things\nhave changed a little bit. I think that's more politics,\nmore just wording sort of things. But, um, to me, like security is at the application level. Um, that's, those are things that you\ndo kind of, um, in a general sense. Um, and then the safety\nis at the model level. Um, things that you're trying to bake\ninto the model or put a extra Guardian. And then when you kind of meet in\nthe middle, um, the model, uh, comes up and the application comes down. Uh, that's where kind of the, the\nconfusion might be a little bit, so it's security that's kind of becoming\nmore AI-ish, and then safety that's become, or the AI model is becoming\nmore secure in some capacities. So yeah, to me there's, uh, the general\nidea is just reducing the risk of harms and, um, uh, the more you can do\nthat, uh, the, that's the, the goal. For our next topic, uh, I wanted\nto kind of bring us to a hardware story, a really interesting, uh,\nfeature coming out in Wired this week on a company called  Extropic. Um, and what  Extropic is investing in is\nan idea called thermodynamic computing. Um, and I really want to kind of bring\nthis up just 'cause, you know, a few episodes ago we talked about quantum. And these guys I think are really\nmaking the argument that like, well, it's not gonna be GPUs, it's not gonna\nbe quantum, it's gonna be this new thing called thermodynamic computing. Um, and I think it's just really\ninteresting as we kind of think about the ways in which hardware\ninfluences, uh, the work of AI. Um, and, uh, was kind of interested\nin, in like the, the takes of this group as the people who kind of\nlike work in AI day in, day out. You know, to what degree are you\nkind of like paying attention to these kinds of developments. Right? Because I feel like one way of\nthinking about this company is that it's, it's big if true, right? Like if you can actually do it,\nthen maybe it's a really big deal. But we kind of don't know at this point. Um, and so I, I'm kind of curious\nlike on a day-to-day level, like are folks kind of thinking about like\nthese alternative computing platforms? Are they sort of still so far\nin basic research that they're kind of not impacting day\nto day sort of thinking. Okay. Maybe I'll kind of turn to you\nfor, for the first take here. Yeah. I mean, and I'm not a expert at all\non chip design or, or hardware, but I think it's something that certainly, uh,\nIBM and we have huge teams working on, specialized in alternative chip design,\nuh, and AI accelerator chips is paying really close attention to, and there's a\nlot of innovations going on in that space. So, you know, I think some of these\nheadlines, like normally we let it mature a little bit before we start\npaying more close attention, but as a field and as a whole, you know,\nI think there's a ton of opportunity to better optimize and redesign chips\nbased off of the inference loads that we expect to see in the future. Um, moving into, for example,\nrunning smaller models more times at inference versus one big model one\ntime at inference in order to improve performance as everyone starts investing\nmore heavily in, uh, a phenomenon, we're calling inference time compute. Um, so, you know, I think that there's just tons of\nopportunities in this space. So certainly eager to see how onic\nevolves and, you know, if something becomes more mature that, that\nthe field can take advantage of. And this is kind of where I wanted to\npoint the discussion 'cause I think, um, you know, in some ways kind of\nlike the, the kind of uniformity of GPUs and even the uniformity of like\nNVIDIA has been in some ways like really good for the AI space just\nbecause like, I think there's been kind of like a common standard that people\ncan build around on the hardware side. Um, and I think one of the questions\nthat I'm sort of curious about on whether or not like as this evolves is if you\nhave all these kind of alternative kind of computing platforms that\nend up being good ways of doing ai. If that kind of fragments up\nthe space a little bit, right? Like I assume the way that you would kind\nof try to do AI on top of something like a thermodynamic computing chip or a quantum\nchip might look really, really different. Um, and so, yeah, I just kind\nof here, like as you kind of think about the future, maybe\nSkyler I'll turn to you is like. Do we think there's gonna\nbe more fragmentation in the space or is it, I don't know. Maybe we'll find some way to just\nget Coda to work on everything. You know, I am. I'm not ready to invest in Extropic\nyet, but I do think they've got some interesting takes and I\nwas reading it about it today. You don't want any randomness in\nyour floating point operations, our typical zeros and ones. But if you're doing billions and\ntrillions of these floating point operations, that noise is actually okay. Uh, the idea of AI and how we train those\nsorts of things, distributions of data. So the problem is you don't want\nany randomness at any individual calculation, but you wanna simulate\nrandomness at the larger scale. Their approach seems to be, let's\nnot bother, bother with zeros and ones anymore at the chip level. Let's embrace randomness down at the\nchip level because that's where we're eventually going anyways, thinking always\nabout distributions rather than the answer being, you know, four for example. So I'm really glad people\nare asking those questions. Whether or not they'll be able to\ninduce the desired distribution by passing, you know, electronics\nthrough, uh, metal wafer. That'll be, that'll remain to be seen. But I'm, I'm really glad that people\nare considering this idea of the extreme accuracy required for our zeros and ones. And then in the bigger picture,\nactually, we don't need that specific, specific accuracy when you're talking\nabout training these massive models. Uh, so with some really cool\ntension to see how it plays out. Uh, but like I said, I'm, I'm\nnot taking my, um, I'm not taking my money there quite yet. Yeah, absolutely. I actually really love that you're,\nI think, revealing a bias in how I kind of frame this segment, which is\nhardware is the upstream thing and all the AI people kind of have to like dance\ndepending on how the hardware evolves. Skyler you're almost making\nthe reverse argument, right? Which is actually like what we're seeing\nnow and I guess what this company is an example of is an attempt to make\nthe hardware kind of like match. Like what we know about sort of AI now. And so it's actually the, the power is\nactually going the other way now, which is like the, in some ways, like GPUs were\nalways kind of an accident in some ways. And so we're kind of like\ntrying to rebuild that, huh. Yeah. That's\na nice\ntake. Yeah. Kush, any final thoughts on all this? Sure. I can maybe go back to, to some\nmore of my, uh, my history lesson if you guys are okay with that. So this is good. I feel like, you know, yeah, it's like we have, we have Chris on for\nlike, the, the crazy take. Yeah. And we have Kush on for, you know, the,\nthe historical history, philosophy, you know, perspective history and everything like that. Right. So, um, uh, just, I mean, what\nis thermodynamic computing? Right? Um, so I think it's to understand a\nlittle bit of, uh, of like how this has come about a little bit more as well,\nbecause, um, uh, I mean, uh, you said it. Uh, at the beginning, right,\nthat, uh, there's some sort of like hardware lottery. Um, and Sarah Hooker, um, is a researcher\nwho wrote an essay all about this, that, whatever the hardware happens to\nbe, that's kind of what, uh, uh, makes things go forward and, and so forth. So even the whole IBM\ncompany, it started, um. Uh, at a time there was this guy,\nHerman Hollerith, and he was doing punch cards and he, um, I mean, did the US\nuh, census in 1890 and stuff, right? And that's like a paper with a hole in it. That's a very basic sort of technology. And then, um, in the sixties, um,\nBob Denar here at IBM Research invented dram, which, um. Took a capacitor and a transistor,\nand you could do memory that that way instead of through these,\nuh, hole punching sort of things. And, uh, then you get to like\nthe thermodynamics of it. So, uh, you have James Clark Maxwell,\num, second Law of Thermodynamics, and he is trying to think about\nthis demon that's trying to like make heat flow without any energy\nexpended or anything like that. Right. And, um, uh, there were these two\nresearchers here at IBM, uh, Raul Landauer and, uh, Charlie Bennett. And, uh, uh, what they figured\nout is like how to argue against what, uh, was this Maxwell's\ndemon, um, sort of thought process. So. Uh, land Hour showed that, uh, any\nsort of computation, um, actually requires the use of energy. Um, so it requires, uh, uh, heat, right? And then, uh, Bennett took that idea and\nsaid that this demon who is sorting uh, hot and cold molecules,\num, uh, must, uh, actually do some information processing, so\nthat's actually using energy. And, um, so the, uh, second law\nof thermodynamics must hold. So like all of this is part of\nlike IBM's heritage as well. And, um, but this new thing,\num, I, I think it's exciting. Uh, it's. Been in the works for,\nfor a long time as well. This, these thermodynamic ideas. So, uh, the claim is that things like\nmatrix inversion, which is a very important computation, um, and it's\nvery expensive to do, um, with large matrices, can be done naturally with,\nuh, with, with this sort of approach. So I think, uh, uh, that\nmakes a lot of sense. So just take a capacitor\nand a, uh, inductor. Um, uh, and then, uh, with\nthose, you can actually, um. Set up, uh, the, the matrix on the\nconductors, uh, let it dissipate energy, uh, however it's supposed to. And then the, uh, correlation among\nthese different circuits actually tells you the inverse of the matrix. So, uh, all of that is\nlike really cool stuff. Um. And I don't see why we shouldn't\nbe looking at those alternatives. Like a lens we know does\nthe reciprocal operation. We know that, uh, resistors do\nthis or that or whatever, right? So like, why not do it this way where\nwe shouldn't be beholden to digital logic just because, um, that's how\nit, it's happened over the years. I think, uh, all of these things,\nI guess you take a look back and it's always like, well, actually\nit's been going on for decades. You know? I feel like all of these\nkind of new developments, I, I mean, AI included, right? Is like, just like part of this like\nvery long kind of historical legacy. So for our final topic, uh, this\nwas kind of a, a fun thing that I did want to talk a little bit about,\num, is in a week that was just packed with different announcements. Um, the one that seems to have taken the\ncake, at least in my social media feeds. Has been the release of 4o\nOpenAI's 4o Image Generator. Um, I think, uh, most importantly I\nguess for me is that, um, this kind of meme of rendering everything in a studio\nGhibli format, in an anime format, um, has just kind of like taken over. Like I, my social media feed is\nnothing but these images right now. Um, and so it's a kind of funny moment\nI think to take a step back and say like, okay, image gen like is suddenly\nkind of like, you know, uh, uh, trending again in a way that almost kind of\nlike dampened, I think all the, a bunch of the other announcements this week. Um, and I guess, I don't know,\nplaying around with it, it is really quite impressive. Um, and, uh, I guess similarly,\nmaybe Skyler, I'll throw it to you for kind of like the vibe check if you've played\naround with it, what you think. Um, and if this is actually like a\nbig improvement or, I mean, we've done style transfer in the past, right? So this is in some ways not new,\nbut this seems to have really hit a nerve in a way that like has not been\nthe case for previous announcements. It has. I have not played with it. But again, okay. My feed. Has been filled with people,\nrememeing, all of these different, uh, all of these different styles. Um, I think, I think with this,\nare we, are we in a position? Is, has multimodality, at least between\nlanguage and images, has that been solved? Is this, are we gonna move the\ngoalposts goalposts further down away, or can we say we have cracked, um. GPT-4o    has cracked multimodality. I think. I think they've done that. I think this is, this is some\nreally, really cool, impressive tech. Um, so yeah, I don't know. Otherwise we're gonna again say,\nno, but I can't do this and we'll keep moving those goalposts. So I think it really is, uh,\nquite impressive, at least again, from all my friends, uh, playing\non it and, and sending images over, uh, over social media. Yeah. In some ways, I think, excuse me, having\nplayed around with it a little bit, it is sort of a triumph, not necessarily of images or text to images, but it's almost\na triumph of like the ability to kind of correctly infer what someone is looking\nfor when they, when they search, right? Like I think that's always kind\nof my reflection is it's kind of the first time like playing with\nolder versions of Midjourney. It was like, oh, well not quite this. Can you make this change? Can you make this change? And you finally get to the end. This one is like kind of magical\n'cause it's like very one shot. You're like, I want this. And it generates an imagery. You're like, oh, that's. Kind of exactly what I was looking for. Um, and I think that's really interesting\nand I don't know if, is there, Kay, you're nodding if there's like a\ngood name for like that achievement. It feels like, what's the\nbig jump here in some ways? Well, I think it's important to recognize\nwhere we were before, which was DALL-E 3 which was back in 2023, you know, ancient, Ancient in generative\nAI terms. Way outta date! So, you know, DALL-E 3 more or less\nkind of being called as a tool. So like being swapped in when it's,\nyou know, being called to generate an image based off a part of the\nconversation and then turned off and, you know, GPT-4o oh or whichever model\ncan take back up the conversation. And so I think what we're seeing here,\nI, I mean obviously OpenAI does not share tremendous amount of details on\ntheir broader architecture and design, but based off of what I've read, like on\ntheir docs and the on the release notes, you know, they talk about this being\na more native capability, embedded far deeper in the architecture of the system. And so I think what we're really seeing\nis some really exciting innovations from multimodality focused on system design\nand how can we bring down some of these multimodal components far more core\nto where the language model operates. But that could mean, for example,\npotentially sharing some parameters and, um, being able to kind of bring\ndifferent components together, uh, much earlier on in the process than kind\nof at the very last minute kind of Tool call, you know, call a friend and,\nand then pick back up the conversation. And I think that is the future, not just\nfor multimodality, but for all types of understanding and more specialized tasks. Um, being able to have different experts,\nwhether that's an expert on documents or expert on images, or expert on audio. Being integrated at a systems level,\nfar more internal to the model and having a model or an application about,\nyou know, a chat bot, be far more of a systems based approach versus here\nare some weights that, you know, we're, we're calling, uh, for a given prompt. Yeah. And I guess as someone who's been\nless involved in this, in the day-to-day, I mean, Kate, could you\nexplain maybe a little bit like why ha, why has that been hard? I guess like from moving from like\nsomething kind of, it sounds like bolted in, at the end to kind of\nlike fully integrated in the system. Like what, what makes that difficult? I think part of it is just momentum of how\nthings have been built the previous way. You know, starting with the release\nof the original GPT, you know, 3.5 models and ChatGPT, uh,\nto scale performance has been. Baking it into the model at training time,\ntrain on more data, have more parameters, and boost your performance by just baking\nit all in, in that upfront training step. And so I think a lot of the system design\nand architecture and applications have been focused on, okay, there's this big\nblack box that we make a single, you know, call to, and we get a response back. And we're starting to see more of a shift. And you know, I don't know that\nit's necessarily more difficult. I think in some ways it's actually a lot\neasier to innovate if we're innovating outside of that training and innovating\nmore on the systems based approach. But you know, we do have\nto make a conscious shift. To enable that we don't have the same\ntools and capabilities available. Um, the community needs to build those. Particularly if you're talking about doing\nthis in the open versus, you know,  OpenAI doing this behind a closed gated wall.  They've got a whole inference,\norchestration layer that they haven't released to the broader world. So I think this is a big challenge\nthat open source models actually face in particular is being able\nto catch up to the same degree of this more systems based approach. 'cause we don't have the same\ninfrastructure or the same kind of revenue coming in, so to speak,\nto pay for that, that build out, um, to enable that system. That's really helpful. Thank you. Um, Kush, I'm gonna call on you not\njust as the history person here, but also as the safety person. Um, I think one of the things I observed\nin this kind of like wave has been, I mean, indeed even like the Studio Ghibli\nmeme  um, is something that I think traditionally, I think companies have\nbeen a lot more restrictive on, right? To say, oh, you, you really\ndon't want to copy a style. Right. Um, I've also seen a number of\nimage generations that are a little bit at the edge of kind of\nlike what you would consider sort of acceptable image generation. Mm-hmm. Do you think this also marks maybe\nlike a shift in how companies are thinking about image gen? Like I think there's one way of reading\nthis, which is OpenAI is concluding that actually we should kind of let up\na little bit, we should actually allow people to use these kind of image gen\nproducts more freely, even though it might occasionally generate some stuff\nwhich is offensive, harmful, toxic, so on. And, and I wanted to just get a\ncomment from you on sort of like. The meta here? Like are companies kind of opening up\nin a way that they haven't in the past, and what are the trade offs of that? Yeah, I think, uh, they are, and uh,\nI think the, uh, the image side of things is maybe a little bit more\nforgiving on, on this because, um, uh, for the natural language, the\ntext is more used in business sort of applications, generative imagery. It's, um, uh, I mean less, uh, sort of. Uh, legalistic in, in some ways. So I, I do think that that is probably\nthe, the case and for demonstration and, and for many other things. So, um, yeah, I was actually playing\naround with this, um, and uh, like an example that my wife and I were\nrunning, so she actually did her,  MFA and computer art a decade ago. And she took a class in,\nuh, digital mat painting. And one of the assignments was for a week. Like they had to take an image, um,\nit was a summertime image, and then change it so that it looked like a\nwintertime image of the same scene. And, um, this thing does it really well. I mean, like in, in a minute you have\nthe, I mean, what you were looking for, but then what she was zooming in\non was the windows of the building. Um. Had had some minor changes across,\num, the, the summer and winter image. And so, uh, like at first\nglance, like I didn't notice it. Like, I mean, she is like an expert at\nthis, so she was like zooming in and going back and forth and like really looking at,\nuh, whether something has changed or not. And, um, uh, from the safety\nperspective, like, um, those sort of little minor things that like. Uh, someone like me, um,\ndoesn't notice is probably fine. But, um, uh, once you're at a very\nexpert level, like if you're, um, an actual like movie maker, um, doing\ndigital net painting or like other stuff, then it becomes critical. So as a consumer tool, I think it's\nall good, but there's still a gap. And, um, uh, we have this\nresearcher, um, uh, Morro Martino. Um, he is a world famous AI\nartist and, um, uh, he just created a 12 minute long, uh, AI. Fully AI generated, uh, film,\nand he couldn't use any of the tools that are out there. I mean, he has to innovate\nthe tools and everything else. And this is being shown in\nSeville, Spain these days. And, um, this film is like so\nprofessional level, like you can imagine the difference between what this image generation stuff\nis able to do and what the professionals are truly able to do. So, um, this is not the tool\nfor them, but, uh, I think it's safe enough for, for all of us. So, uh, I think that's the,\nthe way to think about it. Mm-hmm. Yeah, that's really interesting. And I almost love this kind\nof threshold of like, I. Good enough to fool the amateurs. It's like, I think actually\na really important threshold. I like sent an image to a friend being\nlike, you know, it's really impressive that they get the fingers right now. And then he shot back with like a\nzoomed in version of the image to show that there was this like little\nfingertip still hanging out somewhere. And I was like, oh no. It's like, again, it was like kind\nof enough to get past my sniff test, but I think anyone who with\na keener eye would've clearly just not seen, like seen the problem. So on OpenAI's  blog release, they\nhave a little paragraph about how they've used, uh, a reasoning LLM. On the safety side of this generation,\nand I, I don't know if we'll get. Any more details beyond that paragraph,\nbut I, I thought that was interesting. I don't know if they're, you know,\ncovering themselves or, or trying, but it was, yeah, there was this very clear\nparagraph about how they've used their, uh, their reasoning LLM to help, uh,\nparse through, uh, some of these more, you know, I think edge cases of things\nthat, uh, unquestionable generation. Um, so yeah, love to see if we get\nmore details about that going forward. Uh, and why, why they were. Why they called that, uh,\nthat nuance out in particular. Yeah, that'll be really interesting. I missed that and I think it's\ndefinitely worth keeping an eye on. And I think back to Kate's little\nkind of like reasoning kind of vibe check about like how much time does it\nspend, thinking about whether or not it's a good thing or a violation of its content\nguidelines is like a very interesting set. If it happens at training, I don't\ncare how long it takes. That's true.\nExactly. I don to see it like,\ntake as long as you like. It's a reference time. Yeah. Well, as usual, so many things to cover. Not enough time to cover it all. Kush, Kate. Skyler, thanks for joining us\nand thanks to all you listeners for joining us as well. If you enjoyed what you heard, you can get\nus on Apple Podcasts, Spotify, and podcast platforms everywhere, and we will see you\nnext week as always, on Mixture of Experts"
}