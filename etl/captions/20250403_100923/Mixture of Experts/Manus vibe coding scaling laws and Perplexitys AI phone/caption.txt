Is Manus AI a second DeepSeek moment? Vyoma Gajjar is an AI Technical Solutions Architect. Welcome back to the show. What do you think? Almost. Great. Kaoutar El Maghraoui is a Principal Research Scientist and Manager at the AI Hardware Center. Uh, Kaoutar, welcome back as always. Uh, Manus AI, what do you think? I don't think so. And last but not least is Chris Hay, Distinguished Engineer and CTO of Customer Transformation. Chris, DeepSeek moment, yes or no? Yes, but no, but yes, but no, maybe, yes, no, maybe. Well, we'll be investigating all that and more on today's Mixture of Experts. I'm Tim Hwang and welcome to Mixture of Experts. Each week MoE gathers just the nicest and most brilliant people to talk through the biggest news in the world of artificial intelligence. As always, there's going to be a ton to cover. We're going to talk about vibe coding, scaling laws, a new phone from Perplexity. But first I really want to talk about Manus AI, which was the focus of our initial kickoff question. If you've not been watching the news, Manus AI is a Chinese company that announced a multi purpose agent, um, that has really been kind of taking the sort of AI chatter class by storm. Uh, they have a bunch of demos showing their agent able to pull off some traditionally quite difficult tasks. So they show it, you know, scheduling trips, uh, doing stock analysis, reviewing resumes, evaluating insurance. And so it's a really, really wide range of outcomes. And it seems to be another moment where following hot on the heels of DeepSeek is another time when people have been kind of asking, like, Is China really catching up, if not surpassing a lot of the companies that we talk about almost every single episode on the show at MoE? Um, you know, your open AIs and Anthropics of the world. And so, I guess, Vyoma, maybe I'll start with you because I think you were the most bullish. I think you were like, it's close to being a DeepSeek moment. Um, do you want to kind of lay out sort of the bull case here for, for why it actually is a really big deal? Um, sure. So as you know, half of Silicon Valley is building, um, agentic AI startups right now. And Manus AI is an agentic paradigm that we are seeing. It is more of like an industrialization of intelligence that has been created from all these large language models that we are seeing. If done right, like if they can work well on the compute side, the hardware side, they can come up with something because again, they're first in this entire way, um, paradigm of bringing it out to the market. I know like there are so many other agentic frameworks available. So I feel that. If everything goes right in like 10 other aspects that we have to evaluate from the metrics, hardware, the software, the compute, etc. Maybe, but then, as I said, there are 15 others, or 50 others who can always catch up. So, you never know. Yeah, definitely. Um, Kaoutar, you were a little bit more skeptical, I think, in the opening. Um, curious about what you think here. You know, a friend of mine was kind of saying, it's easy to have a really cool looking demo. Um, and like a real product is like a whole nother thing. And we don't really know whether or not Manus can deliver. Is that kind of the source of your skepticism or is it coming from somewhere else? Yeah, I think I'm, I'm still a bit skeptical about this. I think from my perspective, Manus, um, is definitely shaking things up here a bit. I mean, of course there is a lot of also scepticism in the AI community. Some argue it's transformative. pushing the boundaries of what the AI agents can do. Others just say it's just a rebranding of what's maybe, uh, uh, the cloud wrapper, uh, or cloud is doing more like smoke than fire. The big question here is can madness really redefine the AI autonomy, or is this just another step in an ongoing AI race between East and West? So. Is it just, you know, a leap or it's just, you know, more advancements here? Um, so I think there is a lot more evaluation that needs to be done, uh, to see whether we're seeing, uh, new innovations, a leap, or just, uh, kind of maturing up this technology. So the community is really interested in the implications for AI agent development. So if Manus proves to be a significant advancement, it could accelerate the creation of more, um, sophisticated and capable agents. But of course, there is a lot of pressure here. So there is growing awareness of the increasing competition from Chinese AI companies. Uh, you heard from Vyoma that, you know, half of the startups are agentic, uh, AI companies. So there is a lot of competition here. And I think a lot right now are analyzing the output of what, uh, Manus is doing to see if they can see the hallmarks of Claude's outputs. If this is the case, it's really diminishing the hype surrounding, you know, this product. Yeah, for sure. And I think it's a good chance to bring Chris in. I mean, on this kind of Claude point, uh, the background on all this is that, pretty soon after Manus came out, people said, well, there's a bunch of responses here that are like very kind of Claude flavored, uh, and in some cases we're actually able to kind of like pull out sort of like some verification or some strong evidence that it was from Claude. Let's say for a moment that it is just a Claude wrapper. Does that kind of totally diminish this as like a, an outcome? Like I don't know how we should think about that. I know a lot of people said, "Oh, if it's just the wrapper, then, you know, Manus really hasn't added all that much."" So I guess from my perspective, I mean... Let's think about Cursor, for example. Let's think about Klein. Let's think about Perplexity. We could probably argue all of them are Calude wrappers as well, right? Which is, you know, they're all tools where ultimately Claude is driving the experience. But actually, I don't think this is a story about which AI model is powering it, although I think that is important. This is really a story of somebody bringing together a really great experience and I think they have brought together a great experience because when you use the Manus UI, it does the planning and it's got a little to do list and it ticks and it ticks it off as it goes along and then it's going to have access to the tools, it'll access the terminal, access the browser, very similar to what's going on with, you know, OpenAI with Operator, etc. and Deep Research, for example. They brought that together in a nice experience. They're running it on a sandbox. They're doing tool calling and it kind of feels good. Right. And now it's a little bit more than a Claude wrapper to be fair to them. They have, you know, taken the open source tools and they've integrated them really well together. Right. So, um, so technically we could go and do this ourselves. And I think that's. Why this is probably gonna end up, this is why I went. Yes.
Maybe, maybe, maybe yes. Yes.
Maybe. 'cause I think what's gonna happen is the open source community is gonna go, we can do that. And, and I know that 'cause I've been coding away all week, uh, doing the same thing. Right. Trying to do the same thing. Yeah, exactly right. Like, like every other developer on the planet. Right. And, and therefore. It's something that's achievable. And, and to be fair to them, it's a little bit more as well. They said that Claude was doing orchestration, but they also said they fine tuned a bunch of Qwen models. And I think specifically said that for the, the planning model, the, the one that sort of comes up with the to dos, et cetera, that was a particular kind of Qwen fine tune and they pointed to a version they'd done earlier. So, so it's a little bit more than just, here's Claude with a pretty UI. It's a bunch of fine tuned models. It's, you know, bringing these tools together, sandboxing it, and then bringing the package in together. And I think they've done a kind of a fabulous job. And then finally, they've generated the hype, right? I mean, I was reading today, it had like 2 million folks have signed up for invites. So, we're all running going, yeah, we're going to do this. Will they be around? Are they the next Devon? You know, we will find out in six months or so. Right. But, but for just now the hype cycle's there, but I'm hoping it galvanizes that open source community. And you had a good phrase there, which is, you know, they're tying together a bunch of components and like, sort of we could do this as well. Um, and I did want to dive a little bit into that because I have a friend of mine who you know, he focuses a lot on all the kind of like state level AI bills that are kind of bubbling up. And he made the observation where he's like, well, look we the US Companies could have done this US open source kind of efforts could have launched a very similar thing you know, maybe one reason they don't is because like some of the things that Manus is showing off, you know have been kind of risky from a legal standpoint in the US, right? Like things like resume review is like a thing that, you know, kind of is like very hotly regulated. It's a hotly disputed thing. And so I guess maybe I'm going to toss it back to you. Like, do you think almost there's kind of like an edge here? Like almost like Manus is winning this or in the very least they kind of seem like first to getting this like hype wave just because they've been willing to be more aggressive than other folks or do you do not really buy that? I feel the first thing that Anthropic cloud had tried something called computer use we spoke about it in this board with you and which is sort of compared quite vigorously right now with Manus AI but the computer use Anthropic cloud version it actually performs very well in controlled environments exactly what we're talking about. Like, let's say if there's resume review, et cetera, it brings along a whole different metric system that has to be evaluated for a large language model to be used. Like a use case, POC is very different from what can you integrate in an enterprise architecture, right? And how do we integrate it? So sure, Manus showed the way that, okay, yes, this is how we can do it, but to actually do it. It's going to be a lot of leaps and bounds that the entire industry has to go through, regulations, et cetera, uh, have to be written around it for us to be able to use it. But yes, the US did try it and that the computer use part was actually something that we were all talking about for a while, right? So Kaoutar, I guess maybe the final kind of question and curious to get your thoughts on this is whether or not like, take us six months into the future, like Chris is saying. Like, do you have predictions on where this all kind of goes? I mean, one thing's for certain. It seems like we're going to see a bunch of open source attempts to kind of do the same thing. I guess we can ask the question of whether or not this Manus thing actually changes the fundamental trajectory of where agents is going. Um, but kind of curious if you want to paint a picture of like, where you think we will be in six months. You know, if anything, Manus is kind of just building more hype and more momentum in this direction, but curious to get your prediction. Yeah, I think it's a good question. I definitely feel, you know, I agree with Chris. That's, you know, what they're doing is, it's not just integration, but it's also more about having this fully autonomous. agent capable of independently executing complex tasks, doing various things like sorting, stock trend analysis, website creation, which is really great. So we will see others trying to mimic that. Uh, and they're leading in this space around, you know, this autonomy. Uh, so beyond mere integration, making a significant advancement in the AI autonomy. But I think whether, uh, more hype will follow, I think. It's gonna be the case. Uh, we're seeing now every few days or every few weeks we're seeing new hypes. So I feel we will see, uh, more interesting things coming in this space here. Yeah, it's like if this is a DeepSeek moment, then get ready for like at least 20 or 30 more this year, I suppose. I just want to say, you know what I don't want to see in six months? Another browser operator. You know what? Large language models are really good at text, right? Why? Why are we insisting we have an AI moving a cursor around, finding a bounded box, taking a screenshot, and then typing into the box? You know what I would rather see? I would rather see somebody go, you know what, I'm going to create an AI native browser which parses the text. And actually, yes, it's going to communicate with, with, you know, the websites, and they'll recognize it as a real browser, et cetera. But you don't need to do screenshots. You don't need to move a cursor around. You're a browser and you're a large language model that knows how to code. Do that. That's what I want to see in the next six months. People have gotten lazy, Chris. People don't want to do that. They're like, if we can have someone do this for us, why not? I'll sit on the couch all day. I'm fine for them to sit on the couch. Just, just don't move a cursor around. That's what I'm, that's what's, and take screenshots. That's what's bothering me. Yeah I think that is one of my favorite agentic tropes at the moment. I mean people do it because it looks really cool. Like that's the main reason is that it's like it's it's kind of cool and spooky. Yeah I think it's more for demo purposes. And also for people to like show that this is how we can do AGI. Like this is the next step to AGI. That's, and I think everyone's chasing that now that, okay, we're done with the LLMs, et cetera. Now let's move on. But Vyoma, it sounds like you're defining AGI as a 95 year old grandparent trying to work the internet for the first time. That, that's what I see when I see the AI operate with a browser. Yeah, that's true too. I mean. That's what we defined, I guess, at this point, but let's break that. Yeah, I think it's going to be interesting to see how these human interfaces will evolve. So I agree with you. I also don't like the cursor on these things. So probably more serious thinking into what would be interesting for us to see as these interfaces. What would you like to see? So it really mimics a true human experience without having this cursory or, uh, screenshots and things like that. So, yeah, for sure. Uh, Chris, if for your weekend experimentation, have you been able to replicate Manus? I am surprisingly far. Actually, I went slightly different from them. So I've put MCP at the heart of what I've been doing, uh, which I think is, is a lot better, but then I haven't built a product and got it to 2 million people. This is just Chris and his agents in the night. So I, you know, I don't think I can take the intellectual high ground on this, but I, yeah, I've got, I've got pretty far so far. Yeah, that's actually, I mean, it's a pretty, uh, strong indication, right? Like with not a whole lot of work, you actually get pretty far with these things. Um, I guess it just goes to show how competitive this space is about to be. I'm going to move us on to our next topic, which is a real fun one. Um, Andrej Karpathy, who we've talked about many times on this show before, in addition to being, you know, former Tesla and former OpenAI, I think he's had this kind of like career job in sort of shaping the memes of the, uh, AI space, um, we mentioned Cursor earlier, arguably his shout out of Cursor is one of the reasons that Cursor has been so wildly successful. And, um, he had a nice tweet kind of capturing sort of his thoughts on kind of using AI assisted coding recently, where he said: "there's a new kind of coding I call vibe coding, where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs,  e.g. Cursor Composer with Sonnet, are getting too good". Um, and this has kind of been a funny thing because in, you know, true Andrej form or Karpathy form, um, the vibe coding has just kind of like gotten everywhere. It's just been like a joke that people keep mentioning now. Um, and, uh, and weirdly, I feel like in the last week or so, or however long ago, um, people have been like, oh yeah, I'm like, I did this project through vibe coding. You know, it's almost kind of now becoming like a, a term of art. If I may be able to turn it to you first is like, is vibe coding a real thing? Like, is this the future of coding? Is people just kind of like, you know, just kind of vibing with it until an app comes out? Um, is this a good way of kind of thinking about where engineering is going with all this assistance? Yeah, it's going to be very controversial when I say this, but no, it's not. I don't think this is the future. And I feel that getting to know the concepts and the basics behind how a particular code works is something which is extremely important. Sure, you you won't be able to like code it end to end. You can use wipe coding to assist you with that. But that being the only uh, crutch that we all rely on, I don't think this is going to be successful. Like sure, I can do wipe coding for a weekend project to test out something that I want to maybe show a small POC to understand the concepts. But for a diff, and a diff which is like going through millions of lines of code over there, you use that particular code to solve that diff. And then, put it in production. So totally against that. I don't think that's the right norm. The other thing is, I know everyone keeps talking about white recording, but if you go back in the interview market right now, you have to go through a lead code interview. You have to do solution design. So the basics aren't going anywhere. People are talking about it, but yes, you have to traverse a string if needed or like. add the nodes of a binary tree. Yes, you have to do that. It's not because people want to know how well you code, but they want to know whether you understand the concept. Right?
So that's something that I feel, um, is needed. Yeah, so there's a lot to unpack there. I mean, I think the first thing maybe to get into is, yeah, I don't think even Karpathy is like, oh, you should vibe code. Vibe code like an enormously complex project. But I think it is kind of this interesting debate. I mean, you sort of say like, look, this is going to work for your weekend project, but probably not much further. I think there's almost a question of like, where do you draw that line? Like, how far can you get with vibe coding? If everybody agrees, you can't do the most complex thing, but you can definitely vote vibe code the simplest thing. You know, this dividing line gets very fuzzy as these models get better and better and I think it is, it is a genuinely interesting question. I'm curious if, are you a vibe coder? Are you, do you vibe code? I do it sometimes and I like it. Actually, I'm really fascinated by vibe coding. So, um, and I see vibe coding as kind of a reflection also of the changing nature of software development where AI tools are increasingly being adopted and they're increasingly handling routine tasks. Uh, allowing, you know, the coders to focus on higher level design and problem solving. Of course, I think I'll see we're evolving into a world where we're going to be combining both vibe coding and serious coding. But of course, understanding what this, what the AI is generating, how to test it, how to integrate it, how to do all these, these diffs and so on. It's still going to be very important. Whether we're going to get to the point where it's all going to be automated by AI, I think it remains to be seen. Uh, I think we're heading into the direction as these, um, AI, uh, LLMs are becoming better and better and coding. Uh, one of the things that I'm a bit concerned about is the rigor. Um, so the vibe coding, you know. could also lead to this decline in code rigor and best practices. So there is a worry, you know, that I see that are we getting into also less experienced coding coders that rely more and more on vibe coding, especially among students, people that are still learning, uh, you know, they're, they're given an, uh, programming assignments and they'll just go and ask, you know, an AI agent or a LLM to give me the assignments and then most of these assignments sometimes, you know, the AI does pretty good job. So, um, so they're definitely going to be an influence in these, uh, vibe coding or AI tools, uh, influencing the coding styles and the practices. Uh, but this is also enabling more exploratory and iterative approach to coding. Yeah, for sure. My friend actually, he, uh, he coded up this app. And, uh, I was like, oh, so like, what, what does this menu do? And it was very funny because he was like, I just vibe coded it. So I'm actually not really sure what it does. And I was like, I don't know if this is like a sustainable way to go about building bigger systems, but this bleeds pretty well, I think, to Vyoma, a point that you made, which is first you said, okay, it's only going to be good for weekend projects, not anything bigger. I think the second point that you made is also really interesting as well. If you want a job as an engineer, they're still going to make you go through LeetCode, right? Like you still are forced to kind of like go through this gate. And I was joking with a friend recently. I was like "Oh, well, I'm just looking for the 10x vibe coder". Right? Like someone out there is able to vibe code like way more proficiently than everybody else. If I can just find that person, um, maybe he doesn't, he or she doesn't need to know LeetCode. So even, I'm not saying that LeetCode is 100% a reflection of how good, uh, a software engineer you are. But even if you're not able to solve that pseudocode, how does that if a statement work? How does this while statement work? Trying to explain what you are asked from a LeetCode question is also good enough in case you're not able to code on spot during that particular time that I'm asking you. A 10x viber, vibing coder that we are naming it, I don't know. If that particular coder would actually even understand a legacy code that has been written because for that you'll have to go back and understand, okay, what's a function, how did that function, what are the parameters called in this function, how is a parameter written here, so I'm not there yet, maybe I have not seen a good use of that entire, uh, system, but maybe, um, people might get better. The models keep getting better. I totally agree with that. Sure, you can use it for grunt work, like if that was one of the questions that, uh, was coming up when I was reading about it is like if there is a CSS file and you need to change, uh, a particular bracket or a button, you don't have to sift through thousands of lines. Of course, sure, you can use it for that because obviously better use of your time to do something else, learn something better, but for you to build an application end to end, I don't know if it's the best way to do it. I can say right now, this is, this is here to stay. This is not a weekend project thing. And, and as somebody who's starting graduate job was writing Unix C motif, and I, and I can tell you right now, I spent most of my time chasing memory pointer bugs, right, you know, and I am never going back to that nightmare ever again. I, you know, you talk about productivity. You look at your own terrible graduate written code and try and work out why that memory location is not the place you wanted to point at. You know what, I, and you watch your dreams die as every time you boot up your application and the thing goes, wow, wow, wow, wow. You know, and what, what. What I can do with a large language model is I can go Ctrl+C, Ctrl+V, and with the error message from the compiler, and then say, fix this buddy, and then it goes, ah ha ha, you, you messed it up over here. Oh, that's great. I will just copy and paste that back in. Or using Cursor, I don't even need to copy and paste, I can just go. Click, click, click, like Homer Simpson in the nuclear power factory when he was working at home with that little pigeon going dun, dun, dun. That's, that's the world we're moving to, right? So I'm, I'm all in. I'm all in. Okay, there's about, you've got some inbound here. Uh, Kaoutar, how about you go first? I'm a bit worried about also if we only do this, then if you really want to do software hardware co design, really doing optimizations, then people will lose the skills to understand the computer architecture. What does it mean to have a dangling pointer? How do we do these memory allocations, the efficiency? I mean, I see that right now as we are designing. these efficient systems, having a core understanding of these concepts is very critical to know how to optimize. So if we're just going to do vibe code and then people have no clue what, you know, underlying systems are doing, how they're behaving, what does it mean to have a cache hierarchy, you know, all these implications about, you know, the data movements and the computational units, the bottlenecks. We're going to lose that. And that's what worries me. And how do we optimize these systems end to end? I'm okay with losing that, to be honest. I'm still having, yeah... Of course, it's not for everyone. I'm having nightmares from, from my past. there.
You know, so no, I'm fine with that. But then, but honestly, I think, I think those skills are important. I think we have different, uh, we have different skills within the engineering practice, and I think that's going to expand out. And, and if you really think about it, I mean, like, if you think of something like Lewis Hamilton as a Formula One driver, one of the best drivers in the world, etc. Does he know how to change a tire? I don't know. Maybe he does, maybe he doesn't, right? But, but what he does know how to do is drive a Formula One car at speed through, you know, uh, the race course and better than anyone else. Now, the question I would have there is that there is a wider team, right? Some people are going to be specialists at tire changes, some, you know, ball bearings, whatever. And I think that's, that's pretty cool. So, not everybody needs to know how to deal with dangling pointers, right? Some people just want to build an app and get it out and try and make some money. Go for it. Yeah, there's some interesting history here too, because it's almost like, I guess, you know, just think about like the first people who built planes, right? Like the Wright Brothers. They were like, you know, engineers, right? And they were like, you know, modifying bikes to get the plane to work. And like, yeah, if you're flying a plane, then it almost breaks down so often that you really need to understand every bit of it. Right. And then now pilots have a certain level of training, but they're not necessarily airplane engineers. I actually wonder if that's going to kind of interestingly have that divergence in coding over time, where you almost have like good coders, but that's almost like a discipline that's almost separate from like understanding the inner workings of the machine. And. You know, I guess we get that in part because like machines become super reliable, right? Like your car is not breaking down every single day. So you don't necessarily need to understand. But you know, software used to break down all the time. And so you really do need to know those internal components. And first of all, I'm very happy to know that Chris is a fellow F1 supporter. So even if Hamilton doesn't try to fix a car, Chris, I think he would know how to do it. Like theoretical concept. That's all I feel is. actually needed in the wipe coding part and the other thing is I wouldn't entrust anyone with like a wipe coder with the nuclear reactor control system, but I would make sure that, um, anyone who does wipe coding actually knows what they are doing with it. So as long as that loop ties back, I, we are okay with it. But if it doesn't, and we have someone who's just like vibing with in minimum amount of data points and trying to make something production ready, I don't think I'm comfortable with that. I, I think, I sort of agree with you and I think, I think we're going to move from one extreme to the other and I think that's the reality, right? And I, I can see a world where you're going to vibe code to prototype, you're going to vibe code to figure out some issues, etc. And then it's almost, I think, I've never painted, but it's like, you know, those like Monet paintings or whatever, and then it's all sort of blurry stuff, and then you sort of hone into the detail, I think that's going to start to become a bit of a pattern, right, which is like, okay, I kind of need something like this, I'm going to do this, you're going to orchestrate it. And then you're going to start to say, okay, I know what I've, I've built here. I prototype this. Now I'm going to start engineering this further and then go down and detail. And so I think there's probably a hybrid model, but then the flip of this is, is we're looking at this from an engineering perspective. Why can't that person who's never coded not go and create an app for themselves and get it in the app store and make some money or maybe somebody who wants to do a home automation project, but has never had those skills. Why can't they vibe code and then be able to do that thing that they've never been able to achieve? And then you know what? It might get them interested in the discipline and might want to say, you know what? How does memory work, right? And then they start delving into that. So I, I think actually it's an area where we can have a greater inclusion and greater impact and, and a larger community. So I, I, I hope that's the direction we go in. Yeah, I think the feedback loop is super important. Um, I mean, at least for me who like doesn't really code day in and day out, like the ability to use these tools just makes the experience of like, I have 45 minutes after my kids have gone on down to like kind of play with the computer and it's like oh I could just like get further in that time and it's just like a very strong feedback was like very satisfying in a way that kind of like pre these tools like you didn't really have. A final anecdote that y'all might find interesting. So my mom was like a very early coder. And so she still remembers like, you know punch cards and it's it's Chris to your point It's like it's interesting to me how much like if you felt a lot of pain coding, you are more likely to want these tools because you remember how painful it is. Like my mom's response is oh, yeah I remember programming a big box, like, of punch cards, dropping them, and then basically spending, like, hours having to, like, recompile. And she's like, I love this. Like, we just, like, automate everything, basically. Um, which I think is, like, kind of a really fascinating aspect of, like, people's personal experience of just, like, how difficult it is, might make them more or less willing to adopt these tools. And you could imagine a vision model, multimodal, controlling an action model with a robotic arm, and then that robotic arm can resort those punch cards, and your mom would be fine, right? And that's right. Yeah, exactly. We should.
That's right. I need, I need the, the coding assistant, but for, for punch cards, that actually would be an awesome project. I agree with Chris that it's going to be a hybrid world where we have these people who have no clue about coding, but they're still being able to use this vibe coding to create really nice things for rapid prototyping or proof of concepts or applications maybe that have been mature by these, uh, tools. But then we still need the people who really understand what's, what's happening behind the scenes, who can know how to debug, who can know to optimize. It's going to be specialization at these different levels. For sure. Yeah.
And I, I got to believe, I mean, some of these debates happened when like object oriented programming came around, right? People were like, ah, you don't understand the DNR workings of the system. It's like this battle happens almost at each layer of abstraction, uh, arguably. I'm going to move us on to our next topic. Uh, we wanted to do a quick segment to talk a little bit about scaling laws and this segment kind of puts together. I think a couple of things that we've touched on last few episodes, particularly when it comes to DeepSeek. Um, and I think Kaoutar, great to have you on the show because I think you suggested this topic. Um, the background here of course is, uh, scaling laws are really the idea that we have kind of this interesting relationship in machine learning where sort of the, the more compute that you're using in doing pre-training the better the capabilities are that kind of come out. There's kind of this rough relationship between like how much kind of like muscle you're putting in and the model that kind of comes out of it. And you know, this has been kind of like the thing that has motivated the entire thesis of these companies, particularly the kind of frontier model companies raising enormous amounts of money, which is to say well if we want really powerful systems, we really need lots and lots of data lots and lots of compute and we need to do the biggest possible sort of pre-training run that we need to do and I know Kaoutar, you wanted to bring up this topic because you want to talk a little bit about how you think that DeepSeek kind of doesn't necessarily break this idea, but kind of nuances it a little bit. Do you want to talk a little bit about that? Yeah, definitely. So of course, as you mentioned, in traditional AI development, there is this general belief that bigger models and larger data sets lead to better performance following the scaling laws. And this often translates into these massive investments in hardware and infrastructure. But what this DeepSeek really demonstrated, uh, they're challenging this traditional AI scaling laws. They're demonstrating that smaller, more cost efficient models, they can achieve competitive performance. And they're, you know, even this titan existing business models, reliance on these large scale infrastructures. So they, they used a lot of techniques, uh, like, uh, uh, quantization and distillation and, uh, they even, you know, did some optimizations at the PTX level, given the limitations that they had with the H100 GPUs. So a lot of focus on efficiency, oversize, so, uh, emphasizing efficiency rather than the sheer model size and optimizing at different levels in the stack and also looking at, you know, enhancing the data quality and employing better training strategies. So I mean, the, the, the key idea here is how do we leverage smarter techniques, uh, or smarter training techniques, for example, for their, in their example, that achieves better performance with fewer parameters and reduce these computational costs and computational needs. And I was really fascinated by the wide range of techniques that they have used. You know, they had these data centric approaches. They also had the hardware wear optimizations. They were considering also sustainability. Um, and I think this has, you know, implications on the AI community. So where the focus here is shifting from the scaling by size to scaling by efficiency. I think this is actually, I mean, like there's a lot here that we could get into. Um, I think in some ways for me, the kind of scaling law question is kind of interesting because it has kind of turned out that people have meant a couple of things when they say scaling laws, um, in, in the popular, uh, kind of discussion of AI. And, you know, one of them is just like how much compute you need. Um, and I guess in some ways DeepSeek doesn't really change that. It certainly changes the kind of platforms you need to get high performance out of the models. Um, but I guess it doesn't really necessarily kind of eliminate the idea that like more compute, like, equals better performance. Is that, is that right? Is that the right way of thinking about it? I don't know, Vyoma, if you want to jump in. With the scaling laws, with DeepSeq, with etc. I see a new shift in people trying to optimize GPUs. Or, uh, the ways in which they can revolutionize this entire field. So I don't know if, uh, people know about this, but a month ago, Meta and NVIDIA came up with a paper and with some, and they said something called as warp specialization will be a part of PyTorch. So it kind of optimizes the GPU performance on the, any of the hopper architectures, like the H100s that they do by assigning like some sort of distinct role to each one of these warps. And what is one warp? Like a group of 32 threads that are running. So it kind of pivots to this entire point that we are looking into how do we optimize all of these hardware specs, which are also available based on the previous information that we've got. And I think that had it also came into picture because of some of the scaling loss that we've been seeing. So I don't see that as a way in which it would limit us, etc. I feel we've come up with better ways. Right. It's not necessarily about magnitude. It's more like how we're treating the GPUs basically. Exactly. Exactly.
I think the hardware where optimizations are becoming increasingly important. If you also see the work that's happening around these state space models and, uh, the flex attentions. Every now and then we hear about, you know, different algorithms around flash. You know, how do you do these transformer attention computations more efficiently? Like there is a flash attention. There are various versions of these flash attentions. There is a flex attention. Now the Mamba and the Bamba models. They're also doing a lot of optimizations by understanding the underlying architecture, especially the GPUs right now, and then figuring out how to restructure the computations, and especially the data movement so you can drive more efficiency from the hardware. Um, so also other things like the test time computes. which is something that is also becoming very important. So instead of focusing solo solely on pre-training computes. So, and this is an example also that DeepSeek, uh, uh, pointed out, which can we focus on inference time computes, which is really more critical, meaning smaller models can compute more at test time, longer reasoning. Tree search, Monte Carlo inference, and things like that. And this also reduces the need for enormous parameter count. There was a very interesting paper about test time computes, which showed all of these techniques that really focuses on how do we bring more from the model during test time, not during the pre the training time. And also the distillation, this creating these compact models with large model capabilities. So, of course, you still need to have the large model, but we can create a variety of distilled versions that do really better and can also inherit knowledge and reasoning from much larger models. And of course, you know, I think the high quality training is also something that is outperforming this raw scaling, smart data selections, better fine tuning, reinforcement learning with self improvement. So well trained models can also outperform these poorly trained massive models, especially if you focus on the data quality. Yeah, I was just going to say I think actually we've came from a world of vibe training, which is really, if you think about what was going on in the beginning, which is just like, we're going to take some transformers, and we're just going to throw a bunch of data and get it to NextSoak and predict. And actually we're in this stage now where it's really about honing the algorithms, honing the chain of thoughts, as you say, starting to engineer things. I mean, Kaoutar, you made some really good points on DeepSeek, right? So actually one of the interesting things they did, I think it was last week, is they open sourced a whole bunch of their, uh, code bases that you use to train. So, and that's everything from data frameworks, they, they even engineered themselves a new file system, a distributed file system, etc. So, actually, all of these engineering techniques, anything you can get more efficiency, anything on a better training, I loved your point about the high quality chain of thoughts and inference time compute, that makes a huge difference. That allows you to, to then. start getting smaller models, higher quality models, and I really think we've moved into this kind of engineering phase. So, but I'm going to, I'm going to, like Karpathy, I'm going to, I'm going to call vibe training and see if, see if I can, see if I can get myself a Wikipedia entry off the back of that. Yeah, you heard it here first. Um, I guess Kaoutar, maybe I'll throw it to you for the last kind of question here. Do we think that scaling laws no longer matter? Like, do we care about scaling laws anymore? Given this kind of new era of optimization that we're now in? Yeah, I think we should really shift from just bigger to more smarter and more efficient models. So I, we should really redefine the traditional scaling laws as they were defined by just bigger, better, but I think it should be about smarter and more efficient. Well, I'm gonna move us on to our final topic. I want to end on sort of a, a kind of fun, sort of odd story that kind of came across our um, uh, sort of cues. Um. There was an announcement recently that, uh, Deutsche Telekom and Perplexity, um, were going to work together to announce and launch, uh, what they call an AI phone, which would be a phone that integrates a bunch of, I guess, AI features for less than 1,000 and coming out in 2026. Um, and this news kind of struck everybody as like a little bit sort of surprising in some ways, because if you know Perplexity, the company, um, they largely have been in the world of, uh, AI search, AI powered search, right? I think they're one of the first to market in terms of, you know, you ask a human language query and it gives you sort of results, um, that, you know, attempted to kind of be better than what you'd get from the sort of quote unquote sort of 10 blue links or 10 links from, from Google. Um, and so I think the first question, which is that it's a very kind of perplexing announcement for Perplexity, uh, to be getting into the phone space. Um, Chris, you're already smiling, so maybe I'll throw it to you first. Why is Perplexity doing this at all? Tim, when you're on your mobile phone and you're doing your Google searching, do you ever go to  www.google.com and then type in your query there? Is that your action? I do never, I never do that. What, what is your action, Tim? How do you search on a regular mobile phone? Uh, I would say open the browser and then I type my search term into the browser bar. Exactly, so this is what this is really about is controlling the browser bar, right? So, at the end of the day whoever controls the browser bar means that they can direct those queries to their search engine. So, if I was Perplexity, I would absolutely launch a mobile phone where I'm in control of the browser bar. That's, that's my opinion of what they're doing, and that is a smart move. Uh, do you all agree? Vyoma, Kaoutar? Uh, curious if you are like, brilliant move by Perplexity. This is exactly what should happen. And I think this is also marking a shift in the user interface, you know, how these, how we're interacting with our phones to shift to a more voice centric AI driven user experience, potentially reducing also the reliance on the app based interactions, like, you know, going to apps and so on. I think maybe this is going to shift and change with the, these AI phones. It's going to be maybe a completely different experience that is mostly voice centric. And probably we'll see the disappearance of the apps. And more of these agents in the background working together to satisfy whatever we need. Yeah, the interface part of this I think is really super, super interesting and it's something I actually want to dig into a little bit more. You know, one thing that has been said about a lot of these AI search features, right, whether it is perplexity or what Google is doing. is that increasingly they're kind of moving to a world where you don't have to go to the underlying website, right? It kind of curates the result for you. And so I guess Chris, to your original question, it's like, it's, it's kind of very weird to see. It's almost like the whole feature has been turned inside out, which is you are going to a browser bar. To not browse the web, but instead to get the results of a chatbot. That's, that's really strange, from my perspective. And that chatbot is gonna launch its own browser instance, and then Google somewhere, go to somewhere else, look up that website, and then come back with the answer. It, it's gonna be weird. Definitely. And I think there's almost kind of like, uh, the, the interesting debate here is I think the business rationale for Perplexity makes sense. It's almost a question though of like, how valuable is that browser bar going to be in the future? It of course has been like, I mean, it's been the source of a lot of litigation on like, say, Apple working with Google to have it as the default search engine. But you can almost imagine a future where, you know, maybe the app is actually the more powerful thing. Like when I go to want to know something, I actually don't go to the browser bar anymore. I just go to perplexity. Or in Kaoutar's world, it's like, I just speak into my phone, and the phone just does what I want it to do. Um, you know, I guess, uh, Vyoma, maybe I'll ask you, is like, is there a world where almost like, uh, Perplexity is trying to seize this real estate on the phone, which actually might not be so valuable in the future? Like, maybe browser bars are just like, going to be a thing of the past? Just FYI, uh, it, it has taken over my browser bar for sure. I've been using Perplexity for months now. And so I have many of my friends, you want to research anything, like in my past days, I would go back and like be like, Hey, I want to order these new headphones. space, Reddit. Now I no longer have to do that. Like, I, my, it's on my home screen. It's right there on my mostly used apps, because that's all I use now. I don't research anything no more about, so it has totally taken all that. And AI layered integration at the OS level is much better than anything, any standalone app that exists. So I think Perplexity has hit it outside the park there, and the only one thing that I sometimes struggle with in Perplexity is when I actually want to buy something. So let's say I want to buy a mattress or like a particular lampshade, then I will go in and then I'm researching about it. It's not getting that kind of consumer knowledge about me, like Google has, because of course Google's integrated at OS levels for that context for years. So this is going to be a great pivot for them to make their product or their large language model or their app more context aware, which is the need of the hour now. So it's going to feed all these usage patterns back. And I think I'm never going to lose perplexity from my phone. I love it. Genuinely. I no longer have Google search bar on my phone anymore. That's a, that's a big deal. Yeah. And, and, and I live in the Bay Area and there are many, many people who use that. So believe me, like you'd see them pop it out on their phones all the time. I have friends who use that. So I feel that is, um, one of the things that I'll see, but the one thing that they didn't speak about in that entire blog post was the hardware specifications of it. So what is that inference, um, layer that they're going to use? Is it going to be sound? Robust local interference with like the typical cloud or are they going to be using on prem such as the NPUs or TPUs, etc. So that is going to be the deciding factor, whether it is here to stay or not. That's a very good point, Vyoma, because this definitely depends on how mature or how powerful the edge AI models, especially the on device AI. So, as we're getting, uh, basically these LLMs to become smaller and more efficient, more AI processing can be done on the device. And this provides, of course, faster responses and better privacy. And also what you did is context that allows customization. So I, I see this evolution. I go in hand in hand as the edge AI becomes really more mature and more powerful. We can do more with these AI phones. Exactly. Yeah, the price angle I think is, I hadn't really thought about that. That's, that's very interesting is, you know, almost how, how cheaply can you pack these features into the phone is going to be this really, really interesting question. Cause right now it's almost like a luxury feature. If you want to run kind of a more sophisticated model, then we got to have all the power and all the build out and all the hardware at the edge. It just makes for a much more expensive phone. And they're promising for like less than a thousand dollars. And again, it's already very funny to be like, it's a phone, but. It's going to be cheap. It's going to be less than 1, 000. But even still, like, I think to kind of pull that off is like, pretty interesting in terms of how far you can democratize this tech. Yeah, it is going to start this whole wave of having these specialized devices. I hope we are not going back to the era of the Amazon, Amazon Firephones, how it kind of detached itself and wasn't that great. But I hope that this kind of breaks that curse and we are able to see something greater and better on this. I agree Vyoma, I think I just, I want to see that new experience as you say there, right? And you know, yeah, a native integrated experience and, you know, have all your contacts but it be private and, you know, and I loved your point, Kaoutar, about voice, etc. I think there's so many different modalities that can kind of come into this and, you know, and again, back to the camera as well. So I just, I just hope that we get a different and new experience.   But I, as I said earlier, right, is if you want to, if you want to control that search experience, you need a device there. So I, I do think it's a brilliant move. Yeah, this is all happening while Apple is delaying its AI features. I don't know your take on this. Uh, is that because they want to make sure that they have a very well curated, secure, because Apple in general has been conservative about, you know, the security, Or, you know, this is opening the space for more, for example, for Perplexity and so on to take over some of the market that, um, Apple phones have. Yeah, I think that the Apple part, when they put out Apple intelligence and they hear, like, they got a lot of backlash about that as well. So maybe they are field testing it way, way more before coming into production. I don't know if you know about this, but that Apple, uh, came up with the Apple Kids Watch. Because again, they're as it is like the point that you made, Kaoutar, they're known as the company which respects privacy and has it integrated in all aspects and they've come them coming up with the kids watch kind of showcases their, um, commitment towards it. So I feel they are looking into several avenues before coming out with something. Public yeah, and I still think I think weirdly the kind of hardware mentality actually might be working against them a little bit in implementing some of these features because sort of unlike you know building a phone which you can really kind of like I feel like part of the problem with these models is they still You know, unreliable and kind of probabilistic. And, you know, I think like in some ways the discipline of like launching features is a little bit more risk loving than that Apple might be used to. And I think it's actually holding them back in the market. Yeah, but I ain't giving up my iPhone for anything, Tim. So I'm okay with that. Yeah, that's right. I mean, I think the counter argument as well. Uh, they can just keep trying because everybody's on their phone and they're not going to throw it away. So they can just keep going until they get it. Um, but something to keep an eye on. Um, we'll definitely be keeping an eye on this Perplexity project and, um, a lot more to come there. Um, so, uh, that's all the time we have for today. Uh, Vyoma, Kaoutar, Chris, uh, thanks for joining us as always. Um, and, uh, thanks for joining us, all you listeners. If you enjoyed what you heard, you can get us on Apple Podcasts, Spotify, and podcast platforms everywhere. And we will see you next week on Mixture of Experts.