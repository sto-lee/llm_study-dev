{
  "video_url": "https://www.youtube.com/watch?v=iSJenVM7KnQ",
  "video_id": "iSJenVM7KnQ",
  "title": "NEO 1X Robot, OpenAI chips, The AI Scientist, and the future of prompt engineering",
  "upload_date": "20240906",
  "channel": "IBM Technology",
  "duration": "38:11",
  "caption": "Tim Hwang: My opinion is that prompt\nengineering is never going to die. It's a forever thing. Kate Soule: Anyone who's worked with large\nlanguage models has experienced some of the pain, dark art, black magic of... if I shout loudly enough at my\nmodel, maybe like literally if I type in all caps, maybe this time\nit will do what I'm asking it to do. Tim Hwang: The creepy factor is big,\nbut these robots are also pretty cool if you can get them to work. Kaoutar El Maghraoui: I would\nlove to have one actually in my home, cleaning dishes and cooking. Tim Hwang: How many scientists\nare going to be out of a job in the next 10 to 15 years. Shobhit Varshney: I'm just looking forward\nto a world where we start using the word \"we\" when AI is actually starting\nto do something meaningful for us. Tim Hwang: All that and more on\ntoday's episode of Mixture of Experts. I'm Tim Huang and I'm joined today\nas I am every Friday by a world class panel of engineers, researchers,\nproduct leaders, and more to hash out the week's news in AI. On the panel today, Kate Soule is\na Program Director of Generative AI Research, Shobit Varshney, a Senior\nPartner Consulting on AI for U. S., Canada, and Latin America, and Kaoutar El\nMaghraoui, Principal Research Scientist, AI Engineering and AI Hardware Center. So as always on Mixture of Experts, we're\ngoing to start with a round the horn question, and that question is, will\nprompt engineers even exist in five years? Kate, yes or no? Kate Soule: No, Tim Hwang: Shobhit, yes or no? Shobhit Varshney: Not at all, man. Tim Hwang: Uh, okay, alright,\nand how about you, Koutar? Kaoutar El Maghraoui: I think it's\ngonna evolve to a different role. Tim Hwang: Okay, alright,\nwell let's get right into it. The prompt for this first story that we\nwant to cover today is that we've just had kind of a slew of sort of subplot,\nyou know, sub B kind of announcements coming out from all the companies. They haven't been the most kind\nof prominent things they've been announcing, but it has really kind\nof created a little bit of a pattern. I think, Kate, you flagged this for us. Which is that a lot of the\ncompanies have all been working on prompt automation, right? So Anthropic announced a\nMeta Prompt system that helps generate prompts for you. Cohere is launching a prompt tuning\nfeature, which takes a prompt that you have and improves it automatically. And then Google recently acquired a\ncompany called Prompt Poet, which is very much in the same functionality. Um, and so this is a big deal, right? If you're familiar with LLMs in\nthe past, right, a lot of the work has gone into making a good prompt. Um, and, uh, I think the big thing about\nthis is the future of basically taking the human out of the loop, the idea\nthat you won't need prompting anymore. Um, and I guess, Kate, as someone who\nkind of threw this topic to us, do you want to just explain for our listeners,\nlike why, why is that important? Right, like why, what\nchanges when that happens? Kate Soule: Yeah. Uh, and I, I like what you did\nthere, Tim, the prompt for today. Uh, so look, I think anyone who's\nworked with large language models has experienced some of the... pain, dark art, black magic of... if I shout loudly enough\nat my model, maybe... like literally if I type in all\ncaps, maybe this time it will do what I'm asking it to do, right? Uh, which can be a really frustrating\nprocess and doesn't make like, logical sense, like I think we're all rational\nbeings and ideally there would be a really rational and structured\nway to try and prompt these models. So I'm really excited to see a lot of\nwork come out, which is trying to... not take a human entirely out of\nthe loop, but take a human out of the loop of finding these phrases\nand tokens and words and patterns... that seemed to be more effective\nfor one given model, uh, to perform a task that's in question. So, you know, being able to, for example,\nsearch a broader space of natural language and try and identify, okay, if\nI frame my question this way, um, now I can get an improved level of accuracy. I think that is going to be really\npowerful, um, overall just to improve productivity and, and reduce some of\nthe stress when working with models. Tim Hwang: Yeah, for sure. And now Kaoutar, you said actually in\nyour response Is you, you, you agreed with everybody that kind of, well, maybe\nprompt engineering is kind of not long for this world, but you, you did say\nthat you feel like the role will shift. Um, do you want to tell us a little bit\nmore about what you're thinking there? Kaoutar El Maghraoui: Yeah, sure. So there has been a lot of recent\ndevelopments in prompt engineering that is leading to significant\nchanges, particularly in how prompt engineers interact with large\nlanguage models like Kate mentioned. Things, for example, the\nmeta prompt prompting from anthropic, uh, meta prompting. And the development here, it shifts\nthe focus of the prompt engineers from crafting these individual prompts\nto designing systems that guide the AI to adjust its own behavior. So prompt engineers may\nincreasingly hear focus on creating frameworks for meta prompting... or refining the logic that underpins it. And this creates a more robust\nUh, role where engineers manage how prompts evolve in real time. And if you look, for example, at\nwhat, uh, prompt tuning from coheres, for example, the prompt tuner. So here, the, the prompt tuner from\nCohere enables user to fine tune and optimize prompts specifically\nfor different applications. And, you know, here, the implications\nprompt engineers may transition from manually crafting prompts to overseeing\nor curating automated tuning systems. So this kind of democratizes the prompt\ncreation, and this could reduce the some of these technical barriers to entry,\npushing prompt engineers to focus more on more complex or high impact tasks... where deep expertise is still\nrequired, such as, you know, designing industry specific\nmodels or optimizations of scales. So, and there is also other, like,\nalso if you look at the Prompt points, uh, Poet acquisition by Google. So here, you know, this\nacquisition emphasizes automation here in the generation and\nthe optimization of prompts. And the implication here, this kind\nof further blurs the line between AI systems and prompt engineers. So, AI systems here, like, Prompt Poet\nevolve as they evolve, the role of the engineer here may shift from towards\nmore supervising role, uh, so where you're supervising these AI systems\nthat continuously optimize themselves. So human prompt engineers might focus\nmore on edge cases or creative tasks or model specific customizations. So I think the implications overall\nhere is kind of shifting from manual to kind of a supervisory role. I don't like to say that, you know, we're\ngoing to completely remove human out of the loop here, but more increased focus\non optimizations, expansions of the skill sets here for the prompt engineers. They will need a broader set of\nskills, including model training, data set curation, the integration\nof the LLMs into broader AI pipelines and also some niche specializations. So I think to sum up is kind of the\nprompt engineering is likely likely evolving from hands on manual role\ninto a more, you know, supervisory role where engineers focus on\nhigher level design optimization and supervision of these automated systems. Tim Hwang: Yeah, that\nmakes a lot of sense. And it's sort of interesting that kind\nof like the process that's happening in the movement to like AI agents... will also sort of happen in the the\nprompt space right which is rather than kind of like, you know doing everything\nyou're just sort of like monitoring the system as it goes and keeping it together. Shobhit Varshney: Yes, I think\nthe prompts will get more and more personalized to that particular person. And over time, there will be a lot more\ncontext that will automatically pull in. So the center of gravity is going to keep\nmoving towards more hyper personalization to show it as an individual. Uh, so the way the prompt, when I say\nsomething to a model, the way it expands it out and makes a meta prompt out of\nit, that'll be super hyper personalized to the context, the memory of everything\nthat I've done in the past, right? Uh, like I, I feel like\nbeing a good prompter... to these LLMs at work has made\nme a much better parent... talking to my eight year old daughter. Uh, she just Tim Hwang: Explain it clearly think\nthrough it step by step, you know. Shobhit Varshney: Yes, I have to\ntalk to my daughter saying that Anya, you are, uh, you just turned nine. You are a big girl now, and then\nI walk her to a chair and start reasoning and I get the answer I'm\nexpecting her to say that no, I should not have ice cream before I sleep Tim Hwang: Got it, right? Exactly. That's the desired outcome. Shobhit Varshney: Absolutely,\nand there's a lot, and that's a two way feedback training, right? And now we're at a point\nwhere, say it's, um, it's 8 p. m. at night, and if I say, Anya,\nher response is going to be, \"Papa, I'm almost done eating.\" Because she understands that there's\na pattern that when she's eating and she's taking more, more time, I'm going\nto probably be checking in and seeing if she's eating properly or not, right? So she has a lot more context on how\nto respond to Shobhit itself, right? But if my wife is us calling\nher, her name, her response is going to be slightly different. So I think the hyper personalization of\nthese meta prompts, that's a direction that we will be looking at going forward. Tim Hwang: Yeah, for sure. And I guess, Kate, maybe to turn it to\nyou before we move to the next topic, I think this exact point was one thing\nthat I did want to bring up is, you know, when we think about prompting with\nhumans, we encode in language, right? What's sort of interesting is that,\nyou know, the prompting that we've done is both to kind of, like, help us\nunderstand how we're interfacing with the system, and then also direct the system. I think... I don't know if you buy this which\nis like, many of the optimizations may use tokens that don't even look\nlike, you know, normal grammar, right? Like it could just be like a random string\nof numbers and letters that actually get the best results out of the system. And so I got some kind of curious\nlike do you feel like prompts over time will become like more and\nmore kind of obscure to us, right? Because it turns out like the\noptimal encoding for the language model may actually not be something\nthat's particularly human readable or easily understandable at all. And so there's almost this very\ninteresting trade off of like optimization and readability. Just wanted to kind of\nget your thoughts on that. Kate Soule: Yeah, well, I think to answer\nthat question, it's important to recognize that there's really kind of two different\nsides of innovation that are happening on, uh, happening around this area. So one is improving our ability to\nprompt the models, but the other is improving the model's ability to take\nstructured and more reasonable action. prompt. So, you know, instead of talking to a\nshow of its eight year old daughter, like, can I talk to a software developer that\nunderstands, you know, structured inputs and can provide very structured responses? So if we only innovated on the prompt\noptimization side, where we're trying to create new tokens and, you know, keep\nthe model frozen, then yes, I think we could get to a point where we're starting\nto see a non human readable prompts. But I think we're also seeing like\nwith OpenAI structured outputs, like more and more structure being\nbaked into these models to make it more standardized and systematic\nand how we work with these models. And ultimately, you know, I think\nthat's where the real value would get unlocked and where a lot of,\num, really exciting workflows could develop, especially in agentic patterns. If we can really start to focus more on\nhaving very structured, formulaic, maybe not perfectly machine read, uh, human\nreadable and that it's not, you know, it's not like storytelling when I read what the\nmodel is happening, but a very formulaic way to work with these models, I think is,\nis ultimately where we're going to end up. Tim Hwang: Yeah, it'll be so funny\nbecause what you're describing is we're reconverging towards like code, right? Like structured language as\na way of getting systems to do what they want them to do. Kate Soule: Yeah, we started structured,\ncreated a bunch of unstructured, and now we're like, wait, that was\nactually, there was some good things there that we should maybe bring back. Tim Hwang: So I'm going to\nmove us on to our next topic. Um, uh, we spend a lot of time on Mixture\nof Experts talking about software, we talk a lot about enterprise, but\nI think one of the most kind of, uh, interesting things viral, if you will,\nAI moments of the last few weeks was the launch of a humanoid robot called NEO\nfrom a company called 1X Technologies. Um, and specifically they're working on\nthe ideas to work on humanoid robots that are designed to be at home assistance. So, you know, this demo, basically if\nyou've seen it and if you haven't, it's worth kind of looking up on YouTube\nor whatever, um, is a humanoid robot helping out around the home, right? Cleaning dishes, helping to clean up and\notherwise kind of assist on, on tasks. Um, and. You know, again, I kind of wanted to\nkind of ask the question, and I think it's always an important question to\nask in the world of AI, which is how much of this is going to be a reality? How much of this is\nlike a really cool demo? Um, and maybe most importantly,\nwould you buy one for your own home? But we can address that\nat a certain point. Um, Kaoutar, I'm kind of curious\nabout your thoughts, if you saw the demo, what you thought about it. And, uh, you know, if you, if you\nthink something like this is really going to be a reality, and I think in\npart, right, I think the question is like, whether or not this is like, a\nreal affordable thing from a hardware standpoint, there's like a bunch of\nreally kind of very practical, you know, bits and atoms kind of questions here\nthat I would love to get your take on. Kaoutar El Maghraoui: I would love\nto have one actually in my home, cleaning dishes and cooking, someone\nwho spends like an hour, one of the tasks I hate the most, of course,\nthe demo was very impressive from 1X. And I think 1X is among the, one of\nthe most prominent companies in the emerging field of humanoid robots. But will humanoid robots become\na reality or still a pipe dream? So I think, you know, humanoid\nrobots have been the focus of science fiction for a long time. And transitioning from dream to reality\ncomes with significant challenges. So the argument for humanoid robots\nis that they can fit into environments designed for humans, use existing tools\nand interact more naturally with people. However, I think there are still several\nchallenges that need to be fixed. You know, first, I think there is\nthe mobility aspect, building a robot with these human level dexterity or\nmobility has proven very difficult. Uh, while there are some\nprogress, I think there is still a lot that needs to be done. Technologies like soft robotics and\nadvanced actuators are making strides here but are far from a robot that can\nperform all human tasks autonomously. The other, you know, challenge\nis the energy efficiency. I think these robots require significant\npower to function and which limits, you know, their practical use. NEO, for example, and other similar\nprojects are working to make these robots more energy efficient, but the\nissues around battery life, energy consumption, there's still bottlenecks. Uh, the other, the other thing is\nthe cognitive and social interactions here beyond just the physical tasks. You know, these robots must navigate. Um, the complexities of all the human\nlife, interactions, perceptions, and developing an AI capable, uh,\nrobot of, that's, that is capable of interpreting these social cues, responding\nappropriately, making decisions in real time, is still an ongoing research area. There, there is still a lot of\nwork around AI and reasoning. So I think it's going to take\ntime for us to get there. And another challenge, I think,\nis the economics of this. Building something that is\naffordable and, uh, and versatile, reliable, it's still a major hurdle. And for many industrial and service\napplications, simpler robots or specialized machines are more efficient\nand cost effective than having this general, uh, purpose humanoid robot. So the complexity and the costs of these\nhumanoid robots, I think, uh, especially in their design, still limits, uh, the\nadoption to especially niche markets. So I think there are, you know,\nchallenges, you know, what's the reality versus the long term vision? You know, at present, uh,\nit is a transitional phase. Existing prototypes, they are far from\nubiquitous, but there are really nice demos and it shows a lot of promise. But I think we are still not there\nin terms of the mass market tools and, and adoption and, um, there,\nthere, but in it's not just, you know, a technological pipe dream. I think, um, it's gonna happen. That's my, my thinking. But it's, you know, for the full\nrealization, it's gonna take years, if not maybe decades away before\nthey really become a reality. Tim Hwang: Yeah, that functionality gap\nis very interesting to think about, like, I love the idea that for a period of\ntime people are purchasing these, but it turns out there's like not a whole lot\nyou can do around the home with them, so that they end up just like being like all\nthe lonely Pelotons you see in people's houses, or it's like this really expensive\npiece of hardware that just kind of sits around, but it's, it's just funny because\nit's like a humanoid guy, basically, um. I guess, uh, I don't know, Kate, Shobhit,\nif you've got a kind of view on this, if you're a little bit more skeptical\nor if you kind of agree that like, yeah, maybe, I don't know, Kaoutar,\nyou didn't put a date on it, but like in our lifetime, you know, we'll see\nthis become like a practical reality. Shobhit Varshney: Yeah. So, um, I'm a big geek and I will,\nI will go and buy stuff that I think is, is, is awesome, right. So I'm Tim Hwang: You're going to have the\nPeloton, uh, NEO robot in your house. Shobhit Varshney: So, um, I feel that the\nsame argument about one massive model. That's just absolutely stunning,\ncan do everything like a GPT 4.0 model or cloud models, right? Versus the argument that a smaller\nset of models and a niche for specific use cases, a lot more efficient and a\ntarget for a particular use case, right? I'm on the camp of, I\nwould rather have a device. That is helping me for a\nparticular task and it's incredibly doing a good job at that task. As an example, uh, I use the Roborock\nS8 MaxV Ultra, whatever the highest end of their robot that does vacuuming and\nmopping and goes back and cleans itself up and dries itself up, comes back again\nand finishes off that last little bit of scrubbing that it missed somewhere. More specialized tools helping us\naugment what humans aren't good at... I think that's the future\ndirection in the short run. It'll take a while for us to\nget to something that solves for all the constraints that we just\ndiscussed before you get to a point where a humanoid replica of you\ncan actually start doing things. So I think in the short next five\nyears, specialized tools that do a particular task incredibly well,\nare cost optimized, it's repetitive, they nail that particular use case. I'm more, I'm more in that camp. Kate, do you think the same? Kate Soule: I completely agree. If you think about how model\nspecialization has progressed, uh, you know, we see the same\nexact trends as you pulled out. So, I'm 100 percent in the same camp. It also reminds me of, you know, the\ncommon, you know, story that you hear of where if you asked someone back in\nthe horse and buggy, days what they wanted, and they always said they wanted\na faster horse, and then, you know, Ford came along and released the first cars. And I think we're in a bit of that\nscenario right now where it's like, I just want more human time to do the\nthings that I don't want to do as a human. So create some humanoid robot, but really\nlike, can we rethink of like what the right way this is to make, um, humans more\nsuperpowered, not just create more humans that we don't have to worry about feeding\nthem or other potential, uh, labor issues. Shobhit Varshney: Okay, that sounds\nmore like, say, uh, how we solve the dishwasher paradigm, right? Kate Soule: Yeah. Shobhit Varshney: We figured out\nthat there's an optimal way of washing dishes and it does an\nincredibly good job at a very low price point and it nails it, right? So we have changed the way human\nworkflow used to work, right? Earlier, as a human, I would take a dish,\nrinse it, and keep it somewhere else. We did not try to optimize\nthat particular workflow. We said there's a better way of\nsolving this particular niche use case. It's very custom optimized,\nand we'll nail it. So, I'm on that camp with you that I\nthink we'll get to a point where smaller machines that do a particular task\nreally well will I don't want, like, for example, in our pool, we have,\nuh, we have a skimmer that just skims and removes all the dirt from the top. Now, a human will take a net and try to\nclean up each one of them one by one. That's not the optimal way\nof solving for that problem. So I'm with you that the workflow,\nthe human workflow has got to change. And then we optimize. By the time we get to a point where\nwe get a humanoid that can then solve for all the problems that we\ndiscussed around cost and flexibility, dexterity, and things of that nature. Tim Hwang: Yeah, and I think you,\nfor what it's worth, I think also just, like, you can't discount,\nlike, the creep factor, right? Like, I do feel like it's, like,\na little bit, it's a little bit spooky to have, like, a, you\nknow, a large human in my house. Um, and, uh, and I do think that\nwill be part of the adoption, almost, like, leans in favor of these more\nspecialized applications, because they kind of don't raise that fear. Uh, I don't know. We'll have to see in practice whether\nor not X1 is able to pull this off, or 1X, sorry, is able to pull this off. Kaoutar El Maghraoui: Yeah, I think\nit's interesting development, you know, and it's all it's all comes to\nto what people are also able to consume and the capabilities, of course,\nspecialization versus generalization is always going to be a concern. But of course, if we can combine\nboth, that, that would be great. Um, so it's like what these LLMs are\ndoing, but we still need special models. But, you know, the evolution\nof LLMs is still important. Having these large models that can\ndo a variety of things, but then specializing them for certain tasks. Can we have the same argument for these,\nuh, humanized robots that, you know, can do a variety of tasks, but maybe you can\npress a button and tell it, now I want you just to be focused on cleaning the\ndishwasher or the pool, or so something that's maybe take a subset of that model\nthat is specialized within that humanized. I think that would be cool to have. Tim Hwang: Yeah, I mean, ultimately,\nyou're going to have like, you know, the humanoid robots going to be\nthe one that does the maintenance for all the other smaller robots. It's just going to be\nrobots all the way down. Kaoutar El Maghraoui: It's\nlike a hierarchy over here. Tim Hwang: Yeah, exactly. Shobhit Varshney: I think what\nKaoutar, I mean, this Kaoutar, just the way you framed, I think you're\nlooking at a Transformer robot.... Kaoutar El Maghraoui: Exactly. Something... Shobhit Varshney: ...a vacuum\ncleaner so it can do that one job really, really well. That'll be the world we live in. Kaoutar El Maghraoui: That would be cool. Yeah. Tim Hwang: Um, so I'm gonna\nmove us onto our next topic. Um, so there's a fascinating paper that\nwas shared by a friend of the pod Kush Varshney, who, uh, if you're a listener,\nhas been a recurring guest on this show. Um, and what I love about some of\nthese papers in machine learning is that they like pick the most\ndramatic name for their paper. And so the name of the\npaper is The AI Scientist. It has a long title about kind of\ntowards, you know, effectively like using AI to automate end to end science. Um, and it's a proposed system that\ntries to really see and kind of push the limits of whether or not\nlarge language models can really help out with scientific discovery\nin a fully kind of automated way. And this is a big deal. I mean, you know, you think about how\nyou know, societal progress happens, right, like these technological\nbreakthroughs are really critical. And so, you know, one way of thinking\nabout it is that we've got this kind of bottleneck for the researchers,\nthe brilliant minds that we have. And so, you know, the hope is\nbasically, can we augment that process? Can we accelerate that process with\nAI has been kind of a real focus. Um, you know, what I always worry\nabout these papers is that the results look almost too good and\nlike the ambition is too great. Um, but I mean, Kaoutar, I know you\nlooked at this paper in some detail. I'm curious if you're coming away with\nthis feeling like, yeah, they really kind of hit upon something here that,\nthat really could be the kernel of something, um, new, or if you feel\nlike, you know, you know, ultimately like the way AI fits in science is\ngoing to look a little bit different from the way they're proposing here. Kaoutar El Maghraoui: Yeah, I,\nI enjoyed reading the paper. I think it's really, um, Uh, put\nforward a very nice way of, you know, kind of thinking of this automated AI\nscientist, which made me also worry, you know, what's going to happen\nto the scientists in the future? Um, so, so it presents, you know,\nthis very nice framework where large language models generate research\nideas, write code, run experiments, visualize results, and even write papers. So, and they also showed some very\ninteresting papers that were, uh, you know, generated by this AI scientist. Uh, one thing that... Tim Hwang: Yeah, I just needed to do the,\nuh, the paper session at the conference, uh, the poster session at the conference. Kaoutar El Maghraoui: Makes you even\nworry, you know, what's going to happen to the conferences in the future and\nsome of the papers, are they really generated by real scientists, or\nthis is all, you know, LLM generated? Um, so these advancements could\nsignificantly impact scientific discovery, reducing the cost and also\nincreasing the speed of research. So there, there could be some benefits\nto this, especially if you look at it as an augmentation for human, uh, research. The, the thing is the controversy\nsurrounding this paper is largely, you know, coming from the methodological\nconcerns that they have using. And especially when you look at,\nuh, you know, the, the reliance on automated review systems. to evaluate the scientific quality. And that kind of raised\nsome concerns to me. Uh, you know, the questions\nhere, whether, you know, such reviews can truly assess novelty,\ncreativity, and rigor of the work. Uh, and also I think one thing that's\nskeptical is whether the AI could really fully replace a human intuition\nin scientific discovery, especially when you're dealing with more abstract,\nuh, or interdisciplinary fields. So this, I think AI is\nstill not there yet. when you're really looking across\nmultiple fields and, you know, kind of mimicking that human intuition. And I think another thing, uh, is also the\nbroader ethical and social implications for automating scientific research. So there are a lot of concerns here, but\nI think from a scientific perspective, it's a very nice piece of work. Um, And but has a lot of implications, of\ncourse, ethical and and also the automated review the process that they have. So... Tim Hwang: That's right. Yeah, I'm curious. Kate, I mean, as a researcher yourself,\nhow do you how do you feel about all this? You know, I feel like it's like we're\nvery interesting, for example, seeing like engineers be like, well, They're\nnever going to learn to code as good as I am, so I know there's kind of\nlike a tendency to kind of push back on it, but I'm curious about how you\nthink about these types of experiments. Are they like fun toys? Like, would you use these? Like, would you read the\npapers produced by these AIs? Kate Soule: Yeah, well, I'm honored\nyou call me a researcher, but I certainly work with a lot of amazing\nresearchers here at IBM Research, even if I'm not one directly. But, you know, I, I actually question\nwhether, as a non-researcher, this might be a naive opinion, whether there isn't\nsomething that, uh, LLMs can do well in terms of understanding what's been done in\nthe past with related literature on a much broader scale than what's humanly possible\nto go through and analyze and read and try and find similar methods or approaches\nto apply to a new problem that's related. Um, I don't know if Kaoutar you\nhave any, any thoughts on that, if that's a, maybe a jump too far. Kaoutar El Maghraoui: No, I think I agree. You have a point there. So there might be stuff that they're\ndiscovering that scientists are not able to discover because they're\npulling from a wide variety of sources. Uh, but I think we still need human\nin the loop here to validate, verify, uh, you know, these experiments and\nthen take them to the real world and try them and see the results. So we cannot just take the results out\nfrom, you know, these LLMs and then just apply them directly to, so there,\nI think there still needs to be some verification as probably these systems\nwill get better and better as, you know, we use them more for scientific discovery. Tim Hwang: Yeah, I think one of the\ninteresting things here is that, uh, you know, some of the people I know\nwho research this space think a little bit about like the burden of knowledge,\nwhich is like, there's just like more and more knowledge and more and more papers. And, you know, part of the hope\nwith some of these systems is simply that, like, there's a lot of\nfindings that could exist purely in. Like finding connections between\npapers that just people are not making the connection between. And so that ends up kind of reducing it\nmore to like a search problem, right? I think what's kind of interesting\nhere is the idea that like, then you want them to run the experiment. Then you want the AI to\ndo the empirical stuff. You know, I think there's a question\nabout how far kind of beyond just the question of search you need to go. Shobhit Varshney: Yes. I think just like any workflow from an\nenterprise perspective, we help a lot of, uh, people clients with their R&D\nresearch and things of that nature, right? Coming up with a new formulation for a,\nfor a new food item or a perfume or like product research for the next, uh, car,\nyou know, so on and so forth, right? Battery research, whatnot. So across all of them, just like any\nother workflow in an organization, you figure out that here are\nall the steps that are needed. When you are hiring somebody brilliant\nfrom MIT to come join your team as an intern, you're giving them a specific task\nto augment what a senior researcher in the field for a decade has been doing, right? So, Kaoutar, you will plan out\nsaying that, hey, here's a task that I'm going to go give you, go\nresearch this particular topic. I think we'll start to incrementally see\nmore and more AI helping out on specific tasks in the research spectrum end to end. I don't think, just like any other\nworkflow, I don't think it'll completely be taken over by AI. I think it's. augmenting intelligence\nrather than being replacing. So I think that the good tandem between\nhumans and and AI will also start getting better at what to request for help. So for example, you want to just\nmention a knowledge graph across a whole bunch of different research papers to\nfigure out if somebody overseas in a different country had some novel idea\nthat you just didn't think about, right? So I think we'll get to a point\nwhere this research, what I'm really interested in, is a conference that\nwe get to where each one of us would have our representatives as AI going\nand talking to each other, right? Just imagine if you have a collaboration\nbetween a team of researchers with their AI counterparts in, uh,\nin Israel, talking to the same, like, their counterparts in the U. S. and they're exchanging ideas and\nyou come up with a new theorem and say, hey, I think we came up with\nthis new idea that we should do X. I'm just looking forward to a world where\nwe start using the word \"we\" when AI is actually starting to do something for us. Tim Hwang: Well, and like one of the\nbig dramas in academia, of course, is like, who's the first author? Like I wonder if in the future\nit'll be like, you'll get into this big struggle with some LLM\ncollaborator that you have is trying to take all the credit from you now. And, you know, we'll have that drama play\nout, but it would just be funny because it'll be, you know, humans and AIs. Kaoutar El Maghraoui: So I think\nit'll be competition between models who's writing the best paper and\nwho's, uh, AI conference completely generated by AI and reviewed by AI. Tim Hwang: That's right. Yeah, exactly. Angry that you're unjustly\nturned down for your paper. Reviewer number two, you know. Shobhit Varshney: I would say\nthat there are certain things that we don't think about quite yet\nin the whole research spectrum. When you, we are so focused on doing\nour, our actual novel research, when it comes to say peer reviews. I'll give you an example of what we're\ndoing with some of our utility companies. Utilities, when they have to go file\nfor increasing the price of their electricity in a particular state,\nthey have to go file for a case. And they have to make a case and\nsay, here's why I think I should increase it by X cents, right? Five cents. We're helping these utilities create\nthat whole submission package. So we're looking at everything that\nthey have submitted all competition. It's all openly available online. So you research and help create\nthe first package itself. Then once you know who's going to\nbe on the panel, who's going to be assessing it, we can then go look at\nevery question that they've ever asked. So in this case, in a peer review,\nwe know when Shobhit gets to be the reviewer, I typically ask more about\nethical concerns about a particular paper and so on and so forth, right? Each one of us has a pattern\non how we ask questions, right? So now we reverse engineer what the\njudges would ask on the panel and then we change the documentation\nso that the submission itself is going to address those proactively. Then when you actually go and have\nto present your case in person, that's an interview that's happening. So then we are preparing the witness\nbased on the kind of questions that the person has asked everywhere\nelse and what's the right. chain of thought to go on to that. So I think there are aspects of\nresearch that researchers don't want to do that I think AI will\nbe really helpful in augmenting. Do you think that'll be helpful, Kaoutar? Kaoutar El Maghraoui:\nI think so, definitely. Yeah, of course, as humans we're limited\nand if we're augmented by, you know, AI, we're, we're going to be superhumans and,\nuh, hopefully in the right direction. So... Kate Soule: Well, and I think it gets back\nto what we were just talking about, right? Like, are we going to have AI,\nlike literally try and become its own researcher and just\nreplicate what a human can do? Or are we going to have AI specialize\nin parts of the process and run that process faster and better and support\nhumans and new, more efficient workflows? It's just, you know, now without the\nrobots focused on scientific method. Tim Hwang: The news story of the\nweek was that it was finally kind of rumored a new story kind of came out\nthat OpenAI is going to be investing in trying to produce its own in\nhouse chips to support its work. And part of this is it's. You know, integration and collaboration\nwith Apple, but more generally, you know, there's been something\nthey've been rumored about for some time that now looks like it's now\nmore in the realm of certainty that they really are kind of investing\nthis in a really, really big way. Um, you know, Kaoutar, you're the most\nnatural person to ask about this, but like, why would OpenAI want to do this? Like semiconductors are like wildly\nexpensive, very hard to pull off. You know, my understanding is basically\nlike, you know, China, the whole country has been trying to like reproduce\nthe Taiwanese semiconductor industry. And like, is only\nmoderately successful at it. Like, why should, why is OpenAI kind\nof making such a big bet on hardware? Kaoutar El Maghraoui: I think, um,\nthe CEO of OpenAI, Sam Altman, has made the acquisition of more AI\nchips a top priority of his company. And he publicly even said, he\ncomplained actually about the scarcity of, uh, of these AI chips. So given, I think, all the rising\ncosts, uh, chip costs, the supply chain challenges, and the need\nfor specialized hardware, uh, especially specialized hardware\nthat's optimized for OpenAI models. It seems to me that this\nis a strategic move. So designing their own chips could enable\nOpenAI to tailor hardware for their specific workloads, improving performance,\nefficiency, and scaling potential. However, of course, there are challenges\nhere and financial challenges given the complexity, especially of the\nsemiconductor design and manufacturing. Um, so by creating this in house chips,\nOpenAI can reduce its reliance on third party manufacturers like NVIDIA,\nwhich control a significant portion of the AI hardware market, almost 80%. So it's going to give them more control\nover the supply chains and allow them to specialize and optimize for their unique\nworkloads, potentially improving their efficiency, performance, and scalability. While semiconductor development is\na challenging and costly endeavor, I think this move could enable OpenAI\nto differentiate its hardware and scale, its operations effectively. I think they've thought a lot\nabout this, but I think it's a strategic move for them. But also to diversify. Tim Hwang: Totally. I mean, as wild as what you're saying\nis basically like, you know, what's cheaper than trying to get H 100s? It's like literally building your\nown semiconductor supply chain, which is a really crazy thing to say. Um, I guess, uh, I don't know,\nKate, Shobhit, but if you've got kind of thoughts on this, I mean,\none big question is like, do we think it's going to be successful? Like I can almost see the argument\nfor it, but man, if it isn't a high risk sort of thing, right? Kate Soule: I mean, certainly high risk. I really want to emphasize one point\nthat Kaoutar brought up, which is there's tremendous opportunities. We look at kind of this next generation\nof AI and what's going to come next on AI and hardware co design. So making sure that we're developing\nthese models and the hardware that runs them in tandem to really\nunlock kind of new performance levels, new efficiencies and cost. Um, there's, there's\ntremendous opportunity there. So, you know, I think it makes sense. It makes a lot of sense to start to\nput some skin in the game, so to speak, um, given that, you know, there's\njust a ton of ways that they could continue to innovate, um, once they have\nbetter control over hardware design. Tim Hwang: Yeah, for sure. And Shobhit, I guess maybe you're kind\nof ideal to wrap up this section and close this out for the episode is, you\nknow, you think a little bit about how, what this all means for business, right? What this all means for enterprise. Like, can you paint a picture\na little bit more, right? Because I think the semiconductor\nstuff is often very abstract. But as Kate is saying, there's some\nvery practical implications to, you know, our experience of these kinds\nof technologies in the systems. But like, I'm kind of curious, like, what\ndoes the everyday look like if OpenAI is really successful here, you think? Shobhit Varshney: NVIDIA\nis a great partner with us. We do a lot of work, uh, we have\njoint clients and whatnot, right? So we do a significant amount of work. Yesterday, I spent the\nentire day with NVIDIA. We're doing a lot of work around\nwhere, where they can go and work with enterprises beyond\nthe hyperscalers themselves. So they got into quite a bit of\ndetail, uh, behind the covers, explaining us the intellectual property\nthey've built, the differentiation. They have a significant moat today. Not just on the chip level but\nthe way you do the architect the entire end to end flow. The total cost of ownership--\nyou're going down from a massive data center down to one box. Just the wiring in the existing\ndata centers is more expensive than that one box from NVIDIA. So the total cost of ownership and\nJensen made this uh this famous statement saying even if they're competitors\nwho are the customers as well, even if they made free chips, the total\ncost would still be lower on NVIDIA. So they've done an incredibly\ngood job on driving higher efficiencies, more throughput, 5x,\n10x on the same kind of footprint. So I think it'll take a while\nfor a company like OpenAI to do everything that's around it. It'll take them a while, just like when\nTesla came to market, it took them a while to figure out how to actually\nproductionalize this end to end. Creating a car, the actual, the\ncore of it, that piece was great. The researchers could solve for that. But the whole manufacturing and the\nsupply chain and the total cost, how do you get a car to actually be a\n$30,000 car that people want to buy? It'll take a while for\nOpenAI to get there. And I think there's that, in my view, is\ngoing to distract them a little bit... from their core business. They should, in my view, should be\nfocusing more on how do we get to adding more intelligence, what Ilya\njust did with SSI, raising a billion dollars, uh, what Claude, uh, models\nare doing with more responsible AI and stuff, I think there's still a lot more\nfocus that's needed on solving that side of the problem for enterprises. The cost will come down over time,\njust the way the economics work, the cost of computing on NVIDIA\nhas implemented in the last decade. So I think that the focus of OpenAI\nshould still be problems that need to resolve before they start to go\nvertically integrating end to end. Tim Hwang: Yeah, it'll\nbe fascinating to see. And as I said, I think this\nwill not be the last time that we talk about this issue. So, I'm not overly sad that we ran\nout of time today about it, but we will pick it up in the future. Um, uh, So that's what\nwe have time for today. So Shobhit, Kate, Kaoutar, thanks\nfor joining us on the show. Um, and for all you listeners out\nthere, if you enjoyed what you heard, uh, as always, you can get mixture of\nexperts on Apple Podcasts, Spotify, and podcast platforms everywhere. And we'll see you next week."
}