{
  "video_url": "https://www.youtube.com/watch?v=TsDdk7xHhMY",
  "video_id": "TsDdk7xHhMY",
  "title": "NVIDIA GTC, Baidu reasoning models and Gemini AI image generation",
  "upload_date": "20250321",
  "channel": "IBM Technology",
  "duration": "39:12",
  "caption": "What's the announcement you're\nmost excited about from NVIDIA GTC? Vyoma Gajjar is an AI Technical Solutions Architect. Vyoma, welcome back to the show. Uh, what did you think? Thank you. And I feel the Groot N1 model,\nthe generalist model that they're calling it for humanoid robotics\nwas something that I really enjoyed.\nKaoutar El Maghraoui is a principal Research Scientist and\nManager at the AI hardware center. Uh, Kaoutar, welcome back to the show. Uh, what did you see from\nthe keynote that you liked? Thank you. Great to be here. I was also very excited about the\nrobotics and simulation, uh, announcement, especially the Newton Physics Engine\nfor real time physics simulation and how, you know, it's, uh, working with the AI. Nathalie Baracaldo is a Senior Research Scientist and Master Inventor. Uh, Nathalie, welcome back to the show. We haven't seen you for a while. Um, and, uh, what did you like from GTC? I was super excited with their framework\nto generate synthetic data for robots. Uh, because that has been a key, key\nfactor for reducing the performance of robots in all sorts of, uh, applications. So super excited about that. I guess we're all into robots here. Absolutely. All that and more on\ntoday's Mixture of Experts. I'm Tim Hwang and welcome to Mixture of Experts. Each week, MOE brings together\nthe best minds in artificial intelligence to walk you through\nthe biggest headlines of the week. As always, there's a lot to cover. We're going to talk about\nBaidu's new models that they've dropped, a paper about the flaws of Chain-of-Thought of Thought reasoning, and Gemini 2.0 Flash Experimental. But first, I really want\nto cover NVIDIA GTC. GTC is NVIDIA's sort of big\nConference that they do every year. It's where the big drops happen. Uh, you know, Jensen, Huang gets to walk out on stage and, and do\nall the exciting keynotes. Um, sounds like this group really\nwants to talk about robots and specifically Groot N1 which is a foundation model for robots\nthat NVIDIA announced during the keynote, uh, Vyoma maybe I'll start with you. What got you so excited\nabout this announcement? Um, one of the things that I saw is like a model such as Groot N1 created by NVIDIA, which is trained on both\nthe synthetic and the real data and, uh, the NVIDIA, NVIDIA were during that\nkeynote, they were claiming that it features like a dual system architecture. So it's thinking fast and slow, which\nis kind of inspired by that human cognitive processes that we see. So I feel we are going to get, these\nare the small, small ways in which people are trying to get towards AGI. Like, let's get a little bit\ncloser, let's get a little bit closer, however far it seems. So I feel that was a good, um,\ncatch that they were trying to do in that, uh, part, yeah. Yeah, absolutely. And I know, Nathalie, in your response, you kind of flagged this\nkind of synthetic data part being the thing that got you the most excited. Um, you know, I know that's been a\nlittle bit of a blocker, but it would be good for our listeners to kind of\nunderstand how big of a blocker it has been sort of traditionally if you\nwant to talk a little bit to that. Yes, definitely. So one of the big issues that we have is\nthat when you are trying to simulate a robot to test it before it goes into the\nreal environment, we have limited data and traditionally what has happened is\nthat when you simulate, which is less expensive, you don't have the exact kind\nof a spectrum of different types of, uh, of scenarios where the robot might move. And as a result, when you move your\nmachine learning, uh, programming into the actual robot, it fails. And, uh, there are like, uh, these\nvery nice, uh, videos of how it fails. So if you have a humanoid, it may just\nfall on their face and it's just crazy. So that's why, uh, a lot of, uh, the\ndifferent, uh, robots at companies and, and actual factories, they have\na very restricted set of environments. Do you see them going down an app, for\nexample, if it's an arm and so forth. And it's just because it's very, very\ncomplex to create a robot that can move in an environment that may not be\nexactly the wine it was designed for. So just moving a little bit, uh,\nuh, a millimeter or something the robot may not behave as properly. And having this. type of synthetic generation of\ndata allow us to basically create a huge environment where we can test\nthis and make the whole development cycle much faster and much safer. So another aspect to it is that\nbecause these robots, as they evolve more, they move around. You may have situations where\nyou have unknown safety. things happening. And that is super interesting to me\nbecause understanding how we can make all those environments really safe and try to\nsimulate things that go wrong before the, the, uh, robot actually gets deployed. Uh, I think it's just fascinating. It opens a lot of different, uh,\nnew, uh, opportunities to create safe robots and safe applications\nand deploy them in real life. So I am super excited when I, when\nthey said also they open source it. I, I was very, very excited to hear that. Yeah. The additional kind of open\nsource element, I think is like a really interesting part of this. Cause they've clearly created like\nsomething that's like a big deal from model standpoint, but they're\njust saying, actually we're, we're here to sell hardware, right? So we actually have like ways of,\nuh, the, the business incentives lean towards things like open source. Um, Kaoutar, you spend your days thinking. All about all things hardware,\num, how big of a deal is this? And why is NVIDIA getting into robots? You know, like I, I think about\nNVIDIA, like they started as like a, a gaming GPU company. Um, and then, you know, like the next\ntime we really thought about them, it was like, oh man, we're going to do these\nbig data centers for language models. And that kind of sounds like a lot of this\nkeynote was robots, robots, robots, right? We're going to show you videos of robots. We're going to bring a\nrobot onto the stage. Um, Why is, why is NVIDIA kind of\ninvesting in this, this vertical? I think it's, it's high time\nright now to invest in this, and this is very attractive. I think all the ingredients\nright now are coming together. You know, the, the models, the\nhardware, the simulations, the synthetic data generations all are\ncoming together, which makes these robots really perform very well. So I think the collaboration\nthat they have with. DeepMind and Disney, uh, you know, I\nalso was interested in seeing Disney also play a role here and especially\nif they're going to bring, you know, that maybe, um, uh, the fun, the\nentertainment piece of it, uh, you know, their Disney characters or, you know,\nkind of play that into these robots. That's going to be really interesting. Uh, so one thing also that was\nvery interesting is this physics engine that they talked about,\nwhich is designed for these robotic simulation. Nathalie mentioned this and another thing it's also\nbuilt on their wrap framework, which provides a lot of acceleration. So it provides, you know, this\nhigh fidelity and real time analytics simulations, which\nwas not, you know, kind of. possible or realistic before. And this is very crucial for training\nand testing these robotic systems in virtual environments before\neven deploying them in real world. So I think that is a very big\nstep forward to enable these humanized robots to perform well. and with high fidelity. So, uh, combining basically the simulation\nand the, the AI acceleration using their, this RAP based acceleration\nframework that they have with high performance parallel programming, it\nhelps them achieve, you know, fast and efficient GPU accelerated simulations. So they're kind of combining the AI\nworld with the physical physics based simulations to provide, you know,\nthis, uh, interesting, uh, outcome. And they also have these integrations\nwith their existing frameworks like the, uh, the S Hack lab, the,\nwith their reinforcement learning. And I think they also have a\nplayground, uh, that uses deep minds robotics research, a lot of, you know,\nintegration with existing frameworks. And, uh, so that's really makes, uh,\nthis high precision robotic control possible and paving the, this, um,\nyou know, kind of a great environment that is ideal for simulating tasks\nsuch as, you know, manipulation, grasping, multimodality, et cetera. Yeah.\nAnd I guess a follow up question for you there, Kaoutar, is, um, you know, in the last few episodes, I feel\nlike every few episodes we do a segment where it's like, oh, but you know, open\nAI is we're about to work on its own ship or, you know, Amazon might be catching up. You know, there's lots of\npeople who kind of want to like. You know, capture some of NVIDIA's\nmarket, but you know, I kind of look at all of this robotics work they're\ndoing and also just the announcements about like Blackwell Dynamo, right,\nit's just like the performance metrics are just like insane. Um, I guess from your opinion,\nkind of as someone who thinks about this a lot and watches the\nindustry, like, can anyone catch up? Like, it kind of just feels like\nafter this keynote, it's like, feels like very hard for anyone to really\ncredibly claim that they're going to kind of like, do things kind of on\npar with NVIDIA, particularly because they have this ecosystem, but curious\nabout how you think about that. Yeah, I agree with you. I think it is, they're kind\nof creating this big gap. Uh, and they're also lining\nup the right collaborators. like DeepMind and Disney and others. So it's going to be hard to catch up,\nbut I wouldn't be surprised if somebody comes with some contributions, like either from OpenAI or I think we'll have to see, although I agree with\nyou, it's really difficult to catch up. Um, I want to look. talk a little bit about some\nof the other announcements that were done at the keynote. And, you know, Nathalie, in particular, I kind of thought of you. So, you know, a few episodes ago, we\ntalked a little bit about the project they announced, uh, I think at one of the last\nkeynotes called Digits, which was this like, candidly, like quite cute little\nsupercomputer that they were selling, uh, that would be sort of like a desktop. Um, and, um, I'm kind of curious as\nlike someone who's a researcher, you know, if like that kind of form factor\nfor doing work is interesting to you. Um, I just think a little bit about,\nI have a friend at a company being like, our product's getting really\nsuccessful, but that means we're burning all of our compute on like inference. We have no time to do any like\ntraining or fine tuning work anymore. Um, and there's been kind of this\nlike tension of like, oh, well. All of the compute resources\nfor an organization kind of come out of the same bucket. Um, and I guess I'm kind of curious,\nlike, does something like DGX Spark, which is what it's called now, like, is that,\nis that something that's interesting? I don't know if you put your name in to\nkind of reserve one of these devices, but I'm curious about how you think about it. I would pass that question to Kaoutar actually. I am not sure how to answer that. Yeah, I think definitely, you know,\nuh, it's gonna open up the doors for many, uh, researchers and enthusiasts\nand people who are interested in learning about, you know, all of these\ndifferent cycles in the AI journey. So, of course, there is a lot of focus\non the inferencing and inference scaling, uh, because You know, I think the need\nfor that stemmed from the fact that it's very hard to get access to these GPUs. So we had to come up and be creative\nabout, you know, what can we do with the resources that we have available. But I feel like there is a lot that\ncan be done even, you know, in the pre training and the fine tuning stages. It's just because only a few people or\nfew organizations are really limited because of this, uh, the, the resource\nconstraints that we have right now. So I would love to have access, you\nknow, to AI in a box that I can use in my, in my home and experiment with\nall these different things and then. push the boundaries even further\nand I'm sure many others would have that appetite as well. Yeah, I think it's just kind of\nlike a cool, I mean, I guess I'm a little bit of a device nerd. I was just like, oh, it's just\nlike amazing that you can have that much computing power just\nlike on your desktop right now. And yeah, I think it's like very, very exciting. Um, Vyoma, any thoughts on DGX Spark? I don't know if you like\nhad seen that announcement. Yeah. If you think it's more of a gimmick or\nit's like the kind of thing you'd actually be interested in playing around with. I, I, I feel, uh, the reason why\nthey came up with this also is to target the developer community. That the developers sitting\nat home or even want to try something as a side project. Because that's how\ninnovation kind of flows. Someone's side project, if I\nhave the compute to do it, I, it opens my creativity, mind\ndoors, if you may call that. So it, it helps you, um, experiment. Train like let's even if you want to find\nyou in a small little thing and move on so feel fast kind of works query very\nwell on this and I feel that will be the reason why people want to adapt more that. Okay, I have this. I can leverage this. Learn about it. Try seeing if this works or not. Let's move on. So no longer are you going to see big\ncompanies or big institutions spending a lot of time and energy on like\ninnovation projects because someone somewhere would have tried it and be\nlike, Hey, guys, it's not gonna work. Let's move on. So I feel that a quick turnaround\nis something that is the angle that NVIDIA is trying to play here as well. If I might add here, I think,\nof course, you know, all the points that Vyoma said are, are great. So this is kind of bringing AI\nsupercomputing to the desktop, trying also to democratize AI. And, but I think there is also this\nangle of the robotics, the humanized AI training at scale, which I think that\nwas also one of their motivation, is, uh, basically, pushing these humanized\nrobotics forward with models like the Groot and why DGX here, uh, matters. It allows, you know, developers\nto fine tune and deploy these robotics models locally. So, uh, using, you know, their\nNewton Physics Engine, and it allows also this enabling sim-\nsimulation to real time training. So you need, you know, these\ncapabilities locally to be able to, to advance these things. And I think it would be\nalso great for students. that are learning AI, they need to\nlearn all these concepts and the best way to learn is to experiment\nand have these hands on experiences. So, uh, students right now are struggling\nto get access to to GPUs and resources. Yeah, it'll be really cool if there's\nlike kind of a big schools or education kind of market for these types of devices. I just think about when like the You\nknow, the Macintosh or like the kind of the first iMac laptops came out. Um, it was like a huge thing, like\nApple had a huge market selling to schools because everybody wanted\nto give computers to their kids. Um, and, uh, and it was like a great way\nto kind of break into people learning how to, you know, like use these devices. So I'm gonna move us on\nto our, uh, next topic. Um, Baidu, uh, announced, uh, this week\nthat they were launching two new models. One's called ERNIE X one, and\nthe other one is ERNIE 4.5. Um, and x1 is supposed to be the, their DeepSeek competitor. Um, and of course Baidu is\nlike a longstanding, you know, Chinese tech company. Really one of the leaders in the space. You know, I think in many ways, kind of\nlike one of the people that you would've expected to kind of really dominate. uh, in AI. Um, and almost like a lot of other\nplayers in the space, like OpenAI, you know, it's like they too are now\nkind of struggling with all of these new competitors coming up, right? Like, um, you know, what's interesting about ERNIE x1 and ERNIE 4.5 is they're both closed sourced models. Um, and so I guess maybe as a first\ncut, like curious about you know, how folks think a little bit about sort of\nopen source here, and I guess why we think Baidu is still trying to pursue\nlike a closed source, uh, strategy. Um, you know, I'm kind of curious if you\nhave any thoughts on like why they're still playing this game and if, you know,\nyou really think ultimately they're going to have to open source just like, uh, just\nlike many others are thinking about now. Yeah. Um, I feel Baidu is the kind of\ncompany which was, which stemmed, its origin stemmed from the point\nthat they wanted to create a search engine for China and they wanted to\nkeep majority of that data private, a lot of data privacy, um, inhibitions\nthat they were going through as well. So I've. feel this is like their chance to kind\nof utilize some of the information, the knowledge graph, if you might\nsay, that they have created between their different AI applications\nlike Baidu AI for like search or like Baidu AI for maps, et cetera. So they are trying to come up with\nlike a platform interface with that one particular model, which\nkind of creates synergy across. So I think A1 that is that. I always believe that yes, sooner or\nlater they are going to realize that. The open source market would be some sort\nof a better way to take this forward. Like how Sam Altman after a couple\nof years had to say it in a AMA on Reddit that, Hey, I think maybe\nwe're on the other side of history. He's\ngetting kind of like dragged into it. Exactly. I don't think he wanted to say it. It's just that it just came out, right? So I feel that as well, but, but\nlooking at Baidu's, um, Um, like core structure, they were always like very\nprivacy, um, integrated systems or something that they believed in building. So I get where their mind is right\nnow, but I think sooner or later they are going to have to move. And the pricing that they've\nkept, it's almost like half of what EveSec or the others are. So that is another, there,\nthere another point that, see guys, everyone's gonna use us. We are like half as expensive. So they have like an. up in the market as is. So they're like, maybe we're gonna\nleverage this as much as we can till we can, and then we'll see when we get there. Yeah, the competitive dynamics are really interesting.\nNathalie, I kind of take a look at the situation and, you\nknow, Veeam is a good reminder, right? Like this is like, Baidu is\nlike the, the kind of Google of its, of its market, right? The kind of search engine of its market. And I guess I kind of look at that\nand I say, well, you know, the kind of reputation has been that\nlike Google has been kind of slow. to capture the opportunity from AI. And I say, oh, it's okay. It's very interesting that in\nChina also, like, the search engine company is the one that's been\nkind of like slow to capture this. Um, I don't know. Should we read into anything in that? Do you think that there's like something\nabout search businesses or search companies or, you know, dominant kind\nof, you know, these types of search companies that are like maybe more\nlimited in using or benefiting from AI? Yeah, I think that's an interesting\nquestion because the way I see it is that probably they don't need to\nopen source in the sense that they already have a big user, uh, base. So, uh, people are already\ntrusting them with so many things. So potentially from the\nstrategy perspective, open sourcing, uh, would not be. a key priority as it\nis for other companies. Um, the other aspect that every time I\nthink about open source models versus having a more closed source model, from\nthe security standpoint of view, when you have an open source model, you are\ntelling people, Hey, just go inspect it. We try our best. Tell us how, how would you think\nwe did, and that it's offering a lot of transparency, and I think\nit improves how we move forward. Now, when other companies keep their\nmodels, uh, behind the scenes, and you're just basically not telling how it works\nexactly, they may be, uh, planning, for example, to orchestrate different\ntypes of components in the backend. And, uh, I think, uh, we'll see just\nlike, uh, as we see with OpenAI, We are not fully sure how many\nmodels they have behind the scene. We, we know we have guardrails\nand a lot of things. So I think, um, not fully open\nsourcing in because they already have such a big base for search,\nthen they probably are thinking it's, uh, it's okay to go that way. But as you know, I'm a security\nperson and I like transparency. Uh, it makes it easier to\ntest the system and so forth. So, so yeah, that's, uh, my take on. Open source versus non open\nsource and what they are doing. Yeah, for sure.\nUh, Kaoutar, are you on team Vyoma? Like, do you feel like they're, this\nclosed source strategy is doomed? You know, we're going to see Baidu\nhave to open source in the future. Uh, or do you think there's\nkind of like maybe different things going on in that market? Yeah, I, I think I, I kind of agree with Nathalie, but I see that they've already started making a\nstep forward, uh, towards open source. And they, I think they've\nannounced that they're planning to open source sometimes in June. Uh, their, uh, their new models. And I, this just shows that they\nare also competing with open AI and deep seeks and especially seeing\nall the, um, you know, all the bus that DeepSeek created. Uh, so open sourcing AI models like DeepSeek they've gained traction. And Baidu is likely sees this as a way to\nincrease also adoption of its own models. And so also a way to gain market share,\nattract developers, build an ecosystem around its models, because if you keep\nthese things closed, you're missing in terms of this open ecosystem and\ndevelopers and getting also the community to help and especially the adoption. I think the adoption is kind of goes hand\nin hand with the open source, especially. Uh, so that is very important. Uh, so driving this widespread adoption,\nuh, more developers, more use cases, widespread adoption, faster improvements\nthrough also these external contributions. Those are all win win strategies\nwhen you use open source. And I think Baidu is getting it, and\nit's moving also towards that direction. And this is just, you know, it\njust intensifies the competition in China, but also globally. So, so it's interesting\nto see these dynamics. So the next thing I think I want to talk\na little bit about is I like to always have like a paper that we can discuss. I'm a little bit kind of\nold fashioned in that sense. We talk a lot about industry news, but I\nthink it's just fun seeing what's going on in the world of research and kind of\ninteresting papers from week to week. And this paper caught my eye. So the title of the paper is Chain-of-Thought Reasoning in the Wild is Not Always Faithful. Um, and so, for those of\nyou who are kind of not super aware. Chain-of-Thought and kind of reasoning models and exactly\nhow this is looking right now. Right now we have these kind of like Chain-of-Thought reasoning traces, um, where, you know, a model\nwill kind of think through a problem, uh, to greater or lesser degree before\nit kind of like renders an answer. And, um, You know, overall, right, like\nwe've sort of discovered this method is really, really good in terms of getting\nthe model to perform better and better. But there's this kind of increasing sort\nof series of papers, this is not the only one, that kind of are investigating\nthe problem of what happens when the model gives you erroneous reasoning for\nthe decision that it's trying to make. And when is basically sort of these\nreasoning traces not actually a faithful way of understanding how models make decisions. Um, and Nathalie, you talk, you think a lot about security, um,\nand I think this, this kind of paper really raises a bunch of security\nissues in the sense of like maybe we are giving people the wrong\nimpression of how AIs actually think by giving them Chain-of-Thought traces. Is that the right way of kind of thinking\nabout this paper and I guess kind of the problems of Chain-of-Thought in general? Yeah, I think that that's a\nvery interesting question. Uh, I'd rather have Chain-of-Thought so that I can know at least a little bit\nhow the model came to an answer. What the paper shows is\na lot of biases that may happen in that Chain-of-Thought itself. So, And I think the reason it is really\ninteresting is because the particular bias that they are demonstrating in the paper\nis a bias that it's also in us humans. So, for example, if I ask you, Tim, a\nquestion, is X larger than Y, depending on the way I phrase the question, a\nlot of people would answer one way. versus another. So that's this cognitive bias that\nwe know for sure and cognitive psychologists have for so long a study. Now where that that paper in\nparticular shows that that same bias exists in this model. And I thought that was interesting. And there's like the parallel\nin the cognitive psychology for humans versus that paper. And I think that's just why people are\nlike, oh my gosh, this is so interesting. Uh, if you study farther this\ntype of situation, what you'll see is that the models also exhibit\na lot of other types of biases. Now, uh, in particular for fairness,\nfor example, there are some papers like in 01, uh, there was a very\ninteresting section that I read, uh, about how the Chain-of-Thought itself may be biased. pretty hateful, for example, or may tell\nyou stuff that you as a user don't want to necessarily uh, see or exposed to, to\ncertain, uh, uh, for certain use cases. So, uh, overall, I thought it\nwas really interesting paper. Uh, the caveat, and because I am a\nresearcher at heart, is that they only had one data set and their temperature was 0. 7, uh, which I thought was, interesting. So that goes into a lot of detail about the\npaper, but I would like to see like more, more expansion on this\nwork because it's fascinating. It's\nfascinating. Yeah,\nabsolutely. Um, Vyoma did you agree? I think, uh, I'm curious if you\nsaw things that you were sort of interested in the paper. I mean, you know, from that, I\nthink it's kind of interesting is like on the temperature point, it's\nlike, I don't know, how much should we believe these results, right? Like, it actually maybe turns\nout that, by and large, reasoning traces are really useful as a\nway of kind of like understanding how the model's making decisions. And maybe we shouldn't be so scared? I don't know. What do you think about that? Yeah, I do agree with Nathalie on that point that when it's at the temperatures point,\nyou're actually telling it to be a little bit more creative in its thinking as is. And now you're using that as a base of\nsaying that CoT is not here to stay. It's gone. I feel it is here to stay because it kind\nof tells you what it's going through. And the other part is the people, like\nall these companies which have come up with these models, the reasoning\nmodels, now they are looking into how to make the Chain-of-Thought processes better. So I feel you can, like right now\nwe see a lot of pattern matching than having something which is like\na more generalized way in which you can understand the deep reasoning. But going further. What about a reverse CoT? Like whatever a CoT has given\nyou in the information, go back and evaluate it again. Tell\nme if that Chain-of-Thought was right or not. So there can be innovative\nways in which researchers, etc. will go on, uh, answering. I feel it is your to say and it should. So I'll just give you a short example. I moved and I'm looking for\na sofa in my, uh, apartment. And what I was looking is, I said, I want anand style sofa with a table. And then it just started\ngiving me aand table. But I knew that because I read it in that\nentire reasoning that, oh, now it's just going and spinning on that table thing. I don't want that. Then I went and said, I want a side table. And then again it went and told\nme that no, it's the table. So, so, so I'm trying to tell you that I\nunderstood that I have to be so specific. I want an adjustable low level. site table and so that is, I wouldn't\nhave done any of that had it just spun and I would have been okay it's going to\ngive me a japanese style sofa someday. So I feel those are ways in which\nit tells you to improve your prompt, tells you that this is not, right now Chain-of-Thought is also based a little bit on your prompt. It doesn't tell you the exact model\ninternal workings, but I feel it will. Evolve with time. It should evolve with time, and it will. I mean, people are working on it, so. Yeah, I think that's one of\nthe most interesting things. I never really thought\nabout it that way, but kind of the Chain-of-Thought's useful for letting you know when the reasoning is\ndefinitely off, even though it may not necessarily be a good guide for like when\nit got it right, how it got it right. But it's like, it's kind of a debugging\ntool more than anything else, which I think is like a really fun way of thinking about it. Um, Kaoutar I think I would love to get you\nto comment on, uh, one comment that Nathalie had, which is it's very funny that these models\nhave kind of inherited all of these cognitive biases, uh, that humans\nhave, um, which is very funny. I mean, computers didn't used to\nhave those types of biases, but I guess we live in a world now\nwhere, you know, that's the case. Um, yeah, just like, I don't know,\nsomeone who kind of like thinks about sort of like hardware, which I always\nkind of envision as a much more kind of like structured, you know, thing. It feels like we've kind of like, they're,\nthey're, these computers are now kind of like, you know, executing systems\nthat have like all of these weird kind of like soft emotional aspects to them. And it's just like, I don't know, I'm\ncurious to hear your reflection on that. It's like a very funny kind of\ncontrast to what we thought about computers doing 10 years ago. Computers used to be exact, you know,\nzeros and ones, and we expect them to be kind of the, the opposite of biased. And, uh, but right now, because they're\nlearning with AI, it's learning from the data and this data is generated by, by us. So it has inherited all of our biases\nand the way these models are learning. I think it's only natural\nto see, you know, these. these outcomes that we have to figure\nout systematic ways to solve in them. So Vyoma, I think, mentioned some of them. So, of course, you know, this isn't valent as Chain-of-Thought uh, is unable to generalize and it also\naccumulates all these errors. The longer, the longer the Chain-of-Thought of reasoning is, which, you know, leads\nthis faulty logic despite, you know, these correct answers. But, you know, as Vyoma mentioned, I think there are potential solutions,\nand I also agree that this is something here to stay, especially the\ninterpretability aspect of it is so important that I think we need only\nto amplify the importance of this. So we definitely need things\nlike self correction modules. Uh, Claude, for example, has this\nconstitutional AI, which is a reflection based approach that\nhelps to self correct the model. There's also things like structured step\nverification, these hybrid models where neuro symbolic reasoning, like the tree\nof thoughts, for example, can also be used to help correct, you know, the logic. Uh, you know, also combining\nthings like statistical logical AI with probabilistic reasoning. with logical constraints, all of\nthese techniques, I think, need to be brought into the table. So to figure out how do we combine\nneural symbolic AI approaches to improve the reasoning aspects of\nthese LLMs and having also this self verification in the reasoning and\nself correcting, which I think, you know, will keep CoT useful, uh, and\nreduce the flawlessness in these tools. So I think these hybrid reasoning\nframeworks will be necessary to improve the reliability and\nthe reasoning of these models. Yeah, we'll definitely see that,\nI think, and it is kind of a funny outcome that like we created this like Chain-of-Thought thing, which at times can be very emotional. You\nread the Chain-of-Thought and like I read one that was like, Oh. You know, I'm trying to do\nthe best I can at my job. Okay, let's try to research this task. And then you're kind of trying to\nlike make it more computer, uh, again. Um, it makes me think a little\nbit about like people will say, Oh, he's like a computer. And like, I think like maybe 20 years\nago, that would mean that the person is like very rigid and very logical. It's almost kind of, I think a\nlittle bit about like, maybe, you know, kids growing up today will\nbe like, Oh, he's like a computer. And by that they mean, you know,\nreally irrational and emotional and, you know, it'd be very funny\nif it kind of like flips what we mean, uh, when we say, Oh, like. This person is like a computer or\nthey're thinking like a computer. Imagine, imagine that NotebookLM with CoT. So let's say you see the Chain-of-Thought of thought and like in your NotebookLM you can posit that.\nNo, don't go there. Don't think like this, change this. And then that can be used\nas a training data set. I feel it's going to open new avenues for\nthe prompt engineering aspect as well. People will learn how to make prompt\nengineering more robust, scalable. more precise with time. And I think this also could\nhelp with the customizations. The way you interact with the model\nmight be very different from, you know, how Tim interacted or how Nathalie\ninteracts with, with the model. So that, you know, I think localizations,\ncustomizations might also be interesting. So you can also inject\ncultural cues and preferences. So, Tim, I think it's going to even be\nmore Biases that we're introducing to this world while we're trying to make it different. It's going to be, I think, both. This hybrid world. on our kind of segment on Baidu, which\nis again, like, kind of the narrative that's been in the market or at least\non Twitter, right, is basically that, you know, Google's coming from behind. They should have captured, you know,\nthe AI revolution and they kind of missed it and now they're catching up. But it's kind of like week to week. It feels like Google's like\nreally catching up now. Like, there's just all of these launches,\nwhich are like quite impressive. Um, and, uh, uh, Google\nrecently announced. Um, and this is like almost\nkind of a joke in AI now. Like, they launched a model called Gemini 2.0 Flash Experimental, um, which is basically a model that\nthey had in beta for a small group of people, but it is now widely available. And it's an image gen model,\num, that people can play with. So this by itself maybe wouldn't be\nkind of super impressive, though the model itself is pretty fun to play with. Um, but I wanted to kind of use it as an\nopportunity to talk a little bit about one particular aspect of the launch,\num, which is that Google is touting that one of the reasons why its model, you know, its 2.0 Flash model experimental is so good, is that\nit incorporates what they call world knowledge, uh, to make\nthe image generation better. And, you know, like many phrases in\nAI, you're like, well, okay, world knowledge, what does that even mean? Um, and I guess maybe I'll start with\nyou, like, What is world knowledge anyways, uh, and why is it, why is\nit important, I think, to like AI generation, uh, particularly in images? Correct, um, so that's a good\npoint that you said that I, that first I want to answer this thing\nthat is Google really catching up? So that, that point that we made. Yeah, the hot take. I mean it's just vibes, I don't have any industry stats, so\nfeel free to knock me down there. No, I get it, I get it. I've been asked this like many\ntimes now, like outside speaking sessions as well, because catching\nup is like very subjective. I get it. My, my question here is, is the real\nquestion is, are these models going to surpass or like at least match\nthe creativity of these already established model like Midjourney,\nDall-e, etc, which are there, right? So maybe they've arrived at the table,\ndinner table date, but maybe they got like Really good big products, which\nnone of these people already had. And the other question that you're\nsaying that what is this world knowledge? So I feel the world knowledge in this\nis that they're talking about is deeply integrated with their entire Google's\nknowledge graph that they have with access to all the real world data that we have. So instead of just learning from the\nimage that we have, image pictures of etc. They are also learning from the\ntext, the structured text as well. Imagine all the Google searches that\nwe've done, all the pictures that I've posted about my sofa that, you know, this\nis not what I want, this is what I want. So that has been kind of added into\nthat historically consistent world knowledge that Google already has. And I think it's extremely important\nto have any to kind of create a model which is much more accurate in answering\nthe questions that users might have. Yeah, and I think, I don't know,\nI see this as almost like Google using or trying to use its like\nadvantages in the space, right? It says lots of people can train\nimage generation models, but we've got, we've got the knowledge, right? And so like we have to put that to use. I would trust them. Like if, even though I've been using many\nof these other models available, I'm going to use them now because I know for a fact\nthat they might have much more domain specific accurate data that I might need. Yeah, for sure. Um, Kaoutar, am I just operating on vibes? Is, uh, is Google catching up? Or is this just kind of\nlike, ah, table stakes? They're just like able to generate\na model which is as good pretty much as everybody else now. I think it's table stakes. So I don't think it's a catch up\ngame series, they've been working on it, so it's just the time for them. It's ready for the release. Yeah, right. Um, Nathalie, you were laughing, I guess maybe you agree, or? I, I think at some point, uh, last\nyear I was so surprised and so excited every time I saw an announcement. Now it's like every week\nsomething is happening. And yeah, so I, I think that the\nspace has started to be like people are catching up and it's kind of\nbecoming a commodity sort of situation. Uh, that said, I still get impressed\nby the fact that right now we can say like change my tulips for flowers. that are wild and be very\nfocused on a part of an image. I think that was not the case a few months\nback, and that still makes me happy. So from that perspective, I love\nseeing more and more models coming out. I think not only Google, but many other\nplayers are going to continue improving the models and the capabilities and\nthe ways we describe and get to go get some beautiful pictures out of it. Um, so yeah. Yeah, for sure. Yeah, I feel like it's, uh, it's\nreally hard to be in the AI business because you're like, you're, you're\ndoing like magical things that have never been done with computers before. And then people like six months\nlater are like, ah, what else do you, what else you got? You know, it's like, it's very, very\nhard, I think, to like keep ahead. Cause I, I agree with you. I mean, there's almost like\nannouncement fatigue, you know, it's just like, what is. What is the next big thing? Well, I don't know. It just feels like there's big\nannouncements, like every week. And so all of it kind of\nlike blends in together. Yeah, I think the key question\nhere, are they catching up or are they really innovating? So, uh, I think that's\nwhat we need to focus on. So of course you can catch up. You can see what others are doing\nand try to close those gaps, mimic, you know, or try because a lot of\nthe stuff, the algorithms, you know, a lot of them is published, but\nare you really bringing something new here to the table that nobody? else has thought about. So, I think maybe we should start\nseeing those more, uh, trends. Who's the real innovator here who's\njust playing the catch up game? Yeah, definitely. Kaoutar, I feel like you're, you're a harsh judge. Well, that's all the time\nthat we have for today. Thanks for joining us. Uh, Nathalie, Kaoutar, Vyoma, it's always a pleasure to have you on the show. And thanks to all the listeners out there. We're going to try\nsomething new this week. We're always interested in kind of\nhearing a little bit more about what you out there are interested in,\nuh, hearing about from week to week. So Spotify, please drop a comment. Let us know. We're going to be keeping\nan eye out on that. And we'll probably work\nthat into future episodes. So flag anything you've seen that\nyou want us to talk about And we're looking forward to hearing from you. Um, and as always, if you enjoyed what you\nheard, you can get us on Apple Podcasts, Spotify, and podcast platforms everywhere. And we will see you all next\nweek on Mixture of Experts."
}