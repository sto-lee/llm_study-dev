{
  "video_url": "https://www.youtube.com/watch?v=JCrvxWZEtSY",
  "video_id": "JCrvxWZEtSY",
  "title": "Quantum Error Mitigation and the Path to Useful Quantum Computing",
  "upload_date": "20230614",
  "channel": "IBM Technology",
  "duration": "10:49",
  "caption": "A new paper by IBM Quantum and UC Berkeley successfully demonstrates some of the largest quantum circuits ever run on a quantum computer. I'm Andrew Eddins, an IBM Quantum Researcher and coauthor on the paper. And in this video, we'll talk about what we did in this experiment, how we did it, and in particular why quantum error mitigation is poised to play such an important role in near-term quantum computing. So what did we run in this experiment? We used a 127 qubit processor to run a simulation of 127 interacting spins with each qubit playing the role of a spin. And to do this, we ran a quantum circuit with as many as 60 layers of two qubit CNOT gates. And remarkably, we were able to measure reliable results at the end of the circuit, which is exciting progress because it was only about a year ago that we started being able to run circuits with 100 qubits at all. And the number of gates in these 60 layers-- or the 60 layer depth of the circuit --is roughly double our previous record reported last year at IBM Quantum Summit in 2022. So even though today's quantum computers are not perfect, they have some noise in the hardware. We're still able to extract useful results-- or reliable results --using a class of techniques known as quantum error mitigation. And so this is giving us space to start exploring what we can do with these devices even before the era of fault tolerance and long term quantum computing. And in particular, in this experiment, we used a technique known as Zero Noise Extrapolation, or ZNE. So how does ZNE work? First we'll run our circuit and get some estimate of our observable. So we want to learn some observable property, O, and we want to look in particular at the average or expectation value of that property. We run our experiment and we get some results. However, this result may be made inaccurate by the presence of noise on the quantum hardware. Ideally, we'd like to get an estimate of what the answer would be-- if we ran this --if we solved this problem without any noise. So how do we correct for this inaccuracy brought about by the noise on the hardware? Well, first we'll go and learn what the noise is actually doing-- how it's behaving on the device. So we'll take the problem that we're studying, we'll break it up into layers, and then for each layer we'll further decompose that into two pieces: one that captures the ideal behavior of that layer and another representing the noise. And so by doing a bit of additional work, we can go and measure how all of these noise pieces in the circuit are behaving. And once we have that information, although it's hard to turn down the level of noise that's happening on the hardware, we are able to use that knowledge to turn it up. So by repeating the experiment in the condition where we increase the noise, we can then get additional results which we can use to extrapolate back and estimate the true value in the case of no noise on the hardware. So that's a bit about the basic theory underlying our experiment. And with that out of the way, I'll pass past things over to my colleague and coauthor to further explain details of the experiment. Thanks, Andrew. My name is Youngseok Kim, researcher from IBM Quantum. Like what Andrew said, I'm going to talk about a little bit more detail about what we did. So to make a long story short, what we did is we perform an experiment on spin dynamics of transverse field Ising model. So we perform experiment on our quantum processor, and we work with our collaborators at UC Berkeley and they produce corresponding results in classical computer, and we compare our results against each other to build a confidence in our method. So we use ZNE as our error mitigation method. We use our IBM Kyiv 127 qubit processor to study these spin dynamics. To be more specific, we map our spin lattice to our hardware topology, which is heavy hex topology. And this spin is governed by nearest neighbor interaction j and global transverse field h. And as you can see here, we have large parameter space to explore. Among this parameter space, we have some parameter that results in Clifford circuit, meaning we can efficiently simulate this circuit, thereby we obtain ideal value. So we utilize this nice property to examine our results. So here's the circuit-- 127 qubit, depth of 60 two-qubit gates. And since we know the exact solution, along the way, we check our results from quantum computer and that agrees well with each other. So there's one check. Of course they are large parameter space which results in non-Clifford circuit, which is in general hard to verify. Instead, what we did is, we take the parameter that results in the non-Clifford circuit equal shallower circuit, that's depth of 15, and we examine low weight observable. In this scenario, we realize that there's a light cone where all the qubits within this light cone really matters for this particular observable. And here's where our collaborator from UC Berkeley comes into play. They realize that using the qubits within this light cone, they can use brute force numerics to produce exact solution. So we compare the exact solution and our results from quantum hardware and compare against each other, we realize that they have a reasonable agreement. So here's one more check. So we are building this confidence. We go one step further. So this time taking the same circuit, we examine high weight observable, which eventually accrues more qubits within its light cone. This time our collaborators realize that brute force numerics are not feasible. Instead, they use numerical approximation method, specifically tensor network method. They realize that using this method, they still can obtain exact solution. So we compare their exact solution against our results from quantum computer and they again agree with each other reasonably well. So there's another check. So note that all the results of over here are verifiable circuit, meaning we have exact solution using classical resources. It's crucial step to do this work to build our confidence on our method. So as a next step, we would like to go a little bit farther, namely, we take the same circuit and we progress one more time step to make the circuit a little bit deeper, effectively. And we reexamine similarly high weight observable that eventually includes more number of qubits inside light cone. So in this scenario, our collaborator realized that it's no longer feasible to obtain the exact solution, even using numerical approximate method. So now we are comparing to approximate solution against our results obtained from our quantum machine. In that scenario, actually, what we ran is [the] following: so, again, revisiting the part of the space. There are results in Clifford circuit here. And we are actually tweaking our parameter that includes non-Clifford circuit as well Clifford circuit to verify our results by looking Clifford circuit. So in this scenario we looked at Clifford circuit results and there we see a reasonable agreement between ideal solution and results we get from quantum computer. But for numerical approximation solution from classical computer, we start to see some deviation from its ideal value. Of course, we don't have exact solution here, so any results from non-Clifford circuit represents [an] unverifiable circuit. So we did this, we did the same practice, very similar practice, but this time we go all the way to depth 60 and we look at low weight observable. Which eventually covers all the qubits within this light cone, and we observe very similar behavior that produces reasonable but unverifiable results. Looking ahead, we believe that some researchers will find a way to verify our currently unverifiable circuit. That's good because it means quantum is driving innovation to classical computing. Using their technique if they prove that our results are reasonable, that's again, good, because it means noisy quantum computer can produce reliable estimate on observable with interest. And of course as hardware innovation progresses, and our hardware gets better and better, we'll have further access to deeper and larger circuits. And we believe that this type of research eventually bring us one step closer to a day when a quantum computer can tackle a truly useful problem. I hope you like this video. Be sure to like and share this video. Thank you for your time."
}