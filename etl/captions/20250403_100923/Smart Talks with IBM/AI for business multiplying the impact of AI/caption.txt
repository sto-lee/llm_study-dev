Malcolm Gladwell: Hello, hello. Welcome to Smart 
Talks with IBM, a podcast from Pushkin Industries,   iHeartRadio and IBM. I’m Malcolm Gladwell.
This season, we’re continuing our conversation   with New Creators— visionaries who 
are creatively applying technology in   business to drive change—but with a focus 
on the transformative power of artificial   intelligence and what it means to leverage AI as 
a game- changing multiplier for your business.  Our guest today is Kareem Yusuf, 
senior vice president of product   management and growth for IBM software.
Kareem’s focus at IBM is on product strategy,   thinking about the roadmap for IBM software 
products to ensure they deliver effective   and compelling customer experiences. 
With the current boom in generative AI,   Kareem’s job is to help businesses figure out how 
they can apply artificial intelligence at scale,   to help solve big problems and boost 
creativity at new orders of magnitude.  In today’s episode, you’ll hear 
Kareem explain how AI powered by   foundation models can make AI adoption 
by enterprise businesses even easier,   how generative AI will change the way businesses 
process data and make decisions, and how these   considerations influenced the design of watsonx, 
IBM’s next-generation AI and data platform. Kareem spoke with Jacob Goldstein, host of the 
Pushkin podcast What’s Your Problem? A veteran   business journalist, Jacob has reported for the 
Wall Street Journal, the Miami Herald, and was a longtime host of the NPR program Planet Money.
Okay! Let’s get to the interview.  Jacob Goldstein: I'm Jacob Goldstein. 
I'm one of the hosts at Pushkin  and a correspondent on this 
show, and I'm delighted to   have you here. Can you introduce yourself?
Kareem Yusuf: Hi. I'm Kareem Yusef. I'm the   senior vice president of product management and 
growth for IBM software. You can think of me as   the chief product officer for IBM software. Jacob Goldstein: Okay. Sounds like a big job. We're here today to talk about AI. We've 
heard really an extraordinary amount in   the last few months about ChatGPT, uh, and, you 
know—particularly in how it's used in the very,   kind of, consumer-facing way. But I'm curious: 
what does the rise of ChatGPT and, you know,   AI more generally—what does it mean for business? Kareem Yusuf: Well, you know, if you kind of step back and think about what really happens, you know, in a business, you're really talking about   a set of processes, right? You know, activities 
that represent what a business needs to get done,   whether it's a product they produce and 
then sell or a service that they provide.  And inherent to operating the business, I would 
say, are two very key factors: data, and then the   decisions you make around that data. And then 
actually, lastly, the processes or activities   you do in accordance with that decision.
So if you then think about AI as applied   to business, right, in that context, 
well, the first place it often starts is,   “How do you make sense of a lot of the 
data associated with driving a business?” And so AI has always been, in my mind, at 
its foremost about gaining insights, then   leading to supporting decisions, and ultimately 
ending at helping to automate the activities that   then are executed as a result of those decisions.
So that's kind of my simple way of thinking of AI,   and we can obviously color in with examples, 
but that's my simplest way of thinking about   AI when you think about it in the business 
context. Gain insights from masses of data to   support decisions and then drive actions. Jacob Goldstein: That's a really helpful framework. And then if we think about sort of what's happening in the world now with, with,   you know, enterprise businesses 
and AI, what are you seeing with   enterprise adoption of AI at this moment?
Kareem Yusuf: So we're really talking about   almost a tale of two periods. So let me 
first of all kind of take you back—before   the advent of what I would call “generative 
AI” and the whole ChatGPT—to what has been   going on in what I would term the realm of 
more standardized machine-learning models.  A lot of what has been going on has been 
very much in the realms of certain things   like anomaly detection or optimization, right? 
Using machine-learning models to do that kind of   work. And where might it apply? Well, think 
of anomaly detection in security software,   right? Detecting threats based upon different 
events flowing through. Or in enterprise asset   management software, monitoring equipment and 
detecting anomalies within their behavior.  Or even in IT automation software: once again, 
detecting anomalies based upon what's going on   with various IT events and then tasks that should 
occur. Optimizations often play around in the   realm, as you might imagine, to solve problems of 
resource optimization, whether you think of that   in the context of application resource management 
for IT or in the context of supply chain. These have been very classical applications of, 
uh, machine-learning AI to really make sense of   the data and provide a basis to drive decisions.
Now, what—it's characterized by all those examples   I've given, and the state of the art of that 
kind of technology has always been—it's very   task specific. So there was an “air quote,” if 
I may, kind of “limitation,” in the sense that   the task—it had to be very task specific. And 
so we've seen a lot of broad-based adoption   within the enterprise, right? But it's very, 
very task specific, as you might imagine. Now,   what has happened recently and has been 
brought to the fore has been this discussion   of generative AI, which is powered by a very 
specific innovation: this notion of foundation   models. And in the simplest way to think 
about it, it is about training this large   model that can then be refined to various tasks.
And the easiest one that everybody recognizes at   the moment is the notion of a large language 
model—a model that has an understanding of a   lot of the elements of a language such that 
it can be refined to a variety of tasks:   write an essay, answer a question, sing a song, 
so on and so forth. I like to liken the power,   if you like—and this will speak to the, why 
everybody is so excited about it, why I would   argue it’s an inflection point—I like to liken it 
to teaching a child the alphabet. When you teach a   child an alphabet, it's a set of letters, right?
Let's call that our foundation model. But over   time, that knowledge of the alphabet is tuned to 
read a book, write an essay, do a composition,   create a song, write a poem, write an invoice. 
You understand what I mean, right? And so from   one foundation model, you can support multiple 
targeted tasks, as opposed—sticking with the   analogy—to having a model for reading, writing, 
doing a poem, doing an essay, so on and so forth.  And so in the enterprise context, that means 
that we're now talking about being able to   unlock even additional value at scale because 
of the nature of foundation models and their   appeal to generative use cases— “generative” 
in this case meaning “creation of new content.” Jacob Goldstein: So, let’s talk about watsonx. 
IBM recently announced watsonx. Just—first of all,   what is that? What is watsonx? Kareem Yusuf: Well, “watsonx” refers to our—is our brand for our platform, the watsonx platform, for really taking advantage   of generative AI within the enterprise, within 
business. And so when you begin to think about,   “What does that mean?” Well, it leads you to the 
components of watsonx and to a set of use cases.  So let me paint a few quick pictures for you 
here. watsonx, first of all, is about enabling our   customers to manipulate models against their task, 
manipulate these foundation models against their   task. Our belief is that the world is a multimodel 
world. Right? And especially when you think about   it in the context of business, models are going to 
come from various sources: the ones we supply; the   ones out there in open source and, sort of, view.
But there are activities you need to do around   these models to, as I said, apply them 
to your use case. And we'll talk about   use cases in a bit. So watsonx.ai is that 
environment that builds—a tool, if you like,   for being able to do those manipulation of 
models to meet your specific use case. Things   that people will recognize in the field: 
prompt engineering, prompt tuning, fine   tuning—those kind of activities, which are all 
the manipulation of models to meet your use case.  The second component is data. So watsonx.data 
is essentially a next- generation data store.   It's based upon something referred to as 
an “open-data lake-house architecture” that   helps to bring together the data that's needed to 
actually do the AI. In this case, when you think   about manipulating a model, a foundation model, 
you're generally using some data to prompt it,   tune it, train it to your use cases.
And so we provide a very open data store   that allows all manner of data and formats to 
be brought through to do that. And the third   component is watsonx.governance, and this 
is all about the framework and the toolkit   required to apply the right governance 
principles across doing this kind of work. Because when you're deploying AI within the 
enterprise, governance is actually important,   right? It's critical to understand: Where 
is your data coming from? What data did   you add in? How is your model performing? 
Are you able to keep an appropriate audit   trail of your activities for your own 
internal policy and compliance needs,   or for regulatory needs as well? Jacob Goldstein: So this platform, this system that you're describing— I'm curious: how is it different from the, you know,   the generative AI options that, you know, we've 
all been hearing about, sort of, in the press?  Kareem Yusuf: Well, I think it really comes 
down to the, the ethos or the principles that,   first of all, drive the work that we're doing. 
The first I would fixate on is being open,   right? We fundamentally believe that to do 
this kind of work within the enterprise,   you need an open platform that, as I said, is 
open to all manner of models from all sources.  It's one of the reasons why we announced 
our partnership with Hugging Face—to make   sure that our clients can gain access 
to open-source innovation within the   platform to do their work. So that's the— Jacob Goldstein: Hugging Face, to be clear, is sort of the open-source AI, kind of, hub. Kareem Yusuf: That's right, that's correct. Yes, it's a marketplace hub for all—kind of, “ecosystem coordinator” for open-source models. And I believe   there's a lot of innovation going on out there. 
So first of all, “open” becomes important. The   second: “targeted.” So our focus is very much 
on enabling these business use cases, right?  And you might say, “What kind of use cases 
are we talking about?” I'll give you three   very quick ones that, you know, that our 
customers are focused on. A lot of focus   around enhancing customer-service use cases. 
Think of this as chatbots or digital assistants   that are further trained in more and more 
information about what the company has to   offer—or could be internal policies, 
external policies, so on and so forth. This means a platform that makes it really 
easy to bring your own data to train and   tune the model while protecting your own data. 
That's extremely important for the enterprise,   right? Another important use case: seeing a 
lot of focus on what I would call “AI-based   orchestration” or automation of tasks, 
whereby—think about, like, an HR professional,   as an example, going through a job requisition is 
able to interact with multiple systems via a very   simple chat interface and have work dynamically 
sequenced to support them in doing their tasks.  That, once again, requires a notion of working 
with models and technology in a way that,   in many ways can be unique to how a business 
wishes to work, and indeed in various cases   can embody what they consider their “secret 
sauce” or their differentiated advantage.  So once again: a platform that recognizes 
that and is designed for business. That's   not the same scope or frame of reference 
for a consumer platform. And then,   you know, we're also seeing a lot 
of work around code generation,   application modernization, you know, 
and people enhancing their skills. So   “targeted” becomes really important.
I mentioned “open” and I mentioned   “targeted.” Targeted to the business, to the use 
cases that they need to do. Underpinning that,   then, is “trusted.” So everything I gave you in 
those targeted use cases talks about handling   enterprise, proprietary, and specific data—we 
are trusted in this regard, right? We have   been serving the business for many, many a year.
And we are designing our platform and even our   principles and way of operating to recognize 
and enable that, both in terms of the work we   do around the governance framework and 
transparency that you're able to gain   and apply. But even in the way we allow our 
platform to be deployed in multiple, kind of,   locations or footprints consumed as a service 
on a hyperscaler, running your own private   footprint on prem, or your cloud footprint.
All of these need to be brought together to   meet the needs of an actual enterprise 
business. My last comment is: where I   think we're fundamentally differentiated 
is, we're really about empowering our customers to take advantage of AI to 
unleash the intelligence, capabilities,   productivity of their own business.
This isn't about, “We've established a   bunch of APIs that you can ask questions.” This 
is about, “How do you craft what you need for   your business to deliver differentiated 
value to your customers, shareholders,   employees, with all the appropriate protections 
as well?” And so there's a lot of focus in what   we've done with the platform and the tool set 
to enable that—to enable what we like to call   “AI value creators,” not just consumers of AI. Jacob Goldstein: When you were talking about, basically, enterprise adoption of AI, you used the word “trust.” And I'm curious:   you know, what does, what does “trust” mean 
in the context of AI and the enterprise?  Kareem Yusuf: I would kind of deconstruct “trust” 
along these key avenues. If AI is about giving   you insights to help you support decisions, 
how do you trust what insight is provided?  So: “What data did it use? What did it consider 
based upon that data that therefore led to the   insight provided?” Why is this important? 
Why—why this notion of trust? Well, one,   you're about to make a decision, so you want 
to understand the basis for a decision. It's no   different than me asking you something and then 
saying, “Okay, can you explain you're working?”  That would be a notion of trust that we establish, 
and a very natural interaction as humans,   right? We do it all the time, right? So 
there is that element. The other reason   why it becomes important: if you're applying
AI into business processes and therefore how   your business works, you want to make sure that 
you know what biases are built into any decision,   or not, or if the AI, the model in 
effect, is drifting away from, kind of,   the parameters that you would want it 
to remain within, right? Ergo, trust. And so, in many ways, that's one big aspect of 
trusting the technology, because you're applying   it into decisions you need to make every day, 
and you need to know, in very simple terms,   how it works and how it is working. The other 
element of trust that I think is important in this   discussion: “Who are you getting your AI from?” Jacob Goldstein: Huh. Kareem Yusuf: That's very important to us as 
a company here at IBM, right? Given we serve business, that trust becomes extremely important. And what are the elements of that trust? What are the customers trying to understand? Well, 
first and foremost, what's your ethos around AI?  We're very clear on, “The customer's data is 
their data.” When they tune or refine those   models to meet their use cases, that is all 
theirs. And we actually provide the ability   for them to do that in very isolated and protected 
ways, as they choose. And we never use their data   without explicit opt-in and permissions, right? 
Customers might say “Oh yeah, use this so that you   can make a generally overall better model.”
But it's full awareness, full transparency.   That is important. That's a trust of who you're 
doing business with. So that's how I think about   trust. How do you build systems you trust? 
And are you working with people you trust? Malcolm Gladwell: I find Kareem’s point 
about trust when it comes to data to be   so important. Because as powerful as AI tools 
can be, their helpfulness is dependent on how   trustworthy the data is. Humans will have 
to decide if our data, our decision-making,   and our AI insights live up to the 
vision we hope to achieve in business. As Kareem and Jacob continue the conversation,   Jacob asks some more practical questions 
about how businesses can adopt AI into   their own processes. Let’s listen. Jacob Goldstein: How can—how can businesses move toward integrating AI as part of their core business model instead of sort   of as an add-on on the periphery? Kareem Yusuf: It's funny; you know, my simple answer to that is, “It's actually the simplest thing in the world to do by   thinking about your business.”
Jacob Goldstein: Uh huh.  Kareem Yusuf: Thinking about your elements 
of differentiation, and then thinking about   how AI can help you extend, expand those, 
right? What—what do you want to be known for?  I picked a very simple use case of 
customer-service interaction. Almost   every business needs to do that and wants to do it 
better. And so it becomes a way to start. But then   as you begin to work your way through, you think 
about various—automation of business processes.  You think about decisions that need to be 
made, right? Or “How can individuals be   helped? How can they be made more productive?” 
I think always becomes a very important one,   right? So—and you can apply this in many contexts. 
A financial analyst looking at reams of data and   trying to derive insights; how do you leverage AI 
to make that financial analyst even more powerful?  And so that's how I advise, you know, people 
to always look at it. Think about your tasks.   Think about your business processes. Think 
about where help is needed or where new   value could be unlocked. And then you're 
applying AI as a tool to achieve that end. Jacob Goldstein: One of the themes we 
return to on this show a lot is creativity,   and the relationship between technology and 
creativity. And I'm curious how you think   that AI can help people be more creative at work. Kareem Yusuf: I think AI can help people be more creative at work by automating the mundane to unlock your mind to be able to focus on   higher value. I've talked about deriving insights 
from data, right? To drive informed decisions.  If you can use AI to gather a lot more insights 
into one place than you could typically do   yourself, or more—manually, you'd have to, 
like, write it down, look at six spreadsheets,   copy from here to there—then you actually have 
more time to look at that data, digest those   insights and think about what do I need to do with 
these as a business? Which direction do I want   to go? I think of it as freeing us up to do more 
of what we actually as humans do extremely well,   which is actually that creative thinking.
Think in very simple terms. Why do we use   a calculator to do arithmetic? It's not that 
we cannot necessarily knock it out ourselves,   but if you're trying to balance your checkbook, 
to use an old phrase (or dare I say, just,   “What's a checkbook?” I've thought about 
that. So let us modernize that)—if you're   trying to check your expenses for the month 
and your performance against budget, yes,   you could print out all your statements, 
circle everything, hand-add it all up.  Or you could begin to use technology to 
improve that experience so you can get   more time to think about “What, really, 
am I learning from my spending patterns,   and what do I want to do about it?”
It's a very simple personal example,   but I think it's fundamentally what we're 
talking about here, and that's always been,   in my mind, the promise of technology. 
Freeing us up to actually apply ourselves   to higher-value thought and higher-value problems. Jacob Goldstein: So we've been talking, basically, about the present so far. And I'm curious if you—if you think about the future and you think, you know, medium to long term, how do you 
think AI is going to transform business? And,   you know, how can people now, business 
leaders now, prepare for what's coming?  Kareem Yusuf: So, to an earlier comment I made, I 
do really think that we are at an inflection point   with the advancement of—the technologies of AI. I 
talked about foundation models. We definitely are   at the cusp of being able to address use cases 
at scale that were more challenging before.  And so I do think the future looks like a lot 
more generative AI surfacing within the enterprise   and within business processes and manifesting in 
interesting ways. I think it's almost a given that   any piece of software, right?—whether you think 
of it in terms of an application or you think   about it in terms of, you know, the interaction 
with the website—will have conversational-enabled   interfaces, from the analyst saying “Give 
me the latest reports for the last three   months,” you know—typing that, or saying 
it, versus the “right-click file” blah blah.  I think you're going to see that change 
in interaction to more- conversational   interaction, I think particularly chat based. Jacob Goldstein: Graphical user interface is just a metaphor, right? It's not like the way computers work. It's just an interface. And if   chat is a better interface, people will use chat. Kareem Yusuf: I think we're going to see that really explode. And that's powered by a lot of this generative AI work,   because it becomes—for it to feel natural, for 
it to be as informed, to readily, as I said,   link things together and orchestrate. That's a 
big part. So I think I see that happening, and the   appropriate or associated productivity unlocks—you 
begin to see, with that—will just change what kind   of decisions, the ease with which we can make 
more-and-more-informed business decisions.  And so, for me, it's that: rolling out at scale, 
touching everything, procurement, HR. Think about   the advent of the spreadsheet and how many 
different roles it just ended up touching. And   everybody can use or does use a spreadsheet 
in business in some shape, size, or form. So I think of this as “AI at scale.” And so 
what it therefore means, from—as you said,   getting prepared. Well, it's all about gaining, 
first of all, the right understanding of the   technologies, and part of what we'll be talking 
about. Necessary ingredients begin to be,   well, “Where do I want to apply it first?
What data do I need to bring together to readily   support that? What unlocks what new value?” 
And I think it's going to be like this rollout,   right? You're going to start with this project, 
and then there's another project. And very soon   it will be so much—it will be ubiquitous in the 
way it supports the work we need to do, that—it   will just speak to a new way of us working.
That is, when you now look back, we'll be   pretty different from how we work today. 
You see the seeds today? But, I would argue,   think of that now, like, fully bloomed. 
It's a forest, not a flower bed, you know?  Jacob Goldstein: Yeah. Yeah. Great.
One other, sort of, loose thread I   want to—I want to return to, and that's, 
that's governance, right? You talked about   governance. And maybe just—just to help sort of 
set the table: you mentioned it in a broad way,   but narrowly, what does governance mean in 
the context of IBM's work on enterprise AI?  Kareem Yusuf: I think, as the word tries 
to suggest, it is about having the way to   govern one's activities in this realm, 
which really speaks to policies, rules,   and frameworks within which to understand all 
of that. Now, before we dive in the direction   of regulation, which is where people 
often go, policies can be all internal.  So think about it this way. If I say to 
you, “When I build AI, I do not use—uh,   my customer's data is their customer's data.” Then 
from a governance perspective, I need processes   that ensure I know what data I'm using. And 
I can prove to myself, just, first of all,   internally— forget about anybody else—that I'm 
actually adhering to the policies I've laid out. That, in my mind, is a lot of what governance 
is about, and in the context of AI,   it always tends to structure around three 
key areas. Data: “Where did it come from,   and what did I do with it, and how did I apply 
it, and where did I use it?” And then usage:   “What do I expect this model to do? Is this 
model still performing the way I think it should   be performing? What are my processes to address 
whether the answer to that question is yes or no,   and manage that through?” And then, importantly—so 
this is, then, the bridge to regulation.  If you take a look at what's going on 
in the, in the world of AI regulation,   and—our point of view on this, by the way, 
is that you actually regulate the use cases,   not the technology—then from a governance 
perspective, how are you able to clearly   understand, track, and account for what use cases 
you are leveraging AI for?And then, back to my   earlier comments, how that AI is performing. Jacob Goldstein: And when you talk about governance, how do you make sure that you have the governance you need without inhibiting innovation?  Kareem Yusuf: I think what is key—and this is key, a key design point for what we're doing with   watsonx—is how you make governance seamless in 
situ versus another activity that you do. Right?  And so our goal is to try and drive that, 
kind of—seamless interactions of a value add,   in terms of governance, so that when, “Oh, 
let's pull through the history—right?—of   everything we've done here, what prompts we've 
created or what data we've used,” it's, kind of,   already there, right? And so you can feel free 
to be innovating and testing out your different   prompts and all that stuff, or bring it in your 
data sets, without saying “Oh, before I do that,   I need to make sure I run this checker.”
No, you can, kind of, bring it in, systems—kind   of automatically categorize it, and then you can 
go in and later verify, validate, or explore—say,   “I'm no longer going to take this path based upon 
these facts.” I think the more we can make it more   of a natural extension of the activities that need 
to be done, the more we can make it, then, just a part of what needs to be done. And 
as to your point, gain our governance   needs or support the governance needs 
of our customers without stifling the   innovation of the individuals at the glass 
trying to think through, and iteratively   think through, new valuable ways to do work. Jacob Goldstein: Excellent. Let me ask you: are there things I didn't ask you that I should? Are there things you   want to talk about that we didn't talk about? Kareem Yusuf: I think we covered quite a lot, truth be told. No, I think we, we covered the bases there. Malcolm Gladwell: Earlier, Kareem mentioned 
that we are at an inflection point in AI   technology. Implementing AI in business will 
get easier, and AI platforms like watsonx   can empower even the largest enterprise 
businesses to reinvent the way they run.  As Kareem said, in the same way the 
spreadsheet took over business operations,   the adoption of AI at enterprise scale 
could be just as ubiquitous. It’s not   an overstatement to say that a 
new era of work may be upon us. Smart Talks with IBM is produced by Matt Romano, 
David Zha Nisha Venkat, and Royston Beserve, with   Jacob Goldstein. We’re edited by Lidia Jean Kott. 
Our engineers are Jason Gambrell, Sarah Brugueire,   and Ben Tolliday. Theme song by Gramoscope.
Special thanks to Carly Migliori, Andy Kelly,   Kathy Callaghan, and the EightBar and IBM 
teams, as well as the Pushkin marketing team. Smart Talks with IBM is a production 
of Pushkin Industries and Ruby Studio   at iHeartMedia. To find more Pushkin podcasts, 
listen on the iHeartRadio app, Apple Podcasts,   or wherever you listen to podcasts.
I’m Malcolm Gladwell.  This is a paid advertisement from IBM.