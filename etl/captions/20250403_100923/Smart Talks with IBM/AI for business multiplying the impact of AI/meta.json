{
  "video_url": "https://www.youtube.com/watch?v=hzAUCHh90Fg",
  "video_id": "hzAUCHh90Fg",
  "title": "AI for business: multiplying the impact of AI",
  "upload_date": "20240402",
  "channel": "IBM Technology",
  "duration": "32:22",
  "caption": "Malcolm Gladwell: Hello, hello. Welcome to Smart \nTalks with IBM, a podcast from Pushkin Industries,   iHeartRadio and IBM. I’m Malcolm Gladwell.\nThis season, we’re continuing our conversation   with New Creators— visionaries who \nare creatively applying technology in   business to drive change—but with a focus \non the transformative power of artificial   intelligence and what it means to leverage AI as \na game- changing multiplier for your business.  Our guest today is Kareem Yusuf, \nsenior vice president of product   management and growth for IBM software.\nKareem’s focus at IBM is on product strategy,   thinking about the roadmap for IBM software \nproducts to ensure they deliver effective   and compelling customer experiences. \nWith the current boom in generative AI,   Kareem’s job is to help businesses figure out how \nthey can apply artificial intelligence at scale,   to help solve big problems and boost \ncreativity at new orders of magnitude.  In today’s episode, you’ll hear \nKareem explain how AI powered by   foundation models can make AI adoption \nby enterprise businesses even easier,   how generative AI will change the way businesses \nprocess data and make decisions, and how these   considerations influenced the design of watsonx, \nIBM’s next-generation AI and data platform. Kareem spoke with Jacob Goldstein, host of the \nPushkin podcast What’s Your Problem? A veteran   business journalist, Jacob has reported for the \nWall Street Journal, the Miami Herald, and was a longtime host of the NPR program Planet Money.\nOkay! Let’s get to the interview.  Jacob Goldstein: I'm Jacob Goldstein. \nI'm one of the hosts at Pushkin  and a correspondent on this \nshow, and I'm delighted to   have you here. Can you introduce yourself?\nKareem Yusuf: Hi. I'm Kareem Yusef. I'm the   senior vice president of product management and \ngrowth for IBM software. You can think of me as   the chief product officer for IBM software. Jacob Goldstein: Okay. Sounds like a big job. We're here today to talk about AI. We've \nheard really an extraordinary amount in   the last few months about ChatGPT, uh, and, you \nknow—particularly in how it's used in the very,   kind of, consumer-facing way. But I'm curious: \nwhat does the rise of ChatGPT and, you know,   AI more generally—what does it mean for business? Kareem Yusuf: Well, you know, if you kind of step back and think about what really happens, you know, in a business, you're really talking about   a set of processes, right? You know, activities \nthat represent what a business needs to get done,   whether it's a product they produce and \nthen sell or a service that they provide.  And inherent to operating the business, I would \nsay, are two very key factors: data, and then the   decisions you make around that data. And then \nactually, lastly, the processes or activities   you do in accordance with that decision.\nSo if you then think about AI as applied   to business, right, in that context, \nwell, the first place it often starts is,   “How do you make sense of a lot of the \ndata associated with driving a business?” And so AI has always been, in my mind, at \nits foremost about gaining insights, then   leading to supporting decisions, and ultimately \nending at helping to automate the activities that   then are executed as a result of those decisions.\nSo that's kind of my simple way of thinking of AI,   and we can obviously color in with examples, \nbut that's my simplest way of thinking about   AI when you think about it in the business \ncontext. Gain insights from masses of data to   support decisions and then drive actions. Jacob Goldstein: That's a really helpful framework. And then if we think about sort of what's happening in the world now with, with,   you know, enterprise businesses \nand AI, what are you seeing with   enterprise adoption of AI at this moment?\nKareem Yusuf: So we're really talking about   almost a tale of two periods. So let me \nfirst of all kind of take you back—before   the advent of what I would call “generative \nAI” and the whole ChatGPT—to what has been   going on in what I would term the realm of \nmore standardized machine-learning models.  A lot of what has been going on has been \nvery much in the realms of certain things   like anomaly detection or optimization, right? \nUsing machine-learning models to do that kind of   work. And where might it apply? Well, think \nof anomaly detection in security software,   right? Detecting threats based upon different \nevents flowing through. Or in enterprise asset   management software, monitoring equipment and \ndetecting anomalies within their behavior.  Or even in IT automation software: once again, \ndetecting anomalies based upon what's going on   with various IT events and then tasks that should \noccur. Optimizations often play around in the   realm, as you might imagine, to solve problems of \nresource optimization, whether you think of that   in the context of application resource management \nfor IT or in the context of supply chain. These have been very classical applications of, \nuh, machine-learning AI to really make sense of   the data and provide a basis to drive decisions.\nNow, what—it's characterized by all those examples   I've given, and the state of the art of that \nkind of technology has always been—it's very   task specific. So there was an “air quote,” if \nI may, kind of “limitation,” in the sense that   the task—it had to be very task specific. And \nso we've seen a lot of broad-based adoption   within the enterprise, right? But it's very, \nvery task specific, as you might imagine. Now,   what has happened recently and has been \nbrought to the fore has been this discussion   of generative AI, which is powered by a very \nspecific innovation: this notion of foundation   models. And in the simplest way to think \nabout it, it is about training this large   model that can then be refined to various tasks.\nAnd the easiest one that everybody recognizes at   the moment is the notion of a large language \nmodel—a model that has an understanding of a   lot of the elements of a language such that \nit can be refined to a variety of tasks:   write an essay, answer a question, sing a song, \nso on and so forth. I like to liken the power,   if you like—and this will speak to the, why \neverybody is so excited about it, why I would   argue it’s an inflection point—I like to liken it \nto teaching a child the alphabet. When you teach a   child an alphabet, it's a set of letters, right?\nLet's call that our foundation model. But over   time, that knowledge of the alphabet is tuned to \nread a book, write an essay, do a composition,   create a song, write a poem, write an invoice. \nYou understand what I mean, right? And so from   one foundation model, you can support multiple \ntargeted tasks, as opposed—sticking with the   analogy—to having a model for reading, writing, \ndoing a poem, doing an essay, so on and so forth.  And so in the enterprise context, that means \nthat we're now talking about being able to   unlock even additional value at scale because \nof the nature of foundation models and their   appeal to generative use cases— “generative” \nin this case meaning “creation of new content.” Jacob Goldstein: So, let’s talk about watsonx. \nIBM recently announced watsonx. Just—first of all,   what is that? What is watsonx? Kareem Yusuf: Well, “watsonx” refers to our—is our brand for our platform, the watsonx platform, for really taking advantage   of generative AI within the enterprise, within \nbusiness. And so when you begin to think about,   “What does that mean?” Well, it leads you to the \ncomponents of watsonx and to a set of use cases.  So let me paint a few quick pictures for you \nhere. watsonx, first of all, is about enabling our   customers to manipulate models against their task, \nmanipulate these foundation models against their   task. Our belief is that the world is a multimodel \nworld. Right? And especially when you think about   it in the context of business, models are going to \ncome from various sources: the ones we supply; the   ones out there in open source and, sort of, view.\nBut there are activities you need to do around   these models to, as I said, apply them \nto your use case. And we'll talk about   use cases in a bit. So watsonx.ai is that \nenvironment that builds—a tool, if you like,   for being able to do those manipulation of \nmodels to meet your specific use case. Things   that people will recognize in the field: \nprompt engineering, prompt tuning, fine   tuning—those kind of activities, which are all \nthe manipulation of models to meet your use case.  The second component is data. So watsonx.data \nis essentially a next- generation data store.   It's based upon something referred to as \nan “open-data lake-house architecture” that   helps to bring together the data that's needed to \nactually do the AI. In this case, when you think   about manipulating a model, a foundation model, \nyou're generally using some data to prompt it,   tune it, train it to your use cases.\nAnd so we provide a very open data store   that allows all manner of data and formats to \nbe brought through to do that. And the third   component is watsonx.governance, and this \nis all about the framework and the toolkit   required to apply the right governance \nprinciples across doing this kind of work. Because when you're deploying AI within the \nenterprise, governance is actually important,   right? It's critical to understand: Where \nis your data coming from? What data did   you add in? How is your model performing? \nAre you able to keep an appropriate audit   trail of your activities for your own \ninternal policy and compliance needs,   or for regulatory needs as well? Jacob Goldstein: So this platform, this system that you're describing— I'm curious: how is it different from the, you know,   the generative AI options that, you know, we've \nall been hearing about, sort of, in the press?  Kareem Yusuf: Well, I think it really comes \ndown to the, the ethos or the principles that,   first of all, drive the work that we're doing. \nThe first I would fixate on is being open,   right? We fundamentally believe that to do \nthis kind of work within the enterprise,   you need an open platform that, as I said, is \nopen to all manner of models from all sources.  It's one of the reasons why we announced \nour partnership with Hugging Face—to make   sure that our clients can gain access \nto open-source innovation within the   platform to do their work. So that's the— Jacob Goldstein: Hugging Face, to be clear, is sort of the open-source AI, kind of, hub. Kareem Yusuf: That's right, that's correct. Yes, it's a marketplace hub for all—kind of, “ecosystem coordinator” for open-source models. And I believe   there's a lot of innovation going on out there. \nSo first of all, “open” becomes important. The   second: “targeted.” So our focus is very much \non enabling these business use cases, right?  And you might say, “What kind of use cases \nare we talking about?” I'll give you three   very quick ones that, you know, that our \ncustomers are focused on. A lot of focus   around enhancing customer-service use cases. \nThink of this as chatbots or digital assistants   that are further trained in more and more \ninformation about what the company has to   offer—or could be internal policies, \nexternal policies, so on and so forth. This means a platform that makes it really \neasy to bring your own data to train and   tune the model while protecting your own data. \nThat's extremely important for the enterprise,   right? Another important use case: seeing a \nlot of focus on what I would call “AI-based   orchestration” or automation of tasks, \nwhereby—think about, like, an HR professional,   as an example, going through a job requisition is \nable to interact with multiple systems via a very   simple chat interface and have work dynamically \nsequenced to support them in doing their tasks.  That, once again, requires a notion of working \nwith models and technology in a way that,   in many ways can be unique to how a business \nwishes to work, and indeed in various cases   can embody what they consider their “secret \nsauce” or their differentiated advantage.  So once again: a platform that recognizes \nthat and is designed for business. That's   not the same scope or frame of reference \nfor a consumer platform. And then,   you know, we're also seeing a lot \nof work around code generation,   application modernization, you know, \nand people enhancing their skills. So   “targeted” becomes really important.\nI mentioned “open” and I mentioned   “targeted.” Targeted to the business, to the use \ncases that they need to do. Underpinning that,   then, is “trusted.” So everything I gave you in \nthose targeted use cases talks about handling   enterprise, proprietary, and specific data—we \nare trusted in this regard, right? We have   been serving the business for many, many a year.\nAnd we are designing our platform and even our   principles and way of operating to recognize \nand enable that, both in terms of the work we   do around the governance framework and \ntransparency that you're able to gain   and apply. But even in the way we allow our \nplatform to be deployed in multiple, kind of,   locations or footprints consumed as a service \non a hyperscaler, running your own private   footprint on prem, or your cloud footprint.\nAll of these need to be brought together to   meet the needs of an actual enterprise \nbusiness. My last comment is: where I   think we're fundamentally differentiated \nis, we're really about empowering our customers to take advantage of AI to \nunleash the intelligence, capabilities,   productivity of their own business.\nThis isn't about, “We've established a   bunch of APIs that you can ask questions.” This \nis about, “How do you craft what you need for   your business to deliver differentiated \nvalue to your customers, shareholders,   employees, with all the appropriate protections \nas well?” And so there's a lot of focus in what   we've done with the platform and the tool set \nto enable that—to enable what we like to call   “AI value creators,” not just consumers of AI. Jacob Goldstein: When you were talking about, basically, enterprise adoption of AI, you used the word “trust.” And I'm curious:   you know, what does, what does “trust” mean \nin the context of AI and the enterprise?  Kareem Yusuf: I would kind of deconstruct “trust” \nalong these key avenues. If AI is about giving   you insights to help you support decisions, \nhow do you trust what insight is provided?  So: “What data did it use? What did it consider \nbased upon that data that therefore led to the   insight provided?” Why is this important? \nWhy—why this notion of trust? Well, one,   you're about to make a decision, so you want \nto understand the basis for a decision. It's no   different than me asking you something and then \nsaying, “Okay, can you explain you're working?”  That would be a notion of trust that we establish, \nand a very natural interaction as humans,   right? We do it all the time, right? So \nthere is that element. The other reason   why it becomes important: if you're applying\nAI into business processes and therefore how   your business works, you want to make sure that \nyou know what biases are built into any decision,   or not, or if the AI, the model in \neffect, is drifting away from, kind of,   the parameters that you would want it \nto remain within, right? Ergo, trust. And so, in many ways, that's one big aspect of \ntrusting the technology, because you're applying   it into decisions you need to make every day, \nand you need to know, in very simple terms,   how it works and how it is working. The other \nelement of trust that I think is important in this   discussion: “Who are you getting your AI from?” Jacob Goldstein: Huh. Kareem Yusuf: That's very important to us as \na company here at IBM, right? Given we serve business, that trust becomes extremely important. And what are the elements of that trust? What are the customers trying to understand? Well, \nfirst and foremost, what's your ethos around AI?  We're very clear on, “The customer's data is \ntheir data.” When they tune or refine those   models to meet their use cases, that is all \ntheirs. And we actually provide the ability   for them to do that in very isolated and protected \nways, as they choose. And we never use their data   without explicit opt-in and permissions, right? \nCustomers might say “Oh yeah, use this so that you   can make a generally overall better model.”\nBut it's full awareness, full transparency.   That is important. That's a trust of who you're \ndoing business with. So that's how I think about   trust. How do you build systems you trust? \nAnd are you working with people you trust? Malcolm Gladwell: I find Kareem’s point \nabout trust when it comes to data to be   so important. Because as powerful as AI tools \ncan be, their helpfulness is dependent on how   trustworthy the data is. Humans will have \nto decide if our data, our decision-making,   and our AI insights live up to the \nvision we hope to achieve in business. As Kareem and Jacob continue the conversation,   Jacob asks some more practical questions \nabout how businesses can adopt AI into   their own processes. Let’s listen. Jacob Goldstein: How can—how can businesses move toward integrating AI as part of their core business model instead of sort   of as an add-on on the periphery? Kareem Yusuf: It's funny; you know, my simple answer to that is, “It's actually the simplest thing in the world to do by   thinking about your business.”\nJacob Goldstein: Uh huh.  Kareem Yusuf: Thinking about your elements \nof differentiation, and then thinking about   how AI can help you extend, expand those, \nright? What—what do you want to be known for?  I picked a very simple use case of \ncustomer-service interaction. Almost   every business needs to do that and wants to do it \nbetter. And so it becomes a way to start. But then   as you begin to work your way through, you think \nabout various—automation of business processes.  You think about decisions that need to be \nmade, right? Or “How can individuals be   helped? How can they be made more productive?” \nI think always becomes a very important one,   right? So—and you can apply this in many contexts. \nA financial analyst looking at reams of data and   trying to derive insights; how do you leverage AI \nto make that financial analyst even more powerful?  And so that's how I advise, you know, people \nto always look at it. Think about your tasks.   Think about your business processes. Think \nabout where help is needed or where new   value could be unlocked. And then you're \napplying AI as a tool to achieve that end. Jacob Goldstein: One of the themes we \nreturn to on this show a lot is creativity,   and the relationship between technology and \ncreativity. And I'm curious how you think   that AI can help people be more creative at work. Kareem Yusuf: I think AI can help people be more creative at work by automating the mundane to unlock your mind to be able to focus on   higher value. I've talked about deriving insights \nfrom data, right? To drive informed decisions.  If you can use AI to gather a lot more insights \ninto one place than you could typically do   yourself, or more—manually, you'd have to, \nlike, write it down, look at six spreadsheets,   copy from here to there—then you actually have \nmore time to look at that data, digest those   insights and think about what do I need to do with \nthese as a business? Which direction do I want   to go? I think of it as freeing us up to do more \nof what we actually as humans do extremely well,   which is actually that creative thinking.\nThink in very simple terms. Why do we use   a calculator to do arithmetic? It's not that \nwe cannot necessarily knock it out ourselves,   but if you're trying to balance your checkbook, \nto use an old phrase (or dare I say, just,   “What's a checkbook?” I've thought about \nthat. So let us modernize that)—if you're   trying to check your expenses for the month \nand your performance against budget, yes,   you could print out all your statements, \ncircle everything, hand-add it all up.  Or you could begin to use technology to \nimprove that experience so you can get   more time to think about “What, really, \nam I learning from my spending patterns,   and what do I want to do about it?”\nIt's a very simple personal example,   but I think it's fundamentally what we're \ntalking about here, and that's always been,   in my mind, the promise of technology. \nFreeing us up to actually apply ourselves   to higher-value thought and higher-value problems. Jacob Goldstein: So we've been talking, basically, about the present so far. And I'm curious if you—if you think about the future and you think, you know, medium to long term, how do you \nthink AI is going to transform business? And,   you know, how can people now, business \nleaders now, prepare for what's coming?  Kareem Yusuf: So, to an earlier comment I made, I \ndo really think that we are at an inflection point   with the advancement of—the technologies of AI. I \ntalked about foundation models. We definitely are   at the cusp of being able to address use cases \nat scale that were more challenging before.  And so I do think the future looks like a lot \nmore generative AI surfacing within the enterprise   and within business processes and manifesting in \ninteresting ways. I think it's almost a given that   any piece of software, right?—whether you think \nof it in terms of an application or you think   about it in terms of, you know, the interaction \nwith the website—will have conversational-enabled   interfaces, from the analyst saying “Give \nme the latest reports for the last three   months,” you know—typing that, or saying \nit, versus the “right-click file” blah blah.  I think you're going to see that change \nin interaction to more- conversational   interaction, I think particularly chat based. Jacob Goldstein: Graphical user interface is just a metaphor, right? It's not like the way computers work. It's just an interface. And if   chat is a better interface, people will use chat. Kareem Yusuf: I think we're going to see that really explode. And that's powered by a lot of this generative AI work,   because it becomes—for it to feel natural, for \nit to be as informed, to readily, as I said,   link things together and orchestrate. That's a \nbig part. So I think I see that happening, and the   appropriate or associated productivity unlocks—you \nbegin to see, with that—will just change what kind   of decisions, the ease with which we can make \nmore-and-more-informed business decisions.  And so, for me, it's that: rolling out at scale, \ntouching everything, procurement, HR. Think about   the advent of the spreadsheet and how many \ndifferent roles it just ended up touching. And   everybody can use or does use a spreadsheet \nin business in some shape, size, or form. So I think of this as “AI at scale.” And so \nwhat it therefore means, from—as you said,   getting prepared. Well, it's all about gaining, \nfirst of all, the right understanding of the   technologies, and part of what we'll be talking \nabout. Necessary ingredients begin to be,   well, “Where do I want to apply it first?\nWhat data do I need to bring together to readily   support that? What unlocks what new value?” \nAnd I think it's going to be like this rollout,   right? You're going to start with this project, \nand then there's another project. And very soon   it will be so much—it will be ubiquitous in the \nway it supports the work we need to do, that—it   will just speak to a new way of us working.\nThat is, when you now look back, we'll be   pretty different from how we work today. \nYou see the seeds today? But, I would argue,   think of that now, like, fully bloomed. \nIt's a forest, not a flower bed, you know?  Jacob Goldstein: Yeah. Yeah. Great.\nOne other, sort of, loose thread I   want to—I want to return to, and that's, \nthat's governance, right? You talked about   governance. And maybe just—just to help sort of \nset the table: you mentioned it in a broad way,   but narrowly, what does governance mean in \nthe context of IBM's work on enterprise AI?  Kareem Yusuf: I think, as the word tries \nto suggest, it is about having the way to   govern one's activities in this realm, \nwhich really speaks to policies, rules,   and frameworks within which to understand all \nof that. Now, before we dive in the direction   of regulation, which is where people \noften go, policies can be all internal.  So think about it this way. If I say to \nyou, “When I build AI, I do not use—uh,   my customer's data is their customer's data.” Then \nfrom a governance perspective, I need processes   that ensure I know what data I'm using. And \nI can prove to myself, just, first of all,   internally— forget about anybody else—that I'm \nactually adhering to the policies I've laid out. That, in my mind, is a lot of what governance \nis about, and in the context of AI,   it always tends to structure around three \nkey areas. Data: “Where did it come from,   and what did I do with it, and how did I apply \nit, and where did I use it?” And then usage:   “What do I expect this model to do? Is this \nmodel still performing the way I think it should   be performing? What are my processes to address \nwhether the answer to that question is yes or no,   and manage that through?” And then, importantly—so \nthis is, then, the bridge to regulation.  If you take a look at what's going on \nin the, in the world of AI regulation,   and—our point of view on this, by the way, \nis that you actually regulate the use cases,   not the technology—then from a governance \nperspective, how are you able to clearly   understand, track, and account for what use cases \nyou are leveraging AI for?And then, back to my   earlier comments, how that AI is performing. Jacob Goldstein: And when you talk about governance, how do you make sure that you have the governance you need without inhibiting innovation?  Kareem Yusuf: I think what is key—and this is key, a key design point for what we're doing with   watsonx—is how you make governance seamless in \nsitu versus another activity that you do. Right?  And so our goal is to try and drive that, \nkind of—seamless interactions of a value add,   in terms of governance, so that when, “Oh, \nlet's pull through the history—right?—of   everything we've done here, what prompts we've \ncreated or what data we've used,” it's, kind of,   already there, right? And so you can feel free \nto be innovating and testing out your different   prompts and all that stuff, or bring it in your \ndata sets, without saying “Oh, before I do that,   I need to make sure I run this checker.”\nNo, you can, kind of, bring it in, systems—kind   of automatically categorize it, and then you can \ngo in and later verify, validate, or explore—say,   “I'm no longer going to take this path based upon \nthese facts.” I think the more we can make it more   of a natural extension of the activities that need \nto be done, the more we can make it, then, just a part of what needs to be done. And \nas to your point, gain our governance   needs or support the governance needs \nof our customers without stifling the   innovation of the individuals at the glass \ntrying to think through, and iteratively   think through, new valuable ways to do work. Jacob Goldstein: Excellent. Let me ask you: are there things I didn't ask you that I should? Are there things you   want to talk about that we didn't talk about? Kareem Yusuf: I think we covered quite a lot, truth be told. No, I think we, we covered the bases there. Malcolm Gladwell: Earlier, Kareem mentioned \nthat we are at an inflection point in AI   technology. Implementing AI in business will \nget easier, and AI platforms like watsonx   can empower even the largest enterprise \nbusinesses to reinvent the way they run.  As Kareem said, in the same way the \nspreadsheet took over business operations,   the adoption of AI at enterprise scale \ncould be just as ubiquitous. It’s not   an overstatement to say that a \nnew era of work may be upon us. Smart Talks with IBM is produced by Matt Romano, \nDavid Zha Nisha Venkat, and Royston Beserve, with   Jacob Goldstein. We’re edited by Lidia Jean Kott. \nOur engineers are Jason Gambrell, Sarah Brugueire,   and Ben Tolliday. Theme song by Gramoscope.\nSpecial thanks to Carly Migliori, Andy Kelly,   Kathy Callaghan, and the EightBar and IBM \nteams, as well as the Pushkin marketing team. Smart Talks with IBM is a production \nof Pushkin Industries and Ruby Studio   at iHeartMedia. To find more Pushkin podcasts, \nlisten on the iHeartRadio app, Apple Podcasts,   or wherever you listen to podcasts.\nI’m Malcolm Gladwell.  This is a paid advertisement from IBM."
}