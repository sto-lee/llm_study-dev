{
  "video_url": "https://www.youtube.com/watch?v=THEQbJIAxvE",
  "video_id": "THEQbJIAxvE",
  "title": "Hugging Face and watsonx: why open source is the future of AI in business",
  "upload_date": "20240430",
  "channel": "IBM Technology",
  "duration": "30:42",
  "caption": "Hugging Face and watsonx: why open \nsource is the future of AI in business Malcolm Gladwell: Hello, hello. Welcome to Smart \nTalks with IBM, a podcast from Pushkin Industries,   iHeartRadio and IBM. I’m Malcolm Gladwell.\nThis season, we’re continuing our conversation   with New Creators – visionaries who \nare creatively applying technology in   business to drive change — but with a focus \non the transformative power of artificial   intelligence and what it means to leverage AI as \na game- changing multiplier for YOUR business.  Our guest today is Jeff Boudier [BOO-dee-ay], \nHead of Product and Growth at Hugging Face,   the leading open-source and open- \nscience artificial-intelligence   platform. Before getting into the world of \nopen-source AI, Jeff co-founded a company   called Stupeflix, a video-editing software which \nwas eventually acquired by GoPro. An engineer   by background, he has a self-professed \nobsession with the business of technology.  Recently, IBM and Hugging Face \nannounced a collaboration,   bringing together Hugging Face’s repositories \nof open-source AI models with IBM’s watsonx   platform. It’s a move that gives businesses \neven more access to AI while staying true to   IBM’s long-standing philosophy of supporting \nopen-source technology. With open source,   businesses can build better AI models that \nsuit their specific needs, using their own   proprietary data, while browsing a \nready catalog of pretrained models.  In today’s episode, you’ll hear why open \nsource is so crucial to the advancement of AI,   how IBM’s watsonx interacts with open-source \nAI, and Jeff’s thoughts on why the singular,   omnipotent AI model is a myth.\nJeff spoke with Tim Harford,   host of the Pushkin podcast Cautionary Tales. \nA longtime columnist at the Financial Times, where he writes the “Undercover Economist,” Tim is \nalso a BBC broadcaster with his show More or Less.  OK, let’s get to the interview.\nJeff Boudier: Hi, I'm Jeff Boudier,   and I'm a Product Director at Hugging\nFace.  Tim Harford: So I'm immediately \nintrigued. Hugging Face—is this a  reference to the Alien movie, or something else?\nJeff Boudier: It is not. And it may be not obvious   to a listener, but “Hugging Face” is the name \nof that cute emoji—you know, the one that's   smiling with his two hands extended like that \nto give you a big hug? That's Hugging Face. So   basically we named the company after an emoji.\nTim Harford: Okay. And it is—I saw your website,   and it is a very friendly emoji. So that's \nnice. So tell us a little bit about Hugging   Face and, and about what you do there.\nJeff Boudier: Of course. Well, Hugging   Face is the leading open platform for AI \nbuilders, and it's the place that all of   the AI researchers use to share their work, \ntheir new AI models, and collaborate around   them. It's the place where the data scientists \ngo and find those pretrained models and access   them and use them and work with them.\nAnd increasingly, it's the place where   developers are coming to turn all of \nthese AI models and datasets into their   own applications, their own features.\nTim Harford: So like the Facebook group   or the Reddit or the Twitter for people who are \ninterested in, particularly, generative-language   AI, or all kinds of artificial intelligence?\nJeff Boudier: All kinds of AI, really. And   of course generative AI is this new wave \nthat has caught the world by storm. But   on Hugging Face you can find any \nkind of model. The new, sort of,   transformers models,to do anything from, \ntranslation—or if you wanted to transcribe   what I'm saying into text, uh, then you would \nuse a transformer model. If you wanted to, then take that text and make a summary, \nthat would be another transformer model.  If you wanted to create a nice little thumbnail \nfor the, this podcast by typing a sentence,   that would be, uh, another type of model. So all \nof these models you can find—there's actually,   300,000 that are free and publicly accessible—you \ncan find them on our website at huggingface.co,   and use them, using our open-source libraries.\nTim Harford: And so this is—this is fascinating.   So, so there are 300,000 models. Now, when \nyou say “model,” I'm thinking in my head,   “Oh, it's kind of like, um, like a computer \nprogram.” There were 300,000 computer programs.   Is that—is that roughly right? Or it—not really?\nJeff Boudier: It's a general idea. A model is a   giant, set of numbers that are working together \nto sift through some input that you're going to   give it. So think of it as a big black box \nfilled with numbers. And you give it as a,   as an input maybe some text, maybe a prompt.\nSo you're asking—you're giving an instruction   to the model, or maybe you \ngive it an image as an input,   and then it will sift through that information, \nthanks to all of these numbers, which we call,   in the field, “parameters,” and it will \nproduce an output. So when I told you, “Hey,   we can transcribe this conversation into text,” \nthe input would have been the conversation in   an audio file, and then the output would \nhave been the text of the transcription.  If you want to create a thumbnail for this \npodcast episode, then the input would be   what we call the “prompt,” which is really \na text description— like, uh, “French man in   San Francisco talking about machine learning.”\nAnd the output would be a completely original   image. So that's how I think about what an AI \nmodel is. And I think what we're starting to   realize is that this is becoming the new way of \nbuilding technology in the world. It has been—for   the field of dealing—understanding, \ngenerating text—for quite some time.  But now it's sort of moving across every field \nof technology. We have models to create images,   as I say, but also to generate new proteins, \nto make predictions on numerical data. So   every kind of field of machine learning \nis now using this new type of models. But what's interesting is that if you're,say, a \nproduct manager at a tech company, and you say,   “Hey, I want to build a feature that does this,” \na few years ago the approach would have been to   ask a software developer to write a thousand \nlines of code in order to build a prototype.  And a new way of doing things today is to go look \nfor an off-the-shelf, pretrained model that does a   pretty good job of solving exactly that problem. \nSo you can create a prototype of that feature   fast. So it's a new approach to building tech.\nTim Harford: I'm not a programmer, but I'm aware   that there's this idea of open-source code, \nand now we have open-source models. So what   does it mean for something to be “open source”?\nJeff Boudier: Yes, “open-source AI” actually   means a lot of different, specific things. It's \nthe open-source implementation of the model. So   if you use the Hugging Face transformers \nlibrary to use a model, you're using an   open-source code library to use that model.\nTim Harford: Just to interrupt on the   “transformers”—these are these, kind of, \nways of turning a picture of a dog into   a text output that says, “Hey, this is a \npicture of a dog,” or “This is a French   text,” and—with the transformers helping you \nturn it into English text. Or it's doing all   of these things that you've been describing.\nThat's—the, the transformer is the—kind of   the engine at the, at the heart of that.\nJeff Boudier: Yes, exactly. And we call   them “transformers” because they correspond \nto this new way of building machine-learning   models that was introduced by Google, \nactually, with a very important paper   called “Attention Is All You Need.” And it \nwas published in 2017 by researchers out   of Google DeepMind.\nTim Harford: Wow,   that's just six years. That's so new.\nJeff Boudier: It is very new, and ever since,   the pace of innovation has really, really \naccelerated. But it really started from this   inflection point that came from this paper \nand its implementation in what is now called   “transformer models.” The transformer—that has \nconquered every area of machine learning since. Tim Harford: Okay. Sorry to interrupt. So, \nso—you've got this library of transformer models,   and they're open source, and that means, that \nmeans what? Anyone can use them for free? Or that,   or that anybody can implement \nthem for free? What does it mean?  Jeff Boudier: So again, there's, like, lots that \ngo into it, but the most important thing is for   the model itself to be available so that a \ndata scientist or an engineer can download   them and use them. And also there are a lot \nof considerations about how you make them   accessible. And a very important one is whether or \nnot you give access to the training data—all the   information that went into training that model and \nteaching it to do what, what it's trained to do.  That's, uh—\nTim Harford: Have fed millions   of words into a, into a language transformer, or \nI might have fed millions of photographs into a,   into a picture transformer. Yeah.\nJeff Boudier: Yes. And the accessibility   of that training data is very, very important.\nTIM HARFORD: What's the relationship between the,   the Hugging Face libraries and, uh, GitHub? \nWhich, if I understand GitHub correctly,   it's this—the repository of open-source code, \nlots and lots of lines of code and routines and   programs that are, that are shared and updated \nand tracked, and they're all available on,   on GitHub. Which sounds similar to what you're \ndoing with Hugging Face for AI. So what,   what is the interaction or the relationship there?\nJEFF BOUDIER Yeah, I think you nailed it on the   head. So Hugging Face is to AI what GitHub is to \ncode, right? It's this central platform where AI   builders can go find, and collaborate around, AI \nartifacts, which are models and datasets. So it's   quite—it's different than software, but we play \nthe central, the central role in the community to   share and collaborate and access all of those \nartifacts for AI like GitHub offers for code.  Tim Harford: And that community must be incredibly \nimportant. I mean, the—open source is nothing if   you don't have a community of people working \non it. So how have you been able to foster— Jeff Boudier: Well, I think it goes to the \norigins of the transformer model, and, and   Hugging Face rolled into that. So when the first, \nsort of, open model came out, it was called BERT,   and it came out of Google. The only way you could \naccess it was to use a tool called TensorFlow.  But it happened that most of the AI \ncommunity was using a different tool,   called PyTorch. And something that Hugging \nFace did is to make that new model, BERT,   accessible to all PyTorch users. And they did it \nin open source. It was a project called “BERT's   Pretrained PyTorch” or “BERT PyTorch Pretrained.”\nTim Harford: So this is like being able to play my   Zelda game on, on an Xbox or a PlayStation, right? \nOr am I not really understanding what's going on?  Jeff Boudier: No, that's exactly what it is. And \nthe thing is, everybody was using the Game Boy,   and so it became very popular. And from there, \nthe community sort of gathered to make all of   the other models that were then published by \nAI researchers available through that library,   which was quickly renamed from “BERT’s Pretrained \nPyTorch” into “transformers” to welcome, like,   all of these different, new models.\nAnd today, that's—open-source library   transformers is what all AI builders are \nusing when they want to access those models,   see how they work and build upon them.\nTim Harford: What's striking about this field   is that it's changing so fast. It's improving so \nquickly. So how do open-source models keep up with   that? How do they get iterated and improved?\nJeff Boudier: Actually, it's not so much that   open source is keeping up with it; it's actually \nopen source that is driving that is driving this   pace of change. And that's because— with open \nsource and open research, data scientists’,   researchers can build upon each other's work.\nThey can reproduce each other's work. They can   access each other's work using our \nopen-source libraries, et cetera.  So in a sense, it's not really that open-source AI \nis a new idea. It's rather the opposite. There's   been a blip of time in which closed-source AI \nseems to be the dominant way, but it's really a   blip. In fact, you know, none of the incredible \nadvances that we're marveling about today would be possible without open source. We're \nstanding upon the shoulders of 50 years   of research in open-source software. So \nI think that that's really important;   if it wasn't for that, we'd probably be 50 \nyears away from having this—amazing experiences   like ChatGPT or Stable Diffusion, et cetera.\nSo it's really open source that is fueling this   pace of change—all, all these new models, all \nthese new capabilities. To give you an example:   so Meta released, uh, LLaMA large language \nmodel just a few months ago. And ever since,   there's been this Cambrian explosion of \nvariations and improvements upon the original   models. And today there are over a thousand \nof them that we host and track and evaluate.  So, yeah, open source is really \nthe gas and the engine for that. Malcolm Gladwell: Jeff just made it \nclear that it is open source, not closed,   that sets the pace for AI innovation. If that’s \ntrue, then forward-thinking businesses shouldn't   shy from leveraging open-source AI to solve \ntheir own proprietary challenges. But how?   Businesses can face serious obstacles when \ntrying to adopt open-source technologies,   like complying with government regulation or \nmaking sure their customers’ data stays protected.  In the next part of their conversation, Jeff \nand Tim discuss how IBM’s collaboration with   Hugging Face empowers businesses to \ntap into the open-source AI community,   and how the watsonx platform can enable them \nto customize those AI models to their needs.  Tim Harford: I just wanted to ask \nabout the partnership between Hugging   Face and IBM. How did that come about?\nJeff Boudier: Well, it came through a   conversation. A conversation between our CEO, \nClément Delangue, and Bill Higgins, IBM, who's   really, really close to all the amazing research \nwork and open-source work that's happening at   IBM. And that conversation sort of sparked the \nevidence that we needed to do something together.  We share a lot of values in terms \nof the importance of open source,   which is fundamental to us; with the \nimportance of doing things in a, an ethics-first way, to enable the community \nto incorporate ethical considerations in   how they're building AI. And we sort of have \na different audience to start with, which is   all the AI builders use Hugging Face today.\nTo access all the models we talked about;   to use them using our open source, and build \nwith them. And IBM has this incredible history   of working with enterprise companies \nand enabling them to make use of that   technology in a way that's compliant with \neverything that an enterprise requires.  And so being able to marry these two things \ntogether is an amazing opportunity. And now   we can enable the largest corporations that \nhave, sort of, complex requirements in order   to deploy machine-learning systems and \ngive them an easy experience—to take   advantage of all the latest and greatest \nthat AI has to offer through our platform.  Tim Harford: Let's talk about this idea of a, of \na single model or a variety of models. Because   what I've been hearing you say—you've been saying, \n“Oh, there are lots of models, there are hundreds   of thousands of models available on Hugging Face.”\nBut you've also said “There's this single thing,   the transformer, and they're all transformers.” \nSo if they're all basically the same thing,   why can't you just build one super-clever \nmodel that can do everything?  Jeff Boudier: That's a really interesting idea, \nand very much a new idea. And the reason we have   over a million repositories, 300,000 free \nand accessible models, on the Hugging Face   platform is that models are typically trained \nto do one thing—and they're typically trained   to do one thing with specific types of data.\nAnd what became new and evident in the research   that came out over the last couple years is that \nif you train a big enough model with enough data,   then those models start to have a—sort \nof general capabilities. You can ask   them to do different things. You can even \ntrain them to respond to instructions.  So with the same model you can say, “Hey, \nsummarize this paragraph, translate this   into English, start a conversation in French, and \nthen pivot to German.” And so these are general,   sort of, language capabilities. And I think when \nChatGPT came online, and the world, sort of, discovered these new capabilities, there was, \nat least for a short period, this sort of idea,   this sort of myth, that “the end game of all \nthis is maybe one or a handful of models are   so much better than anything else that exists, \nthat they can do anything that we can ask them to   do. And that's the only model that we will need.”\nAnd I, for one—I think it is a myth. I don't think   it is practical, for a variety of reasons.\nSay you're writing an email and you have,   like, this great suggestion of text to, sort of, \ncomplete your sentence. Well, that's AI. That's,   that's a large language model. That's \na transformer model that does that.  So there are a ton of existing use cases like \nthis, and these use cases are powered by specific   models that have been trained to do one thing well \nand to do it fast. If you wanted to apply these,   sort of—all-knowing, powerful, Oracle type \nof model, you would not be able to serve   millions of customers through a search engine.\nYou would not be able to complete people's   sentences, because the amount of money that \nyou would need, the number of computers that   you would need, to run such a service—it just \nexceeds what is available on the planet. So   one reason for which it's not a practical \nscenario is that it's just very expensive   to run those very, very large models.\nTim Harford: What I'm hearing is,   it's like, “Look, if you want to screw in \na screw, you need a screwdriver.” You don't   want an entire toolshed full of tools if the \ntask is to screw in—a screwdriver. And sure,   you could bring the toolshed. There are all \nthe tools; there's a screwdriver there. But   it's not necessary. It's incredibly \nexpensive. It's incredibly cumbersome,   and that cost exists even though, maybe, as the \nuser who's just typing in a, into a prompt box,   the user may not see it, but it's still very real.\nJeff Boudier: That's right. And then another   one is performance. So, taking the \nscrewdriver example, so—and by the way,   like, we're not quite there at this moment where \nwe have this all-knowing, powerful Oracle; that   is still sort of a sci-fi scenario. But—we have \nscrewdrivers, but we also have the Leatherman,   right? The, the multitool—a Swiss Army knife, and \nthat's, sort of the moment that we are in today. But now if I'm trying to open up my computer, \nit turns out that it requires a specific kind   of a screw, like these tiny little Torx screws, \nand having a Torx screwdriver will get me   much further than trying to use my Leatherman, \nwhere maybe I'll get the knife blade and it'll,   it will mess up the screw, and maybe eventually \nI'll get to what I need—but my point is that if   you take a very specifically trained model for \na particular problem, it will work much better.  It will give you better results \nthan a very, very generalistic,   big model that can do a lot of things. And so \nfor things like search engines, for things like   translation, for things that are very specific, \ncompanies are much better off using smaller,   more-efficient models that produce better results.\nTim Harford: That's really interesting and   presumably then being able to know which model to \nuse, or being able to know who to ask which model   to use, becomes a very important capability.\nJeff Boudier: Yes, and that's what we're   trying to make easy through our platform.\nTim Harford: So tell me about how this works   with IBM's watsonx platform. How do you see \nHugging Faces’ customers benefiting from that?  Jeff Boudier: The end goal is to make it really \neasy for watsonx customers to make use of all   the great models and libraries that we talked \nabout—all the, the, the 300,000 models that are   today on Hugging Face. And to do this, we need to \nreally collaborate deeply with the IBM teams that   build the watsonx platform, so that our libraries, \nour open source, our models are well integrated   into the platform. If you're a single user, if \nyou are a data-science student, and you want to   use a model, we make it super easy, right? We \nhave our open-source library. You can download   the model on your computer and run with it then.\nBut in enterprises, there is a vast complexity of   infrastructure and rules around what \npeople can do and how the data can   be accessed. And all this complexity is, \nsort of, solved by the watsonx platform.  Tim Harford: This season of the \nSmart Talks podcast features what   we're calling New Creators. Do you, do you \nsee yourself as being a creative person? Jeff Boudier: I think it's a requirement for \nthe job. I mean, we're in such a new and rapidly   evolving industry that we have to be creative \nin order to invent the business models, the use   cases, of tomorrow. My role within the company \nis really to create the business around all of   the great work of our science and open-source \nand product team. And by and large the business   model of AI within the whole ecosystem is still \nsomething that companies are trying to figure out.  So creativity is really, really important—to \nreally have the conversation with companies,   understand what they're trying to do and then \nbuild the right kind of solution. So that's,   like, where creativity comes into play.\nTim Harford: And one of the things that you've,   you've been talking about is just this, this \ngrowing number of models, this growing number   of capabilities, this growing number of use \ncases—enormously exciting. But also, I think,   completely bewildering for most people who are \ntrying to navigate their way through this, this   maze of possibilities that is, that is growing \nfaster than they can even learn about it. So   how are you helping people navigate and make \nchoices in that environment? And how does the   partnership with IBM help with that?\nJeff Boudier: Hmm. Well, as I said,   like, our vision is that AI machine \nlearning is becoming the default way   of creating technology. And that \nmeans, like, every product, app,   service that you're going to be using is going \nto be using AI to do whatever it is better,   faster. And I guess there are two competing \nvisions of the world coming from that.  There is this vision of the Oracle all-powerful \nmodel that can do everything. And our vision is   different. Our vision is that every single company \nwill be able to create their own models that they   own, uh, that they can use, that they control. \nAnd that's the, the, the vision that we're trying   to bring to life through our open-source tools \nthat make this work easy, through our platform   where you can find all those pretrained \nmodels that are shared by the community.  So we really want to empower companies to \nbuild their own stuff, not to outsource all   the intelligence to a third party, and the \nwatsonx platform from IBM gives those tools   to enterprise companies. So that's—you can use \nthe open-source models that Hugging Face offers.   Then you can improve them with your own data \nwithout sharing that data to a third party. And then you could do every—all of this work in \ncompliance with whatever governance requirements   you have for your company. Maybe you’re a finance \nservices company and you have a specific set of   rules. Maybe you’re a healthcare company and \nyou have very strong privacy requirements   for patients’ data. Maybe you’re a tech \ncompany and you have your, your customers’,   your users’ personal information. So you need to \nbe able to do this work, respecting all of that.  Tim Harford: Jeff Boudier. Thank you very much. \nJeff Boudier: Thanks so much, Tim. It was fun. Malcolm Gladwell: To create the AI models of \nthe future, we are going to need open source.   That means there’s a place for business \nin the open- source community to harness   the game-changing potential of AI innovation.\nLike Jeff said, businesses face unique challenges   they need to solve at scale. Without proper \nsupport systems, tapping into open- source AI   at enterprise level is daunting: finding the \nright-sized model for the job, fine-tuning   its purpose, all while addressing governance \nrequirements around data, privacy, and ethics.  So for businesses, IBM’s collaboration with \nHugging Face is a mark of progress because   it signifies that business can tap into open- \nsource AI while preserving enterprise-level   integrity. Businesses should embrace the \nopen-source community and the AI future,   much like Hugging Face (and \nits emoji namesake) suggests.  I’m Malcolm Gladwell.\nThis is a paid advertisement from IBM.  Smart Talks with IBM is produced by Matt \nRomano, David Zha [JAH], Nisha [Nih-sha] Venkat,   and Royston Beserve, with Jacob Goldstein. We’re \nedited by Lidia Jean Kott. Our engineers are   Jason Gambrell, Sarah Bruguiere [Brew-Ghare (hard \nG!)], and Ben Tolliday. Theme song by Gramoscope. Special thanks to Carly Migliori, Andy Kelly, \nKathy Callaghan [Calla-Han], and the EightBar and   IBM teams, as well as the Pushkin marketing team.\nSmart Talks with IBM is a production of Pushkin   Industries and Ruby Studio at iHeartMedia. \nTo find more Pushkin podcasts, listen on   the iHeartRadio app, Apple Podcasts, \nor wherever you listen to podcasts."
}